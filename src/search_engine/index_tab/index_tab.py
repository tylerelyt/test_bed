import gradio as gr
from datetime import datetime
import json
import os
import tempfile

def show_index_stats(search_engine):
    """æ˜¾ç¤ºç´¢å¼•ç»Ÿè®¡ä¿¡æ¯"""
    try:
        stats = search_engine.get_stats()
        html_content = f"""
        <div style="background-color: #f8f9fa; padding: 15px; border-radius: 8px; border-left: 4px solid #007bff;">
            <h4>ğŸ“Š ç´¢å¼•ç»Ÿè®¡ä¿¡æ¯</h4>
            <ul>
                <li><strong>æ€»æ–‡æ¡£æ•°:</strong> {stats.get('total_documents', 0)}</li>
                <li><strong>æ€»è¯é¡¹æ•°:</strong> {stats.get('total_terms', 0)}</li>
                <li><strong>å¹³å‡æ–‡æ¡£é•¿åº¦:</strong> {stats.get('average_doc_length', 0):.2f}</li>
            </ul>
            <p style="color: #6c757d; font-size: 0.9em;">ç»Ÿè®¡æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}</p>
        </div>
        """
        return html_content
    except Exception as e:
        return f"<p style='color: red;'>è·å–ç´¢å¼•ç»Ÿè®¡å¤±è´¥: {str(e)}</p>"

def check_index_quality(search_engine):
    """æ£€æŸ¥ç´¢å¼•è´¨é‡"""
    try:
        stats = search_engine.get_stats()
        total_docs = stats.get('total_documents', 0)
        total_terms = stats.get('total_terms', 0)
        avg_length = stats.get('average_doc_length', 0)
        
        issues = []
        recommendations = []
        
        if total_docs == 0:
            issues.append("ç´¢å¼•ä¸­æ²¡æœ‰æ–‡æ¡£")
            recommendations.append("æ·»åŠ æ›´å¤šæ–‡æ¡£åˆ°ç´¢å¼•")
        
        if total_terms <= 50:
            issues.append("è¯é¡¹æ•°é‡è¾ƒå°‘")
            recommendations.append("å¢åŠ æ–‡æ¡£å¤šæ ·æ€§")
        
        if avg_length < 10:
            issues.append("æ–‡æ¡£å¹³å‡é•¿åº¦è¿‡çŸ­")
            recommendations.append("å¢åŠ æ–‡æ¡£å†…å®¹é•¿åº¦")
        elif avg_length > 100:
            issues.append("æ–‡æ¡£å¹³å‡é•¿åº¦è¿‡é•¿")
            recommendations.append("è€ƒè™‘æ–‡æ¡£åˆ†æ®µ")
        
        html_content = f"""
        <div style="background-color: #f8f9fa; padding: 15px; border-radius: 8px; border-left: 4px solid #007bff;">
            <h4>ğŸ” ç´¢å¼•è´¨é‡æ£€æŸ¥æŠ¥å‘Š</h4>
            <h5>ğŸ“ˆ è´¨é‡æŒ‡æ ‡:</h5>
            <ul>
                <li>æ–‡æ¡£æ•°é‡: {total_docs} ä¸ª</li>
                <li>è¯é¡¹æ•°é‡: {total_terms} ä¸ª</li>
                <li>å¹³å‡æ–‡æ¡£é•¿åº¦: {avg_length:.2f} ä¸ªè¯</li>
            </ul>
        """
        
        if issues:
            html_content += f"""
            <h5>âš ï¸ å‘ç°çš„é—®é¢˜:</h5>
            <ul style="color: #dc3545;">
                {''.join([f'<li>{issue}</li>' for issue in issues])}
            </ul>
            """
        
        if recommendations:
            html_content += f"""
            <h5>ğŸ’¡ æ”¹è¿›å»ºè®®:</h5>
            <ul style="color: #007bff;">
                {''.join([f'<li>{rec}</li>' for rec in recommendations])}
            </ul>
            """
        
        html_content += f"""
            <p style="color: #6c757d; font-size: 0.9em;">æ£€æŸ¥æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}</p>
        </div>
        """
        return html_content
    except Exception as e:
        return f"<p style='color: red;'>ç´¢å¼•è´¨é‡æ£€æŸ¥å¤±è´¥: {str(e)}</p>"

def view_inverted_index(search_engine):
    """æŸ¥çœ‹å€’æ’ç´¢å¼•å†…å®¹"""
    try:
        index_service = search_engine.index_service
        # ç›´æ¥è®¿é—®åº•å±‚InvertedIndexå¯¹è±¡
        inverted_index = index_service.index.index
        # å–å‰20ä¸ªè¯é¡¹
        items = list(inverted_index.items())[:20]
        data = [[term, ', '.join(list(doc_ids)[:10])] for term, doc_ids in items]
        return data
    except Exception as e:
        return [["é”™è¯¯", str(e)]]

def get_all_documents(search_engine):
    """è·å–æ‰€æœ‰æ–‡æ¡£åˆ—è¡¨"""
    try:
        documents = search_engine.get_all_documents()
        if not documents:
            return [["æš‚æ— æ–‡æ¡£", "è¯·å…ˆå¯¼å…¥æ–‡æ¡£æ–‡ä»¶"]]
        
        data = []
        for doc_id, content in documents.items():
            # æˆªå–å‰100ä¸ªå­—ç¬¦ä½œä¸ºé¢„è§ˆ
            preview = content[:100] + "..." if len(content) > 100 else content
            data.append([doc_id, preview])
        
        return data
    except Exception as e:
        return [["é”™è¯¯", str(e)]]

def export_documents(search_engine):
    """å¯¼å‡ºæ‰€æœ‰æ–‡æ¡£åˆ°JSONæ–‡ä»¶"""
    try:
        documents = search_engine.get_all_documents()
        if not documents:
            return None, "âŒ æ²¡æœ‰æ–‡æ¡£å¯å¯¼å‡º"
        
        # ç”Ÿæˆå¯¼å‡ºæ–‡ä»¶å
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        export_filename = f"documents_export_{timestamp}.json"
        
        # å¯¼å‡ºæ–‡æ¡£æ•°æ®
        export_data = {
            "export_time": datetime.now().isoformat(),
            "total_documents": len(documents),
            "documents": documents
        }
        
        # å†™å…¥ä¸´æ—¶æ–‡ä»¶
        with tempfile.NamedTemporaryFile(delete=False, suffix=".json", mode="w", encoding="utf-8") as tmp:
            json.dump(export_data, tmp, ensure_ascii=False, indent=2)
            tmp_path = tmp.name
        
        return tmp_path, f"âœ… æ–‡æ¡£å¯¼å‡ºæˆåŠŸï¼\næ–‡æ¡£æ•°é‡: {len(documents)}\nç‚¹å‡»ä¸Šæ–¹ä¸‹è½½æŒ‰é’®è·å–æ–‡ä»¶"
    except Exception as e:
        return None, f"âŒ å¯¼å‡ºæ–‡æ¡£å¤±è´¥: {str(e)}"

def import_documents_from_file(search_engine, file):
    """ä»æ–‡ä»¶å¯¼å…¥æ–‡æ¡£å¹¶æ›´æ–°ç´¢å¼•"""
    try:
        if file is None:
            return "âŒ è¯·é€‰æ‹©è¦å¯¼å…¥çš„æ–‡ä»¶"
        
        # è¯»å–æ–‡ä»¶å†…å®¹
        with open(file.name, 'r', encoding='utf-8') as f:
            import_data = json.load(f)
        
        # éªŒè¯æ–‡ä»¶æ ¼å¼
        if "documents" not in import_data:
            return "âŒ æ–‡ä»¶æ ¼å¼é”™è¯¯ï¼šç¼ºå°‘ 'documents' å­—æ®µ"
        
        documents = import_data["documents"]
        if not isinstance(documents, dict):
            return "âŒ æ–‡ä»¶æ ¼å¼é”™è¯¯ï¼š'documents' åº”è¯¥æ˜¯å­—å…¸æ ¼å¼"
        
        if not documents:
            return "âŒ æ–‡ä»¶ä¸­æ²¡æœ‰æ–‡æ¡£æ•°æ®"
        
        # æ¸…ç©ºç°æœ‰ç´¢å¼•
        search_engine.clear_index()
        
        # æ‰¹é‡æ·»åŠ æ–°æ–‡æ¡£
        success_count = search_engine.batch_add_documents(documents)
        
        # ä¿å­˜æ›´æ–°åçš„ç´¢å¼•
        search_engine.save_index()
        
        return f"âœ… æ–‡æ¡£å¯¼å…¥æˆåŠŸï¼\nå¯¼å…¥æ–‡æ¡£æ•°: {success_count}\næ€»æ–‡æ¡£æ•°: {len(documents)}\n\nğŸ’¡ æç¤ºï¼šç°åœ¨å¯ä»¥åœ¨ã€ŒğŸ•¸ï¸ çŸ¥è¯†å›¾è°±ã€æ ‡ç­¾é¡µä¸­æ„å»ºçŸ¥è¯†å›¾è°±ï¼"
    except Exception as e:
        return f"âŒ å¯¼å…¥æ–‡æ¡£å¤±è´¥: {str(e)}"

def build_index_tab(search_engine):
    with gr.Blocks() as index_tab:
        gr.Markdown("""
        ### ğŸ—ï¸ ç¬¬ä¸€éƒ¨åˆ†ï¼šç¦»çº¿ç´¢å¼•æ„å»º
        """)
        
        with gr.Tabs():
            # ç´¢å¼•ä¿¡æ¯æ ‡ç­¾é¡µ
            with gr.Tab("ğŸ“Š ç´¢å¼•ä¿¡æ¯"):
                with gr.Row():
                    with gr.Column(scale=2):
                        index_stats_btn = gr.Button("ğŸ“Š æŸ¥çœ‹ç´¢å¼•ç»Ÿè®¡", variant="primary")
                        index_stats_output = gr.HTML(value="<p>ç‚¹å‡»æŒ‰é’®æŸ¥çœ‹ç´¢å¼•ç»Ÿè®¡ä¿¡æ¯...</p>", elem_id="index_stats_output")
                        index_quality_btn = gr.Button("ğŸ” ç´¢å¼•è´¨é‡æ£€æŸ¥", variant="secondary")
                        index_quality_output = gr.HTML(value="<p>ç‚¹å‡»æŒ‰é’®è¿›è¡Œç´¢å¼•è´¨é‡æ£€æŸ¥...</p>", elem_id="index_quality_output")
                        view_index_btn = gr.Button("ğŸ“– æŸ¥çœ‹å€’æ’ç´¢å¼•", variant="secondary")
                        view_index_output = gr.Dataframe(headers=["è¯é¡¹", "æ–‡æ¡£IDåˆ—è¡¨"], label="å€’æ’ç´¢å¼•ç‰‡æ®µ", interactive=False)
                    with gr.Column(scale=3):
                        gr.HTML("<p>ç´¢å¼•æ„å»ºè¯¦ç»†ä¿¡æ¯...</p>")
            
            # æ–‡æ¡£ç®¡ç†æ ‡ç­¾é¡µ
            with gr.Tab("ğŸ“„ æ–‡æ¡£ç®¡ç†"):
                with gr.Row():
                    with gr.Column(scale=1):
                        gr.Markdown("### ğŸ“‹ æ–‡æ¡£åˆ—è¡¨")
                        refresh_docs_btn = gr.Button("ğŸ”„ åˆ·æ–°æ–‡æ¡£åˆ—è¡¨", variant="primary")
                        docs_list = gr.Dataframe(
                            headers=["æ–‡æ¡£ID", "å†…å®¹é¢„è§ˆ"], 
                            label="æ‰€æœ‰æ–‡æ¡£", 
                            interactive=False,
                            wrap=True
                        )
                    
                    with gr.Column(scale=1):
                        gr.Markdown("### ğŸ“¤ å¯¼å‡ºæ–‡æ¡£")
                        gr.HTML("<p style='color: #6c757d;'>å¯¼å‡ºæ‰€æœ‰æ–‡æ¡£åˆ°JSONæ–‡ä»¶ï¼ŒåŒ…å«æ–‡æ¡£IDå’Œå†…å®¹</p>")
                        export_docs_btn = gr.Button("ğŸ“¤ å¯¼å‡ºæ‰€æœ‰æ–‡æ¡£", variant="primary")
                        export_download = gr.File(label="ä¸‹è½½æ–‡æ¡£æ–‡ä»¶", interactive=False)
                        export_result = gr.Textbox(label="å¯¼å‡ºç»“æœ", interactive=False)
                
                with gr.Row():
                    with gr.Column(scale=1):
                        gr.Markdown("### ğŸ“¥ å¯¼å…¥æ–‡æ¡£")
                        gr.HTML("<p style='color: #6c757d;'>ä¸Šä¼ JSONæ–‡ä»¶å¯¼å…¥æ–‡æ¡£ï¼Œå°†æ›¿æ¢ç°æœ‰ç´¢å¼•</p>")
                        import_file = gr.File(
                            label="é€‰æ‹©æ–‡æ¡£æ–‡ä»¶", 
                            file_types=[".json"],
                            file_count="single"
                        )
                        import_docs_btn = gr.Button("ğŸ“¥ å¯¼å…¥æ–‡æ¡£å¹¶æ›´æ–°ç´¢å¼•", variant="primary")
                        import_result = gr.Textbox(label="å¯¼å…¥ç»“æœ", interactive=False)
            
            # çŸ¥è¯†å›¾è°±æ ‡ç­¾é¡µ
            with gr.Tab("ğŸ•¸ï¸ çŸ¥è¯†å›¾è°±"):
                gr.Markdown("### ğŸ§  åŸºäºLLMçš„çŸ¥è¯†å›¾è°±æ„å»º")
                
                # ä½¿ç”¨è¯´æ˜
                gr.HTML("""
                <div style="background-color: #e8f5e8; padding: 15px; border-radius: 8px; border-left: 4px solid #28a745; margin-bottom: 20px;">
                    <h4 style="margin-top: 0; color: #155724;">ğŸ’¡ ä½¿ç”¨æŒ‡å—</h4>
                    <ol style="margin-bottom: 0;">
                        <li><strong>ç¬¬ä¸€æ­¥</strong>ï¼šåœ¨"ğŸ“„ æ–‡æ¡£ç®¡ç†"æ ‡ç­¾é¡µä¸­å¯¼å…¥æ–‡æ¡£</li>
                        <li><strong>ç¬¬äºŒæ­¥</strong>ï¼šè¿”å›æ­¤é¡µé¢ï¼Œç‚¹å‡»"ğŸ”¨ æ„å»ºçŸ¥è¯†å›¾è°±"å¼€å§‹æ„å»º</li>
                        <li><strong>ç¬¬ä¸‰æ­¥</strong>ï¼šç­‰å¾…NERå¤„ç†å®Œæˆï¼ˆçº¦2-5åˆ†é’Ÿï¼‰ï¼Œç³»ç»Ÿä¼šè‡ªåŠ¨ä¿å­˜å›¾è°±</li>
                        <li><strong>ç¬¬å››æ­¥</strong>ï¼šä½¿ç”¨"ğŸ” å®ä½“æœç´¢"æ‰¾åˆ°æ„Ÿå…´è¶£çš„å®ä½“</li>
                        <li><strong>ç¬¬äº”æ­¥</strong>ï¼šä½¿ç”¨"ğŸ”— å®ä½“å…³ç³»æŸ¥è¯¢"æŸ¥çœ‹å®ä½“çš„ç›¸å…³å®ä½“å’Œå…³ç³»</li>
                    </ol>
                </div>
                """)
                
                # å›¾è°±æ„å»ºéƒ¨åˆ†
                with gr.Row():
                    with gr.Column(scale=2):
                        gr.Markdown("#### ğŸ—ï¸ å›¾è°±æ„å»º")
                        
                        # APIé…ç½®ï¼ˆç¡¬ç¼–ç ï¼‰
                        gr.Markdown("**é…ç½®ä¿¡æ¯ï¼š** ä¼˜å…ˆä½¿ç”¨ qwen-plus (äº‘ç«¯)ï¼Œä¸å¯ç”¨æ—¶è‡ªåŠ¨åˆ‡æ¢åˆ° qwen2.5-coder:latest (æœ¬åœ°Ollama)")
                        
                        with gr.Row():
                            build_kg_btn = gr.Button("ğŸ”¨ æ„å»ºçŸ¥è¯†å›¾è°±", variant="primary")
                            rebuild_kg_btn = gr.Button("ğŸ”„ é‡å»ºçŸ¥è¯†å›¾è°±", variant="secondary")
                            clear_kg_btn = gr.Button("ğŸ—‘ï¸ æ¸…ç©ºå›¾è°±", variant="stop")
                        
                        # é‡å»ºç¡®è®¤å¯¹è¯æ¡†
                        gr.Markdown("#### âš ï¸ é‡å»ºé¡»çŸ¥")
                        gr.Markdown("""
                        **è¯·æ³¨æ„ï¼š**
                        - çŸ¥è¯†å›¾è°±ä¼šè‡ªåŠ¨ä¿å­˜åˆ°ç£ç›˜ (`models/knowledge_graph.pkl`)
                        - NERå¤„ç†å¾ˆè€—æ—¶ï¼Œé¢„è®¡éœ€è¦ **2-5åˆ†é’Ÿ** (å–å†³äºæ–‡æ¡£æ•°é‡å’Œæ¨¡å‹)
                        - é‡å»ºå°†**å®Œå…¨è¦†ç›–**ç°æœ‰å›¾è°±ï¼Œæ— æ³•æ¢å¤
                        - å»ºè®®åœ¨é‡å»ºå‰å…ˆå¯¼å‡ºç°æœ‰å›¾è°±ä½œä¸ºå¤‡ä»½
                        """)
                        
                        # é‡å»ºç¡®è®¤è¾“å…¥æ¡†
                        rebuild_confirm_input = gr.Textbox(
                            label="ç¡®è®¤é‡å»ºï¼šè¯·è¾“å…¥ 'CONFIRM' æ¥ç¡®è®¤é‡å»ºæ“ä½œ",
                            placeholder="è¾“å…¥ CONFIRM ç¡®è®¤é‡å»º",
                            visible=False
                        )
                        
                        # å®é™…é‡å»ºæŒ‰é’®
                        rebuild_confirm_btn = gr.Button(
                            "âš ï¸ ç¡®è®¤é‡å»ºçŸ¥è¯†å›¾è°±", 
                            variant="stop",
                            visible=False
                        )
                            
                        kg_build_status = gr.Textbox(
                            label="æ„å»ºçŠ¶æ€",
                            value="ç‚¹å‡»æŒ‰é’®å¼€å§‹æ„å»ºçŸ¥è¯†å›¾è°±",
                            lines=4,
                            interactive=False
                        )
                        
                    with gr.Column(scale=1):
                        gr.Markdown("#### ğŸ“Š å›¾è°±ç»Ÿè®¡")
                        kg_stats_display = gr.JSON(label="çŸ¥è¯†å›¾è°±ç»Ÿè®¡")
                        refresh_kg_stats_btn = gr.Button("ğŸ“Š åˆ·æ–°ç»Ÿè®¡", variant="secondary")
                
                # å®ä½“æœç´¢å’ŒæŸ¥è¯¢
                with gr.Row():
                    with gr.Column():
                        gr.Markdown("#### ğŸ” å®ä½“æœç´¢")
                        
                        with gr.Row():
                            entity_search_query = gr.Textbox(
                                label="æœç´¢å®ä½“",
                                placeholder="è¾“å…¥å®ä½“åç§°æˆ–å…³é”®è¯"
                            )
                            entity_search_btn = gr.Button("ğŸ” æœç´¢å®ä½“", variant="primary")
                            
                        entity_search_results = gr.Dataframe(
                            headers=["å®ä½“åç§°", "ç±»å‹", "æè¿°", "æ–‡æ¡£æ•°é‡", "åˆ†æ•°"],
                            label="æœç´¢ç»“æœ",
                            interactive=False
                        )
                
                # å®ä½“å…³ç³»æŸ¥è¯¢
                with gr.Row():
                    with gr.Column():
                        gr.Markdown("#### ğŸ”— å®ä½“å…³ç³»æŸ¥è¯¢")
                        
                        with gr.Row():
                            entity_query_input = gr.Textbox(
                                label="æŸ¥è¯¢å®ä½“",
                                placeholder="è¾“å…¥è¦æŸ¥è¯¢çš„å®ä½“åç§°"
                            )
                            entity_query_btn = gr.Button("ğŸ”— æŸ¥è¯¢å…³ç³»", variant="primary")
                            
                        entity_query_results = gr.JSON(
                            label="å®ä½“å…³ç³»ä¿¡æ¯"
                        )
                
                # å›¾è°±å¯¼å‡º
                with gr.Row():
                    with gr.Column():
                        gr.Markdown("#### ğŸ’¾ å›¾è°±å¯¼å‡º")
                        
                        with gr.Row():
                            export_kg_btn = gr.Button("ğŸ’¾ å¯¼å‡ºçŸ¥è¯†å›¾è°±", variant="secondary")
                            
                        kg_export_download = gr.File(label="ä¸‹è½½çŸ¥è¯†å›¾è°±æ–‡ä»¶", interactive=False)
                        kg_export_status = gr.Textbox(
                            label="å¯¼å‡ºçŠ¶æ€",
                            value="ç‚¹å‡»æŒ‰é’®å¯¼å‡ºçŸ¥è¯†å›¾è°±",
                            lines=2,
                            interactive=False
                        )
        
        # ç»‘å®šäº‹ä»¶
        # ç´¢å¼•ä¿¡æ¯ç›¸å…³
        index_stats_btn.click(
            fn=lambda: show_index_stats(search_engine), 
            outputs=index_stats_output
        )
        index_quality_btn.click(
            fn=lambda: check_index_quality(search_engine), 
            outputs=index_quality_output
        )
        view_index_btn.click(
            fn=lambda: view_inverted_index(search_engine), 
            outputs=view_index_output
        )
        
        # æ–‡æ¡£ç®¡ç†ç›¸å…³
        refresh_docs_btn.click(
            fn=lambda: get_all_documents(search_engine),
            outputs=docs_list
        )
        
        export_docs_btn.click(
            fn=lambda: export_documents(search_engine),
            outputs=[export_download, export_result]
        )
        
        import_docs_btn.click(
            fn=lambda file: import_documents_from_file(search_engine, file),
            inputs=import_file,
            outputs=import_result
        )
        
        # çŸ¥è¯†å›¾è°±ç›¸å…³äº‹ä»¶
        # çŸ¥è¯†å›¾è°±æ„å»ºå‡½æ•°ï¼ˆç¡¬ç¼–ç æ¨¡å‹é€‰æ‹©ï¼‰
        def build_knowledge_graph():
            try:
                # ç¡¬ç¼–ç é…ç½®ï¼šä¼˜å…ˆä½¿ç”¨ qwen-plusï¼Œå¤±è´¥åˆ™ä½¿ç”¨ ollama
                
                # è·å–æ–‡æ¡£ç»Ÿè®¡ä¿¡æ¯
                doc_stats = search_engine.get_stats()
                doc_count = doc_stats.get('total_documents', 0)
                
                status_msg = f"ğŸ”„ å¼€å§‹æ„å»ºçŸ¥è¯†å›¾è°±...\n"
                status_msg += f"ğŸ“Š æ–‡æ¡£æ•°é‡: {doc_count}\n"
                status_msg += f"ğŸ”§ å°è¯•ä½¿ç”¨ qwen-plus (äº‘ç«¯)ï¼Œå¤±è´¥æ—¶è‡ªåŠ¨åˆ‡æ¢åˆ° qwen2.5-coder:latest (æœ¬åœ°)\n"
                estimated_time = doc_count * 20  # æ¯ä¸ªæ–‡æ¡£çº¦20ç§’
                status_msg += f"â±ï¸ é¢„è®¡æ—¶é—´: {estimated_time}ç§’ (æ¯ä¸ªæ–‡æ¡£çº¦10-30ç§’)\n"
                status_msg += f"ğŸ“ æ­£åœ¨è¿›è¡ŒNERå¤„ç†ï¼Œè¯·è€å¿ƒç­‰å¾…...\n"
                
                # å…ˆå°è¯• qwen-plus
                try:
                    search_engine.set_ner_api_config(
                        api_type="openai",
                        base_url="https://dashscope.aliyuncs.com/compatible-mode/v1",
                        default_model="qwen-plus"
                    )
                    result = search_engine.build_knowledge_graph("qwen-plus")
                    if "error" not in result:
                        success_msg = f"âœ… {result['message']} (ä½¿ç”¨ qwen-plus)\n"
                        success_msg += f"â±ï¸ å®é™…æ„å»ºæ—¶é—´: {result['build_time']:.2f}ç§’\n"
                        success_msg += f"ğŸ’¾ å›¾è°±å·²è‡ªåŠ¨ä¿å­˜åˆ° models/knowledge_graph.pkl"
                        return success_msg
                except Exception as e:
                    print(f"qwen-plus failed: {e}")
                
                # qwen-plus å¤±è´¥ï¼Œä½¿ç”¨æœ¬åœ° ollama
                search_engine.set_ner_api_config(
                    api_type="ollama",
                    default_model="qwen2.5-coder:latest"
                )
                result = search_engine.build_knowledge_graph("qwen2.5-coder:latest")
                if "error" in result:
                    return f"âŒ {result['error']}"
                else:
                    success_msg = f"âœ… {result['message']} (ä½¿ç”¨ qwen2.5-coder:latest)\n"
                    success_msg += f"â±ï¸ å®é™…æ„å»ºæ—¶é—´: {result['build_time']:.2f}ç§’\n"
                    success_msg += f"ğŸ’¾ å›¾è°±å·²è‡ªåŠ¨ä¿å­˜åˆ° models/knowledge_graph.pkl"
                    return success_msg
            except Exception as e:
                return f"âŒ æ„å»ºçŸ¥è¯†å›¾è°±å¤±è´¥: {str(e)}"
        
        def show_rebuild_confirm():
            """æ˜¾ç¤ºé‡å»ºç¡®è®¤ç•Œé¢"""
            return gr.update(visible=True), gr.update(visible=True), "è¯·åœ¨ä¸‹æ–¹è¾“å…¥ 'CONFIRM' ç¡®è®¤é‡å»ºæ“ä½œ"
        
        def rebuild_knowledge_graph(confirm_text):
            """é‡å»ºçŸ¥è¯†å›¾è°±ï¼ˆéœ€è¦ç¡®è®¤ï¼Œç¡¬ç¼–ç æ¨¡å‹é€‰æ‹©ï¼‰"""
            if confirm_text.strip().upper() != "CONFIRM":
                return "âŒ è¯·è¾“å…¥ 'CONFIRM' ç¡®è®¤é‡å»ºæ“ä½œ", gr.update(visible=False), gr.update(visible=False)
            
            try:
                # è·å–å½“å‰å›¾è°±çŠ¶æ€
                current_stats = search_engine.get_knowledge_graph_stats()
                
                status_msg = f"ğŸ”„ å¼€å§‹é‡å»ºçŸ¥è¯†å›¾è°±...\n"
                status_msg += f"âš ï¸ å½“å‰å›¾è°±: {current_stats.get('entity_count', 0)} ä¸ªå®ä½“, {current_stats.get('relation_count', 0)} æ¡å…³ç³»\n"
                status_msg += f"ğŸ”§ å°è¯•ä½¿ç”¨ qwen-plus (äº‘ç«¯)ï¼Œå¤±è´¥æ—¶è‡ªåŠ¨åˆ‡æ¢åˆ° qwen2.5-coder:latest (æœ¬åœ°)\n"
                status_msg += f"ğŸ“ æ­£åœ¨è¿›è¡ŒNERå¤„ç†ï¼Œé¢„è®¡éœ€è¦2-5åˆ†é’Ÿï¼Œè¯·è€å¿ƒç­‰å¾…...\n"
                
                # å…ˆå°è¯• qwen-plus
                try:
                    search_engine.set_ner_api_config(
                        api_type="openai",
                        base_url="https://dashscope.aliyuncs.com/compatible-mode/v1",
                        default_model="qwen-plus"
                    )
                    result = search_engine.rebuild_knowledge_graph("qwen-plus")
                    if "error" not in result:
                        success_msg = f"âœ… {result['message']} (ä½¿ç”¨ qwen-plus)\nâ±ï¸ é‡å»ºæ—¶é—´: {result['build_time']:.2f}ç§’\n"
                        success_msg += f"ğŸ’¾ å›¾è°±å·²è‡ªåŠ¨ä¿å­˜åˆ°ç£ç›˜"
                        return success_msg, gr.update(visible=False), gr.update(visible=False)
                except Exception as e:
                    print(f"qwen-plus rebuild failed: {e}")
                
                # qwen-plus å¤±è´¥ï¼Œä½¿ç”¨æœ¬åœ° ollama
                search_engine.set_ner_api_config(
                    api_type="ollama",
                    default_model="qwen2.5-coder:latest"
                )
                result = search_engine.rebuild_knowledge_graph("qwen2.5-coder:latest")
                if "error" in result:
                    return f"âŒ {result['error']}", gr.update(visible=False), gr.update(visible=False)
                else:
                    success_msg = f"âœ… {result['message']} (ä½¿ç”¨ qwen2.5-coder:latest)\nâ±ï¸ é‡å»ºæ—¶é—´: {result['build_time']:.2f}ç§’\n"
                    success_msg += f"ğŸ’¾ å›¾è°±å·²è‡ªåŠ¨ä¿å­˜åˆ°ç£ç›˜"
                    return success_msg, gr.update(visible=False), gr.update(visible=False)
            except Exception as e:
                return f"âŒ é‡å»ºçŸ¥è¯†å›¾è°±å¤±è´¥: {str(e)}", gr.update(visible=False), gr.update(visible=False)
        
        def clear_knowledge_graph():
            try:
                result = search_engine.clear_knowledge_graph()
                return f"âœ… {result}"
            except Exception as e:
                return f"âŒ æ¸…ç©ºçŸ¥è¯†å›¾è°±å¤±è´¥: {str(e)}"
        
        def refresh_kg_stats():
            try:
                stats = search_engine.get_knowledge_graph_stats()
                
                # æ·»åŠ æŒä¹…åŒ–çŠ¶æ€ä¿¡æ¯
                import os
                graph_file = "models/knowledge_graph.pkl"
                if os.path.exists(graph_file):
                    file_stats = os.stat(graph_file)
                    stats["persistence"] = {
                        "file_exists": True,
                        "file_path": graph_file,
                        "file_size_mb": round(file_stats.st_size / (1024*1024), 2),
                        "last_modified": datetime.fromtimestamp(file_stats.st_mtime).strftime('%Y-%m-%d %H:%M:%S')
                    }
                else:
                    stats["persistence"] = {
                        "file_exists": False,
                        "file_path": graph_file,
                        "message": "çŸ¥è¯†å›¾è°±æ–‡ä»¶ä¸å­˜åœ¨ï¼Œéœ€è¦å…ˆæ„å»º"
                    }
                
                return stats
            except Exception as e:
                return {"error": str(e)}
        
        def search_entities(query):
            if not query:
                return []
            
            try:
                results = search_engine.search_entities(query, limit=10)
                table_data = []
                for entity in results:
                    table_data.append([
                        entity.get("entity", ""),
                        entity.get("type", ""),
                        entity.get("description", "")[:100] + "..." if len(entity.get("description", "")) > 100 else entity.get("description", ""),
                        entity.get("doc_count", 0),
                        f"{entity.get('score', 0):.4f}"
                    ])
                return table_data
            except Exception as e:
                return [["é”™è¯¯", "N/A", str(e), "0", "0"]]
        
        def query_entity_relations(entity_name):
            if not entity_name:
                return {}
            
            try:
                results = search_engine.query_entity_relations(entity_name)
                return results
            except Exception as e:
                return {"error": str(e)}
        
        def export_knowledge_graph():
            try:
                filepath, message = search_engine.export_knowledge_graph()
                if filepath:
                    return gr.File(value=filepath, interactive=False), message
                else:
                    return None, message
            except Exception as e:
                return None, f"âŒ å¯¼å‡ºçŸ¥è¯†å›¾è°±å¤±è´¥: {str(e)}"
        
        # ç»‘å®šçŸ¥è¯†å›¾è°±äº‹ä»¶
        build_kg_btn.click(
            fn=build_knowledge_graph,
            outputs=kg_build_status
        )
        

        
        # é‡å»ºçŸ¥è¯†å›¾è°± - åˆ†ä¸¤æ­¥ï¼šå…ˆæ˜¾ç¤ºç¡®è®¤ï¼Œåæ‰§è¡Œé‡å»º
        rebuild_kg_btn.click(
            fn=show_rebuild_confirm,
            outputs=[rebuild_confirm_input, rebuild_confirm_btn, kg_build_status]
        )
        
        rebuild_confirm_btn.click(
            fn=rebuild_knowledge_graph,
            inputs=rebuild_confirm_input,
            outputs=[kg_build_status, rebuild_confirm_input, rebuild_confirm_btn]
        )
        
        clear_kg_btn.click(
            fn=clear_knowledge_graph,
            outputs=kg_build_status
        )
        
        refresh_kg_stats_btn.click(
            fn=refresh_kg_stats,
            outputs=kg_stats_display
        )
        
        entity_search_btn.click(
            fn=search_entities,
            inputs=entity_search_query,
            outputs=entity_search_results
        )

        entity_query_btn.click(
            fn=query_entity_relations,
            inputs=entity_query_input,
            outputs=entity_query_results
        )
        
        export_kg_btn.click(
            fn=export_knowledge_graph,
            outputs=[kg_export_download, kg_export_status]
        )
        
        # é¡µé¢åŠ è½½æ—¶è‡ªåŠ¨åˆ·æ–°æ–‡æ¡£åˆ—è¡¨å’ŒçŸ¥è¯†å›¾è°±ç»Ÿè®¡
        index_tab.load(
            fn=lambda: get_all_documents(search_engine),
            outputs=docs_list
        )
        
        index_tab.load(
            fn=refresh_kg_stats,
            outputs=kg_stats_display
        )
    
    return index_tab 