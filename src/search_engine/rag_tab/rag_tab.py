#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
RAGæ ‡ç­¾é¡µUIå®ç°
"""

import gradio as gr
import json
from typing import Dict, Any, Tuple, List
from .rag_service import RAGService

def build_rag_tab(index_service):
    """æ„å»ºRAGæ ‡ç­¾é¡µ"""
    
    # åˆå§‹åŒ–RAGæœåŠ¡
    rag_service = RAGService(index_service)
    
    with gr.Column():
        gr.Markdown("""
        # ğŸ¤– RAGé—®ç­”ç³»ç»Ÿ (æ£€ç´¢å¢å¼ºç”Ÿæˆ)
        
        åŸºäºç°æœ‰å€’æ’ç´¢å¼•å’ŒTF-IDFçš„æ£€ç´¢å¢å¼ºç”Ÿæˆç³»ç»Ÿï¼Œä½¿ç”¨Ollamaè¿›è¡Œæ–‡æœ¬ç”Ÿæˆã€‚
        """)
        
        # 1. è¿æ¥çŠ¶æ€æ£€æŸ¥
        with gr.Row():
            check_connection_btn = gr.Button("ğŸ” æ£€æŸ¥Ollamaè¿æ¥", variant="secondary")
            connection_status = gr.Textbox(
                label="è¿æ¥çŠ¶æ€",
                value="ç‚¹å‡»æ£€æŸ¥è¿æ¥çŠ¶æ€",
                interactive=False
            )
        
        # 2. æŸ¥è¯¢ç•Œé¢
        with gr.Row():
            with gr.Column(scale=2):
                query_input = gr.Textbox(
                    label="è¾“å…¥æ‚¨çš„é—®é¢˜",
                    placeholder="ä¾‹å¦‚ï¼šä»€ä¹ˆæ˜¯æœºå™¨å­¦ä¹ ï¼Ÿ",
                    lines=2
                )
                
                with gr.Row():
                    top_k_slider = gr.Slider(
                        minimum=1,
                        maximum=10,
                        value=5,
                        step=1,
                        label="æ£€ç´¢æ–‡æ¡£æ•°é‡"
                    )
                    
                    model_dropdown = gr.Dropdown(
                        choices=["llama3.1:8b", "llama3.2:1b", "qwen2.5:7b"],
                        value="llama3.1:8b",
                        label="é€‰æ‹©æ¨¡å‹"
                    )
                
                rag_query_btn = gr.Button("ğŸš€ RAGæŸ¥è¯¢", variant="primary")
                
            with gr.Column(scale=1):
                gr.Markdown("### ğŸ“Š ç³»ç»ŸçŠ¶æ€")
                stats_display = gr.JSON(label="RAGæœåŠ¡çŠ¶æ€")
        
        # 3. ç»“æœå±•ç¤º
        with gr.Row():
            with gr.Column():
                gr.Markdown("### ğŸ“ ç”Ÿæˆå›ç­”")
                answer_output = gr.Textbox(
                    label="å›ç­”",
                    lines=10,
                    max_lines=15,
                    interactive=False,
                    show_copy_button=True
                )
                
                processing_info = gr.Textbox(
                    label="å¤„ç†ä¿¡æ¯",
                    lines=2,
                    interactive=False
                )
        
        # 4. æç¤ºè¯å±•ç¤º
        with gr.Row():
            with gr.Column():
                gr.Markdown("### ğŸ“ å‘é€ç»™LLMçš„æç¤ºè¯")
                prompt_display = gr.Textbox(
                    label="å®Œæ•´æç¤ºè¯",
                    lines=20,
                    max_lines=30,
                    interactive=False,
                    placeholder="æ‰§è¡ŒRAGæŸ¥è¯¢åï¼Œè¿™é‡Œå°†æ˜¾ç¤ºå‘é€ç»™LLMçš„å®Œæ•´æç¤ºè¯",
                    show_copy_button=True,
                    autoscroll=False
                )
        
        # 5. æ£€ç´¢è¯¦æƒ…
        with gr.Row():
            with gr.Column():
                gr.Markdown("### ğŸ” æ£€ç´¢ç»“æœè¯¦æƒ…")
                retrieved_docs = gr.DataFrame(
                    headers=["æ–‡æ¡£ID", "ç›¸å…³åº¦åˆ†æ•°", "æ–‡æ¡£å†…å®¹"],
                    label="æ£€ç´¢åˆ°çš„æ–‡æ¡£",
                    interactive=False
                )
                
                context_output = gr.Textbox(
                    label="æ„å»ºçš„ä¸Šä¸‹æ–‡",
                    lines=12,
                    max_lines=20,
                    interactive=False,
                    show_copy_button=True
                )
    
    # äº‹ä»¶å¤„ç†å‡½æ•°
    def check_connection():
        """æ£€æŸ¥Ollamaè¿æ¥"""
        connected, status = rag_service.check_ollama_connection()
        return status
    
    def refresh_model_list():
        """åˆ·æ–°æ¨¡å‹åˆ—è¡¨"""
        models = rag_service.get_available_models()
        return gr.Dropdown(choices=models, value=models[0] if models else "llama3.1:8b")
    
    def get_rag_stats():
        """è·å–RAGæœåŠ¡ç»Ÿè®¡ä¿¡æ¯"""
        return rag_service.get_stats()
    
    def process_rag_query(query: str, top_k: int, model: str):
        """å¤„ç†RAGæŸ¥è¯¢"""
        if not query.strip():
            return (
                "è¯·è¾“å…¥æ‚¨çš„é—®é¢˜",
                "æœªå¤„ç†",
                [],
                "",
                ""
            )
        
        # æ‰§è¡ŒRAGæŸ¥è¯¢
        result = rag_service.rag_query(query, top_k, model)
        
        # æ„å»ºæ£€ç´¢ç»“æœè¡¨æ ¼
        retrieved_table = []
        for doc_id, score, content in result.get("retrieved_docs", []):
            # æˆªæ–­å†…å®¹ä»¥é€‚åº”è¡¨æ ¼æ˜¾ç¤º
            truncated_content = content[:100] + "..." if len(content) > 100 else content
            retrieved_table.append([doc_id, f"{score:.4f}", truncated_content])
        
        # æ„å»ºå¤„ç†ä¿¡æ¯
        processing_info = f"""å¤„ç†æ—¶é—´: {result.get('processing_time', 0):.2f}ç§’
ä½¿ç”¨æ¨¡å‹: {result.get('model_used', 'unknown')}
æ£€ç´¢æ–‡æ¡£æ•°: {len(result.get('retrieved_docs', []))}"""
        
        return (
            result.get("answer", "ç”Ÿæˆå›ç­”å¤±è´¥"),
            processing_info,
            retrieved_table,
            result.get("context", ""),
            result.get("prompt_sent", "")
        )
    
    # ç»‘å®šäº‹ä»¶
    check_connection_btn.click(
        fn=check_connection,
        outputs=[connection_status]
    )
    
    rag_query_btn.click(
        fn=process_rag_query,
        inputs=[query_input, top_k_slider, model_dropdown],
        outputs=[answer_output, processing_info, retrieved_docs, context_output, prompt_display]
    )
    
    # é¡µé¢åŠ è½½æ—¶è·å–ç»Ÿè®¡ä¿¡æ¯
    stats_display.value = get_rag_stats()
    
    # å®šæœŸåˆ·æ–°æ¨¡å‹åˆ—è¡¨
    check_connection_btn.click(
        fn=refresh_model_list,
        outputs=[model_dropdown]
    )
    
    return gr.Column() 