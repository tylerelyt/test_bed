import threading
import uuid
from datetime import datetime
from typing import List, Dict, Any, Optional
import pandas as pd
import jieba
from .training_tab.ctr_config import CTRSampleConfig
from abc import ABC, abstractmethod
import time
import asyncio
from concurrent.futures import ThreadPoolExecutor


class DataServiceInterface(ABC):
    """æ•°æ®æœåŠ¡æ¥å£ - å®šä¹‰æ ‡å‡†çš„æ•°æ®è®¿é—®æ–¹æ³•"""
    
    @abstractmethod
    def record_impression(self, query: str, doc_id: str, position: int, 
                         score: float, summary: str, request_id: str) -> Dict[str, Any]:
        """è®°å½•å±•ç¤ºäº‹ä»¶"""
        pass
    
    @abstractmethod
    def record_click(self, doc_id: str, request_id: str) -> bool:
        """è®°å½•ç‚¹å‡»äº‹ä»¶"""
        pass
    
    @abstractmethod
    def get_all_samples(self) -> List[Dict[str, Any]]:
        """è·å–æ‰€æœ‰CTRæ ·æœ¬"""
        pass
    
    @abstractmethod
    def get_stats(self) -> Dict[str, Any]:
        """è·å–æ•°æ®ç»Ÿè®¡ä¿¡æ¯"""
        pass


class DataService(DataServiceInterface):
    """æ•°æ®æœåŠ¡ï¼šè´Ÿè´£CTRäº‹ä»¶æ”¶é›†ã€æ ·æœ¬çŠ¶æ€ç®¡ç†å’Œæ•°æ®è¯»å†™æ“ä½œ
    
    è®¾è®¡è¯´æ˜ï¼š
    - ä½ç½®ï¼šæœåŠ¡å±‚ (Service Layer)
    - èŒè´£ï¼šç»Ÿä¸€ç®¡ç†CTRæ•°æ®ï¼Œæä¾›çº¿ç¨‹å®‰å…¨çš„æ•°æ®è®¿é—®æ¥å£
    - ä½¿ç”¨ï¼šè¢«å¤šä¸ªä¸šåŠ¡æ¨¡å—è°ƒç”¨ï¼Œç¬¦åˆåˆ†å±‚æ¶æ„åŸåˆ™
    - æ•°æ®å­˜å‚¨ï¼šmodels/ctr_data.json (ä¸æ¨¡å‹æ–‡ä»¶æ”¾åœ¨ä¸€èµ·ä¾¿äºç®¡ç†)
    
    ä¼˜åŒ–ç‰¹æ€§ï¼š
    - æ‰¹é‡ä¿å­˜ï¼šå‡å°‘é¢‘ç¹çš„æ–‡ä»¶IOæ“ä½œ
    - å»¶è¿Ÿä¿å­˜ï¼šå¼‚æ­¥ä¿å­˜æ•°æ®ï¼Œä¸é˜»å¡ä¸»çº¿ç¨‹
    - æ•°æ®ç¼“å­˜ï¼šå†…å­˜ç¼“å­˜æé«˜è®¿é—®é€Ÿåº¦
    """
    
    def __init__(self, auto_save_interval: int = 30, batch_size: int = 100, model_service=None):
        self.ctr_data: List[Dict[str, Any]] = []
        self.lock = threading.Lock()
        self.data_file = "models/ctr_data.json"
        
        # ä¼˜åŒ–å‚æ•°
        self.auto_save_interval = auto_save_interval  # è‡ªåŠ¨ä¿å­˜é—´éš”ï¼ˆç§’ï¼‰
        self.batch_size = batch_size  # æ‰¹é‡ä¿å­˜å¤§å°
        self.pending_changes = 0  # å¾…ä¿å­˜çš„å˜æ›´æ•°é‡
        self.last_save_time = time.time()
        
        # å¼‚æ­¥ä¿å­˜ç›¸å…³
        self.save_executor = ThreadPoolExecutor(max_workers=1, thread_name_prefix="DataSaver")
        self.is_saving = False
        
        # æ•°æ®ç¼“å­˜
        self._stats_cache = None
        self._stats_cache_time = 0
        self._cache_ttl = 10  # ç¼“å­˜TTLï¼ˆç§’ï¼‰
        
        # åœ¨çº¿å­¦ä¹ ç›¸å…³
        self.model_service = model_service  # æ¨¡å‹æœåŠ¡å¼•ç”¨
        self.last_training_data_count = 0  # ä¸Šæ¬¡è®­ç»ƒæ—¶çš„æ•°æ®é‡
        self.online_training_trigger_threshold = 10  # æ¯æ–°å¢Næ¡æ•°æ®è§¦å‘ä¸€æ¬¡åœ¨çº¿è®­ç»ƒ
        
        self._load_existing_data()
        self.last_training_data_count = len(self.ctr_data)  # åˆå§‹åŒ–è®­ç»ƒæ•°æ®è®¡æ•°
        self._start_auto_save_timer()
    
    def _start_auto_save_timer(self):
        """å¯åŠ¨è‡ªåŠ¨ä¿å­˜å®šæ—¶å™¨"""
        def auto_save():
            while True:
                time.sleep(self.auto_save_interval)
                if self.pending_changes > 0:
                    self._save_data_async()
        
        timer_thread = threading.Thread(target=auto_save, daemon=True)
        timer_thread.start()
    
    def _should_save_now(self) -> bool:
        """åˆ¤æ–­æ˜¯å¦åº”è¯¥ç«‹å³ä¿å­˜"""
        return (
            self.pending_changes >= self.batch_size or
            time.time() - self.last_save_time > self.auto_save_interval
        )
    
    def _save_data_async(self):
        """å¼‚æ­¥ä¿å­˜æ•°æ®"""
        if self.is_saving:
            return
        
        self.is_saving = True
        self.save_executor.submit(self._save_data_sync)
    
    def _save_data_sync(self):
        """åŒæ­¥ä¿å­˜æ•°æ®åˆ°æ–‡ä»¶"""
        try:
            import json
            import os
            
            with self.lock:
                data_to_save = self.ctr_data.copy()
                self.pending_changes = 0
                self.last_save_time = time.time()
            
            # ç¡®ä¿ç›®å½•å­˜åœ¨
            os.makedirs(os.path.dirname(self.data_file), exist_ok=True)
            
            # å†™å…¥ä¸´æ—¶æ–‡ä»¶ï¼Œç„¶ååŸå­æ€§æ›¿æ¢
            temp_file = self.data_file + ".tmp"
            with open(temp_file, 'w', encoding='utf-8') as f:
                json.dump(data_to_save, f, ensure_ascii=False, indent=2)
            
            # åŸå­æ€§æ›¿æ¢
            os.replace(temp_file, self.data_file)
            
            print(f"âœ… æ•°æ®ä¿å­˜æˆåŠŸ: {len(data_to_save)}æ¡è®°å½•")
            
        except Exception as e:
            print(f"âš ï¸ ä¿å­˜CTRæ•°æ®å¤±è´¥: {e}")
        finally:
            self.is_saving = False
    
    def _invalidate_cache(self):
        """æ¸…é™¤ç¼“å­˜"""
        self._stats_cache = None
        self._stats_cache_time = 0
    
    def _load_existing_data(self):
        """åŠ è½½å·²å­˜åœ¨çš„CTRæ•°æ®"""
        try:
            import json
            import os
            if os.path.exists(self.data_file):
                with open(self.data_file, 'r', encoding='utf-8') as f:
                    self.ctr_data = json.load(f)
                print(f"âœ… åŠ è½½CTRæ•°æ®æˆåŠŸï¼Œå…±{len(self.ctr_data)}æ¡è®°å½•")
        except Exception as e:
            print(f"âš ï¸ åŠ è½½CTRæ•°æ®å¤±è´¥: {e}")
            self.ctr_data = []
    
    def record_impression(self, query: str, doc_id: str, position: int, 
                         score: float, summary: str, request_id: str) -> Dict[str, Any]:
        """è®°å½•å±•ç¤ºäº‹ä»¶"""
        with self.lock:
            try:
                # ä½¿ç”¨å†…éƒ¨æ–¹æ³•åˆ›å»ºæ ·æœ¬
                sample = self._create_sample(query, doc_id, position, score, summary, request_id)
                
                # æ£€æŸ¥é‡å¤è®°å½•
                duplicate_count = sum(1 for d in self.ctr_data 
                                    if d.get('request_id') == request_id.strip() and 
                                       d.get('doc_id') == doc_id.strip() and 
                                       d.get('position') == position)
                
                if duplicate_count > 0:
                    print(f"âš ï¸ å‘ç°é‡å¤è®°å½•: request_id={request_id}, doc_id={doc_id}, position={position}")
                
                self.ctr_data.append(sample)
                self.pending_changes += 1
                self._invalidate_cache()  # æ–°å¢æ•°æ®æ—¶æ¸…é™¤ç¼“å­˜
                
                if self._should_save_now():
                    self._save_data_async()
                
                return sample
                
            except Exception as e:
                print(f"âŒ è®°å½•å±•ç¤ºäº‹ä»¶å¤±è´¥: {e}")
                raise
    
    def record_click(self, doc_id: str, request_id: str) -> bool:
        """è®°å½•ç‚¹å‡»äº‹ä»¶"""
        # æ•°æ®éªŒè¯
        if not doc_id or not doc_id.strip():
            raise ValueError("æ–‡æ¡£IDä¸èƒ½ä¸ºç©º")
        
        if not request_id or not request_id.strip():
            raise ValueError("è¯·æ±‚IDä¸èƒ½ä¸ºç©º")
        
        with self.lock:
            try:
                updated_count = 0
                doc_id_clean = doc_id.strip()
                request_id_clean = request_id.strip()
                
                for sample in self.ctr_data:
                    if (sample.get('request_id') == request_id_clean and 
                        sample.get('doc_id') == doc_id_clean):
                        # è®°å½•ç‚¹å‡»äº‹ä»¶ - ä¸åŒæ¬¡ç‚¹å‡»ä½œä¸ºç‹¬ç«‹äº‹ä»¶
                        if sample.get('clicked', 0) == 0:
                            # é¦–æ¬¡ç‚¹å‡»
                            sample['clicked'] = 1
                            sample['click_time'] = datetime.now().isoformat()
                            sample['click_count'] = 1
                            updated_count += 1
                            print(f"âœ… é¦–æ¬¡ç‚¹å‡»: doc_id={doc_id_clean}, request_id={request_id_clean}")
                        else:
                            # å¤šæ¬¡ç‚¹å‡»ï¼Œé€’å¢ç‚¹å‡»è®¡æ•°
                            sample['click_count'] = sample.get('click_count', 1) + 1
                            sample['last_click_time'] = datetime.now().isoformat()
                            updated_count += 1
                            print(f"âœ… å¤šæ¬¡ç‚¹å‡»: doc_id={doc_id_clean}, request_id={request_id_clean}, æ€»è®¡ç‚¹å‡»{sample['click_count']}æ¬¡")
                
                if updated_count > 0:
                    self.pending_changes += updated_count
                    self._invalidate_cache()  # æ›´æ–°æ•°æ®æ—¶æ¸…é™¤ç¼“å­˜
                    if self._should_save_now():
                        self._save_data_async()
                    print(f"âœ… è®°å½•ç‚¹å‡»äº‹ä»¶æˆåŠŸ: doc_id={doc_id_clean}, request_id={request_id_clean}, æ›´æ–°{updated_count}æ¡è®°å½•")
                    
                    # ä¸´æ—¶ç¦ç”¨åœ¨çº¿è®­ç»ƒè§¦å‘ï¼Œæ’æŸ¥ segmentation fault
                    # TODO: é‡æ–°å¯ç”¨åéœ€è¦è°ƒè¯• threading + scikit-learn çš„å…¼å®¹æ€§
                    # æ£€æŸ¥æ˜¯å¦éœ€è¦è§¦å‘åœ¨çº¿è®­ç»ƒï¼ˆé‡Šæ”¾é”åæ‰§è¡Œï¼‰
                    # should_trigger = self._should_trigger_online_training()
                    # 
                    # # é‡Šæ”¾é”
                    # if should_trigger:
                    #     # åœ¨é”å¤–æ‰§è¡Œè®­ç»ƒï¼Œé¿å…æ­»é”
                    #     threading.Thread(target=self._trigger_online_training_async, daemon=True).start()
                    
                    return True
                else:
                    print(f"âš ï¸ æœªæ‰¾åˆ°åŒ¹é…çš„CTRæ ·æœ¬: doc_id={doc_id_clean}, request_id={request_id_clean}")
                    return False
                    
            except Exception as e:
                print(f"âŒ è®°å½•ç‚¹å‡»äº‹ä»¶å¤±è´¥: {e}")
                raise
    
    def get_samples_by_request(self, request_id: str) -> List[Dict[str, Any]]:
        """è·å–æŒ‡å®šè¯·æ±‚çš„CTRæ ·æœ¬"""
        with self.lock:
            return [sample for sample in self.ctr_data if sample.get('request_id') == request_id]
    
    def get_all_samples(self) -> List[Dict[str, Any]]:
        """è·å–æ‰€æœ‰CTRæ ·æœ¬"""
        with self.lock:
            return self.ctr_data.copy()
    
    def get_samples_dataframe(self, request_id: Optional[str] = None) -> pd.DataFrame:
        """è·å–CTRæ ·æœ¬DataFrame"""
        with self.lock:
            if request_id:
                samples = [sample for sample in self.ctr_data if sample.get('request_id') == request_id]
            else:
                samples = self.ctr_data
            
            if not samples:
                return pd.DataFrame()
            
            df = pd.DataFrame(samples)
            
            # ç¡®ä¿DataFrameåŒ…å«æ‰€æœ‰é…ç½®çš„åˆ—
            expected_columns = CTRSampleConfig.get_field_names()
            missing_columns = [col for col in expected_columns if col not in df.columns]
            for col in missing_columns:
                df[col] = ''
            
            # éªŒè¯DataFrameçš„åˆ—é¡ºåº
            field_names = CTRSampleConfig.get_field_names()
            if list(df.columns) != field_names:
                df = df.reindex(columns=field_names)
            
            return df
    
    def get_stats(self) -> Dict[str, Any]:
        """è·å–æ•°æ®ç»Ÿè®¡ä¿¡æ¯ï¼ˆå¸¦ç¼“å­˜ï¼‰"""
        current_time = time.time()
        
        # æ£€æŸ¥ç¼“å­˜æ˜¯å¦æœ‰æ•ˆ
        if (self._stats_cache is not None and 
            current_time - self._stats_cache_time < self._cache_ttl):
            return self._stats_cache
        
        # é‡æ–°è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
        with self.lock:
            if not self.ctr_data:
                stats = {
                    'total_samples': 0,
                    'total_clicks': 0,
                    'click_rate': 0.0,
                    'unique_queries': 0,
                    'unique_docs': 0,
                    'cache_hit': False,
                    'cache_time': current_time
                }
            else:
                df = pd.DataFrame(self.ctr_data)
                total_samples = len(df)
                total_clicks = df['clicked'].sum() if 'clicked' in df.columns else 0
                click_rate = total_clicks / total_samples if total_samples > 0 else 0.0
                unique_queries = df['query'].nunique() if 'query' in df.columns else 0
                unique_docs = df['doc_id'].nunique() if 'doc_id' in df.columns else 0
                
                # æ–°å¢ç‚¹å‡»è®¡æ•°ç»Ÿè®¡
                total_click_events = 0
                avg_clicks_per_clicked_item = 0.0
                max_clicks_per_item = 0
                if 'click_count' in df.columns:
                    click_counts = df[df['clicked'] == 1]['click_count']
                    if len(click_counts) > 0:
                        total_click_events = click_counts.sum()
                        avg_clicks_per_clicked_item = click_counts.mean()
                        max_clicks_per_item = click_counts.max()
                else:
                    # å…¼å®¹æ—§æ•°æ®
                    total_click_events = total_clicks
                    avg_clicks_per_clicked_item = 1.0 if total_clicks > 0 else 0.0
                    max_clicks_per_item = 1 if total_clicks > 0 else 0
                
                stats = {
                    'total_samples': total_samples,
                    'total_clicks': total_clicks,
                    'total_click_events': total_click_events,
                    'click_rate': click_rate,
                    'avg_clicks_per_clicked_item': round(avg_clicks_per_clicked_item, 2),
                    'max_clicks_per_item': max_clicks_per_item,
                    'unique_queries': unique_queries,
                    'unique_docs': unique_docs,
                    'cache_hit': False,
                    'cache_time': current_time
                }
            
            # æ›´æ–°ç¼“å­˜
            self._stats_cache = stats
            self._stats_cache_time = current_time
            
            return stats
    
    def clear_data(self):
        """æ¸…ç©ºæ‰€æœ‰CTRæ•°æ®"""
        with self.lock:
            self.ctr_data = []
            self.pending_changes = 0
            self._save_data_async() # æ¸…ç©ºåä¹Ÿä¿å­˜ä¸€æ¬¡
            print("âœ… CTRæ•°æ®å·²æ¸…ç©º")
    
    def export_data(self, filepath: str) -> bool:
        """å¯¼å‡ºCTRæ•°æ®"""
        try:
            with self.lock:
                import json
                with open(filepath, 'w', encoding='utf-8') as f:
                    json.dump(self.ctr_data, f, ensure_ascii=False, indent=2)
                print(f"âœ… CTRæ•°æ®å¯¼å‡ºæˆåŠŸ: {filepath}")
                return True
        except Exception as e:
            print(f"âŒ CTRæ•°æ®å¯¼å‡ºå¤±è´¥: {e}")
            return False
    
    def import_data(self, filepath: str) -> bool:
        """å¯¼å…¥CTRæ•°æ®"""
        try:
            import json
            with open(filepath, 'r', encoding='utf-8') as f:
                imported_data = json.load(f)
            
            with self.lock:
                self.ctr_data.extend(imported_data)
                self.pending_changes += len(imported_data)
                if self._should_save_now():
                    self._save_data_async()
                print(f"âœ… CTRæ•°æ®å¯¼å…¥æˆåŠŸ: {len(imported_data)}æ¡è®°å½•")
                return True
        except Exception as e:
            print(f"âŒ CTRæ•°æ®å¯¼å…¥å¤±è´¥: {e}")
            return False 
    
    def batch_record_impressions(self, impressions: List[Dict[str, Any]]) -> Dict[str, Any]:
        """æ‰¹é‡è®°å½•å±•ç¤ºäº‹ä»¶"""
        if not impressions:
            return {'success': False, 'error': 'æ²¡æœ‰æ•°æ®éœ€è¦è®°å½•'}
        
        results = {
            'success': True,
            'total_count': len(impressions),
            'success_count': 0,
            'error_count': 0,
            'errors': []
        }
        
        with self.lock:
            try:
                batch_samples = []
                
                for i, impression in enumerate(impressions):
                    try:
                        # éªŒè¯å¿…è¦å­—æ®µ
                        required_fields = ['query', 'doc_id', 'position', 'score', 'summary', 'request_id']
                        for field in required_fields:
                            if field not in impression:
                                raise ValueError(f"ç¼ºå°‘å¿…è¦å­—æ®µ: {field}")
                        
                        # åˆ›å»ºæ ·æœ¬
                        sample = self._create_sample(
                            impression['query'],
                            impression['doc_id'],
                            impression['position'],
                            impression['score'],
                            impression['summary'],
                            impression['request_id']
                        )
                        
                        batch_samples.append(sample)
                        results['success_count'] += 1
                        
                    except Exception as e:
                        results['error_count'] += 1
                        results['errors'].append(f"ç¬¬{i+1}æ¡è®°å½•é”™è¯¯: {str(e)}")
                
                # æ‰¹é‡æ·»åŠ åˆ°æ•°æ®ä¸­
                if batch_samples:
                    self.ctr_data.extend(batch_samples)
                    self.pending_changes += len(batch_samples)
                    self._invalidate_cache()
                    
                    if self._should_save_now():
                        self._save_data_async()
                
                print(f"âœ… æ‰¹é‡è®°å½•å±•ç¤ºäº‹ä»¶: æˆåŠŸ{results['success_count']}æ¡, å¤±è´¥{results['error_count']}æ¡")
                
            except Exception as e:
                results['success'] = False
                results['error'] = str(e)
                print(f"âŒ æ‰¹é‡è®°å½•å±•ç¤ºäº‹ä»¶å¤±è´¥: {e}")
        
        return results
    
    def _create_sample(self, query: str, doc_id: str, position: int, 
                      score: float, summary: str, request_id: str) -> Dict[str, Any]:
        """åˆ›å»ºå•ä¸ªæ ·æœ¬ï¼ˆå†…éƒ¨æ–¹æ³•ï¼‰"""
        # æ•°æ®éªŒè¯
        if not query or not query.strip():
            raise ValueError("æŸ¥è¯¢ä¸èƒ½ä¸ºç©º")
        
        if not doc_id or not doc_id.strip():
            raise ValueError("æ–‡æ¡£IDä¸èƒ½ä¸ºç©º")
        
        if position < 1:
            raise ValueError("ä½ç½®å¿…é¡»å¤§äº0")
        
        if score < 0:
            raise ValueError("åˆ†æ•°ä¸èƒ½ä¸ºè´Ÿæ•°")
        
        if not request_id or not request_id.strip():
            raise ValueError("è¯·æ±‚IDä¸èƒ½ä¸ºç©º")
        
        # ç”Ÿæˆæ—¶é—´æˆ³
        ts = datetime.now().isoformat()
        
        # è®¡ç®—æŸ¥è¯¢åŒ¹é…åº¦
        query_words = set(jieba.lcut(query.strip()))
        summary_words = set(jieba.lcut(summary or ""))
        match_ratio = 0.0
        if len(query_words) > 0:
            match_ratio = len(query_words.intersection(summary_words)) / len(query_words)
        
        # è®¡ç®—å†å²CTR
        query_history = [d for d in self.ctr_data if d.get('query') == query.strip()]
        doc_history = [d for d in self.ctr_data if d.get('doc_id') == doc_id.strip()]
        query_ctr = sum(d.get('clicked', 0) for d in query_history) / len(query_history) if query_history else 0.1
        doc_ctr = sum(d.get('clicked', 0) for d in doc_history) / len(doc_history) if doc_history else 0.1
        
        # åˆ›å»ºæ ·æœ¬
        sample = {
            'query': query.strip(),
            'doc_id': doc_id.strip(),
            'position': position,
            'score': float(score),
            'summary': summary or "",
            'request_id': request_id.strip(),
            'request_time': ts,
            'clicked': 0,
            'click_count': 0,
            'click_time': "",
            'last_click_time': "",
            'match_score': round(match_ratio, 4),
            'query_ctr': round(query_ctr, 4),
            'doc_ctr': round(doc_ctr, 4),
            'timestamp': ts,
            'doc_length': len(summary) if summary else 0,
            'query_length': len(query.strip()),
            'summary_length': len(summary) if summary else 0,
            'position_decay': round(1.0 / position, 4)
        }
        
        # éªŒè¯æ ·æœ¬å®Œæ•´æ€§
        errors = CTRSampleConfig.validate_sample(sample)
        if errors:
            raise ValueError(f"CTRæ ·æœ¬éªŒè¯å¤±è´¥: {errors}")
        
        return sample
    
    def batch_record_clicks(self, clicks: List[Dict[str, str]]) -> Dict[str, Any]:
        """æ‰¹é‡è®°å½•ç‚¹å‡»äº‹ä»¶"""
        if not clicks:
            return {'success': False, 'error': 'æ²¡æœ‰æ•°æ®éœ€è¦è®°å½•'}
        
        results = {
            'success': True,
            'total_count': len(clicks),
            'success_count': 0,
            'error_count': 0,
            'errors': []
        }
        
        with self.lock:
            try:
                for i, click in enumerate(clicks):
                    try:
                        # éªŒè¯å¿…è¦å­—æ®µ
                        if 'doc_id' not in click or 'request_id' not in click:
                            raise ValueError("ç¼ºå°‘å¿…è¦å­—æ®µ: doc_id æˆ– request_id")
                        
                        doc_id_clean = click['doc_id'].strip()
                        request_id_clean = click['request_id'].strip()
                        
                        # æŸ¥æ‰¾å¹¶æ›´æ–°åŒ¹é…çš„æ ·æœ¬
                        updated = False
                        for sample in self.ctr_data:
                            if (sample.get('request_id') == request_id_clean and 
                                sample.get('doc_id') == doc_id_clean):
                                if sample.get('clicked', 0) == 0:
                                    # é¦–æ¬¡ç‚¹å‡»
                                    sample['clicked'] = 1
                                    sample['click_time'] = datetime.now().isoformat()
                                    sample['click_count'] = 1
                                    updated = True
                                    break
                                else:
                                    # å¤šæ¬¡ç‚¹å‡»ï¼Œé€’å¢ç‚¹å‡»è®¡æ•°
                                    sample['click_count'] = sample.get('click_count', 1) + 1
                                    sample['last_click_time'] = datetime.now().isoformat()
                                    updated = True
                                    break
                        
                        if updated:
                            results['success_count'] += 1
                        else:
                            results['error_count'] += 1
                            results['errors'].append(f"ç¬¬{i+1}æ¡è®°å½•: æœªæ‰¾åˆ°åŒ¹é…çš„å±•ç¤ºè®°å½•")
                            
                    except Exception as e:
                        results['error_count'] += 1
                        results['errors'].append(f"ç¬¬{i+1}æ¡è®°å½•é”™è¯¯: {str(e)}")
                
                if results['success_count'] > 0:
                    self.pending_changes += results['success_count']
                    self._invalidate_cache()
                    
                    if self._should_save_now():
                        self._save_data_async()
                
                print(f"âœ… æ‰¹é‡è®°å½•ç‚¹å‡»äº‹ä»¶: æˆåŠŸ{results['success_count']}æ¡, å¤±è´¥{results['error_count']}æ¡")
                
            except Exception as e:
                results['success'] = False
                results['error'] = str(e)
                print(f"âŒ æ‰¹é‡è®°å½•ç‚¹å‡»äº‹ä»¶å¤±è´¥: {e}")
        
        return results
    
    def get_samples_by_time_range(self, start_time: str, end_time: str) -> List[Dict[str, Any]]:
        """æŒ‰æ—¶é—´èŒƒå›´è·å–æ ·æœ¬"""
        with self.lock:
            try:
                from datetime import datetime
                start_dt = datetime.fromisoformat(start_time.replace('Z', '+00:00'))
                end_dt = datetime.fromisoformat(end_time.replace('Z', '+00:00'))
                
                filtered_samples = []
                for sample in self.ctr_data:
                    if 'timestamp' in sample:
                        sample_dt = datetime.fromisoformat(sample['timestamp'].replace('Z', '+00:00'))
                        if start_dt <= sample_dt <= end_dt:
                            filtered_samples.append(sample)
                
                return filtered_samples
                
            except Exception as e:
                print(f"âŒ æŒ‰æ—¶é—´èŒƒå›´è·å–æ ·æœ¬å¤±è´¥: {e}")
                return []
    
    def get_samples_by_query_pattern(self, pattern: str) -> List[Dict[str, Any]]:
        """æŒ‰æŸ¥è¯¢æ¨¡å¼è·å–æ ·æœ¬"""
        with self.lock:
            try:
                import re
                regex = re.compile(pattern, re.IGNORECASE)
                
                filtered_samples = []
                for sample in self.ctr_data:
                    if 'query' in sample and regex.search(sample['query']):
                        filtered_samples.append(sample)
                
                return filtered_samples
                
            except Exception as e:
                print(f"âŒ æŒ‰æŸ¥è¯¢æ¨¡å¼è·å–æ ·æœ¬å¤±è´¥: {e}")
                return []
    
    def force_save(self):
        """å¼ºåˆ¶ä¿å­˜æ•°æ®"""
        self._save_data_sync()
    
    def get_data_health_check(self) -> Dict[str, Any]:
        """æ•°æ®å¥åº·æ£€æŸ¥"""
        with self.lock:
            try:
                health_report = {
                    'total_samples': len(self.ctr_data),
                    'pending_changes': self.pending_changes,
                    'cache_status': 'valid' if self._stats_cache else 'invalid',
                    'data_issues': [],
                    'recommendations': []
                }
                
                if not self.ctr_data:
                    health_report['data_issues'].append('æ²¡æœ‰æ•°æ®')
                    health_report['recommendations'].append('è¿›è¡Œä¸€äº›æœç´¢å®éªŒç”Ÿæˆæ•°æ®')
                    return health_report
                
                # æ£€æŸ¥é‡å¤è®°å½•
                seen_keys = set()
                duplicates = 0
                for sample in self.ctr_data:
                    key = (sample.get('request_id'), sample.get('doc_id'), sample.get('position'))
                    if key in seen_keys:
                        duplicates += 1
                    else:
                        seen_keys.add(key)
                
                if duplicates > 0:
                    health_report['data_issues'].append(f'å‘ç°{duplicates}æ¡é‡å¤è®°å½•')
                    health_report['recommendations'].append('è€ƒè™‘æ¸…ç†é‡å¤æ•°æ®')
                
                # æ£€æŸ¥æ•°æ®å®Œæ•´æ€§
                incomplete_samples = 0
                for sample in self.ctr_data:
                    required_fields = ['query', 'doc_id', 'position', 'score', 'request_id']
                    if not all(field in sample for field in required_fields):
                        incomplete_samples += 1
                
                if incomplete_samples > 0:
                    health_report['data_issues'].append(f'å‘ç°{incomplete_samples}æ¡ä¸å®Œæ•´è®°å½•')
                    health_report['recommendations'].append('æ£€æŸ¥æ•°æ®æ”¶é›†é€»è¾‘')
                
                # æ£€æŸ¥ç‚¹å‡»ç‡
                total_clicks = sum(sample.get('clicked', 0) for sample in self.ctr_data)
                click_rate = total_clicks / len(self.ctr_data) if self.ctr_data else 0
                
                if click_rate < 0.01:
                    health_report['data_issues'].append(f'ç‚¹å‡»ç‡è¿‡ä½: {click_rate:.2%}')
                    health_report['recommendations'].append('æ£€æŸ¥ç‚¹å‡»äº‹ä»¶è®°å½•æ˜¯å¦æ­£å¸¸')
                
                return health_report
                
            except Exception as e:
                return {
                    'error': str(e),
                    'total_samples': len(self.ctr_data),
                    'pending_changes': self.pending_changes
                } 
    
    def set_model_service(self, model_service):
        """è®¾ç½®æ¨¡å‹æœåŠ¡å¼•ç”¨"""
        self.model_service = model_service
        print("âœ… æ¨¡å‹æœåŠ¡å·²å…³è”åˆ°æ•°æ®æœåŠ¡")
    
    def set_online_training_threshold(self, threshold: int):
        """è®¾ç½®åœ¨çº¿è®­ç»ƒè§¦å‘é˜ˆå€¼"""
        self.online_training_trigger_threshold = max(1, threshold)
        print(f"ğŸ”„ åœ¨çº¿è®­ç»ƒè§¦å‘é˜ˆå€¼å·²è®¾ç½®ä¸º: {threshold}æ¡æ–°æ•°æ®")
    
    def _should_trigger_online_training(self) -> bool:
        """æ£€æŸ¥æ˜¯å¦åº”è¯¥è§¦å‘åœ¨çº¿è®­ç»ƒï¼ˆéœ€è¦åœ¨é”å†…è°ƒç”¨ï¼‰"""
        # å¦‚æœæ²¡æœ‰model_serviceå¼•ç”¨ï¼Œåˆ™è·³è¿‡
        if not self.model_service:
            return False
        
        # å¦‚æœåœ¨çº¿å­¦ä¹ æœªå¯ç”¨ï¼Œåˆ™è·³è¿‡
        if not self.model_service.is_online_learning_enabled():
            return False
        
        # è®¡ç®—æ–°å¢çš„æ•°æ®é‡
        current_data_count = len(self.ctr_data)
        new_data_count = current_data_count - self.last_training_data_count
        
        # å¦‚æœæ–°å¢æ•°æ®è¾¾åˆ°é˜ˆå€¼ï¼Œè§¦å‘åœ¨çº¿è®­ç»ƒ
        return new_data_count >= self.online_training_trigger_threshold
    
    def _trigger_online_training_async(self):
        """å¼‚æ­¥è§¦å‘åœ¨çº¿è®­ç»ƒ"""
        try:
            with self.lock:
                current_data_count = len(self.ctr_data)
                new_data_count = current_data_count - self.last_training_data_count
            
            print(f"ğŸ“Š æ£€æµ‹åˆ°{new_data_count}æ¡æ–°æ•°æ®ï¼Œè§¦å‘åœ¨çº¿è®­ç»ƒ...")
            
            result = self.model_service.trigger_online_training(
                self, 
                min_new_samples=self.online_training_trigger_threshold
            )
            
            if result.get('success', False):
                # æ›´æ–°è®­ç»ƒæ•°æ®è®¡æ•°
                with self.lock:
                    self.last_training_data_count = len(self.ctr_data)
                print(f"âœ… åœ¨çº¿è®­ç»ƒå®Œæˆï¼Œå·²å¤„ç†{new_data_count}æ¡æ–°æ•°æ®")
            elif not result.get('skipped', False):
                print(f"âš ï¸ åœ¨çº¿è®­ç»ƒå¤±è´¥: {result.get('error', 'æœªçŸ¥é”™è¯¯')}")
        except Exception as e:
            print(f"âŒ è§¦å‘åœ¨çº¿è®­ç»ƒæ—¶å‘ç”Ÿé”™è¯¯: {e}") 