import gradio as gr
from datetime import datetime
import os
import json
from typing import List, Tuple
import numpy as np
import matplotlib.pyplot as plt

import jieba

# å»¶è¿ŸåŠ è½½ gensimï¼Œå¹¶åœ¨ç¼ºå¤±æ—¶è‡ªåŠ¨å®‰è£…ï¼ˆé¿å…éœ€è¦é‡å¯ï¼‰
import importlib
import subprocess
import sys
Word2Vec = None

def ensure_gensim(auto_install: bool = True):
    """ç¡®ä¿ gensim.Word2Vec å¯ç”¨ï¼›å¿…è¦æ—¶è‡ªåŠ¨å®‰è£…ã€‚
    Returns: (ok: bool, detail: str)
    """
    global Word2Vec
    if Word2Vec is not None:
        return True, "loaded"
    try:
        Word2Vec = importlib.import_module("gensim.models").Word2Vec
        return True, "imported"
    except Exception:
        if not auto_install:
            return False, "missing"
        try:
            subprocess.run([sys.executable, "-m", "pip", "install", "gensim>=4.3.0"],
                           check=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)
            Word2Vec = importlib.import_module("gensim.models").Word2Vec
            return True, "installed"
        except Exception as e:
            return False, f"install failed: {e}"

try:
    import torch
    from transformers import (
        AutoTokenizer,
        AutoModel,
        AutoModelForCausalLM,
        CLIPProcessor,
        CLIPModel,
    )
    from PIL import Image
except Exception:
    torch = None
    AutoTokenizer = AutoModel = AutoModelForCausalLM = None
    CLIPProcessor = CLIPModel = None
    Image = None

from ..data_utils import (
    get_data_statistics,
    get_ctr_dataframe,
    clear_all_data,
    export_ctr_data,
    import_ctr_data,
    analyze_click_patterns
)
from .ctr_config import CTRModelConfig

def get_history_html(ctr_collector):
    """è·å–å†å²è®°å½•HTML"""
    try:
        history = ctr_collector.get_history()
        if not history:
            return "<p>æš‚æ— å†å²è®°å½•</p>"
        
        html_content = "<div style='max-height: 400px; overflow-y: auto;'>"
        html_content += "<h4>ğŸ“Š ç‚¹å‡»è¡Œä¸ºå†å²è®°å½•</h4>"
        
        for record in history[:20]:  # åªæ˜¾ç¤ºå‰20æ¡
            clicked_icon = "âœ…" if record.get('clicked', 0) else "âŒ"
            html_content += f"""
            <div style="border: 1px solid #ddd; margin: 5px 0; padding: 10px; border-radius: 5px;">
                <div><strong>æŸ¥è¯¢:</strong> {record.get('query', 'N/A')}</div>
                <div><strong>æ–‡æ¡£ID:</strong> {record.get('doc_id', 'N/A')}</div>
                <div><strong>ä½ç½®:</strong> {record.get('position', 'N/A')}</div>
                <div><strong>åˆ†æ•°:</strong> {record.get('score', 'N/A'):.4f}</div>
                <div><strong>ç‚¹å‡»:</strong> {clicked_icon}</div>
                <div><strong>æ—¶é—´:</strong> {record.get('timestamp', 'N/A')}</div>
            </div>
            """
        
        html_content += "</div>"
        return html_content
    except Exception as e:
        return f"<p style='color: red;'>è·å–å†å²è®°å½•å¤±è´¥: {str(e)}</p>"

def create_model_instance(model_type: str):
    """æ ¹æ®æ¨¡å‹ç±»å‹åˆ›å»ºæ¨¡å‹å®ä¾‹"""
    try:
        model_config = CTRModelConfig.get_model_config(model_type)
        if not model_config:
            raise ValueError(f"ä¸æ”¯æŒçš„æ¨¡å‹ç±»å‹: {model_type}")
        
        module_name = model_config['module']
        class_name = model_config['class']
        
        if model_type == 'logistic_regression':
            from .ctr_model import CTRModel
            return CTRModel()
        elif model_type == 'wide_and_deep':
            from .ctr_wide_deep_model import WideAndDeepCTRModel
            return WideAndDeepCTRModel()
        else:
            raise ValueError(f"æœªå®ç°çš„æ¨¡å‹ç±»å‹: {model_type}")
    except Exception as e:
        print(f"åˆ›å»ºæ¨¡å‹å®ä¾‹å¤±è´¥: {e}")
        # å›é€€åˆ°é»˜è®¤LRæ¨¡å‹
        from .ctr_model import CTRModel
        return CTRModel()

def train_ctr_model_direct(ctr_model, data_service, model_type: str = "logistic_regression"):
    """ç›´æ¥ä½¿ç”¨data_serviceè®­ç»ƒCTRæ¨¡å‹"""
    try:
        # è·å–è®­ç»ƒæ•°æ®
        records = data_service.get_all_samples()
        
        if len(records) < 10:
            return (
                "<p style='color: orange;'>âš ï¸ è®­ç»ƒæ•°æ®ä¸è¶³ï¼Œè‡³å°‘éœ€è¦10æ¡è®°å½•</p>",
                "<p>è¯·å…ˆè¿›è¡Œä¸€äº›æœç´¢å’Œç‚¹å‡»æ“ä½œæ”¶é›†æ•°æ®</p>",
                "<p>æš‚æ— ç‰¹å¾æƒé‡æ•°æ®</p>"
            )
        
        # æ ¹æ®é€‰æ‹©çš„æ¨¡å‹ç±»å‹åˆ›å»ºæ¨¡å‹å®ä¾‹
        if model_type != "logistic_regression":
            model_instance = create_model_instance(model_type)
        else:
            model_instance = ctr_model
        
        # è®­ç»ƒæ¨¡å‹
        result = model_instance.train(records)
        
        if 'error' in result:
            return (
                f"<p style='color: red;'>âŒ è®­ç»ƒå¤±è´¥: {result['error']}</p>",
                "<p>è¯·æ£€æŸ¥æ•°æ®è´¨é‡</p>",
                "<p>æš‚æ— ç‰¹å¾æƒé‡æ•°æ®</p>"
            )
        
        # è·å–æ¨¡å‹é…ç½®ä¿¡æ¯
        model_config = CTRModelConfig.get_model_config(model_type)
        model_name = model_config.get('name', model_type)
        
        # ç”Ÿæˆè®­ç»ƒç»“æœHTML
        model_status = f"""
        <div style="background-color: #d4edda; padding: 10px; border-radius: 5px; border-left: 4px solid #28a745;">
            <h4>âœ… CTRæ¨¡å‹è®­ç»ƒæˆåŠŸ</h4>
            <p><strong>æ¨¡å‹ç±»å‹:</strong> {model_name}</p>
            <p><strong>AUC:</strong> {result.get('auc', 0):.4f}</p>
            <p><strong>å‡†ç¡®ç‡:</strong> {result.get('accuracy', 0):.4f}</p>
            <p><strong>è®­ç»ƒæ ·æœ¬:</strong> {result.get('train_samples', 0)}</p>
            <p><strong>æµ‹è¯•æ ·æœ¬:</strong> {result.get('test_samples', 0)}</p>
        </div>
        """
        
        train_result = f"""
        <div style="background-color: #f8f9fa; padding: 10px; border-radius: 5px;">
            <h4>ğŸ“ˆ è®­ç»ƒç»“æœè¯¦æƒ…</h4>
            <ul>
                <li><strong>ç²¾ç¡®ç‡:</strong> {result.get('precision', 0):.4f}</li>
                <li><strong>å¬å›ç‡:</strong> {result.get('recall', 0):.4f}</li>
                <li><strong>F1åˆ†æ•°:</strong> {result.get('f1', 0):.4f}</li>
                <li><strong>è®­ç»ƒå‡†ç¡®ç‡:</strong> {result.get('train_score', 0):.4f}</li>
                <li><strong>æµ‹è¯•å‡†ç¡®ç‡:</strong> {result.get('test_score', 0):.4f}</li>
            </ul>
        </div>
        """
        
        # ç‰¹å¾æƒé‡å¯è§†åŒ–
        feature_weights = result.get('feature_weights', {})
        feature_importance = result.get('feature_importance', {})
        
        # åˆå¹¶ç‰¹å¾æƒé‡å’Œé‡è¦æ€§
        all_features = {**feature_weights, **feature_importance}
        
        if all_features:
            weights_html = "<h4>ğŸ¯ ç‰¹å¾é‡è¦æ€§åˆ†æ</h4><ul>"
            sorted_weights = sorted(all_features.items(), key=lambda x: x[1], reverse=True)
            for feature, weight in sorted_weights[:10]:  # æ˜¾ç¤ºå‰10ä¸ªç‰¹å¾
                weights_html += f"<li><strong>{feature}:</strong> {weight:.4f}</li>"
            weights_html += "</ul>"
        else:
            weights_html = "<p>æš‚æ— ç‰¹å¾æƒé‡æ•°æ®</p>"
        
        return model_status, train_result, weights_html
        
    except Exception as e:
        return (
            f"<p style='color: red;'>âŒ è®­ç»ƒè¿‡ç¨‹å‡ºé”™: {str(e)}</p>",
            "<p>è¯·æ£€æŸ¥ç³»ç»ŸçŠ¶æ€</p>",
            "<p>æš‚æ— ç‰¹å¾æƒé‡æ•°æ®</p>"
        )

def train_ctr_model(ctr_model, ctr_collector, model_type: str = "logistic_regression"):
    """è®­ç»ƒCTRæ¨¡å‹"""
    try:
        # è·å–è®­ç»ƒæ•°æ®
        training_data = ctr_collector.export_data()
        records = training_data.get('records', [])
        
        if len(records) < 10:
            return (
                "<p style='color: orange;'>âš ï¸ è®­ç»ƒæ•°æ®ä¸è¶³ï¼Œè‡³å°‘éœ€è¦10æ¡è®°å½•</p>",
                "<p>è¯·å…ˆè¿›è¡Œä¸€äº›æœç´¢å’Œç‚¹å‡»æ“ä½œæ”¶é›†æ•°æ®</p>",
                "<p>æš‚æ— ç‰¹å¾æƒé‡æ•°æ®</p>"
            )
        
        # æ ¹æ®é€‰æ‹©çš„æ¨¡å‹ç±»å‹åˆ›å»ºæ¨¡å‹å®ä¾‹
        if model_type != "logistic_regression":
            model_instance = create_model_instance(model_type)
        else:
            model_instance = ctr_model
        
        # è®­ç»ƒæ¨¡å‹
        result = model_instance.train(records)
        
        if 'error' in result:
            return (
                f"<p style='color: red;'>âŒ è®­ç»ƒå¤±è´¥: {result['error']}</p>",
                "<p>è¯·æ£€æŸ¥æ•°æ®è´¨é‡</p>",
                "<p>æš‚æ— ç‰¹å¾æƒé‡æ•°æ®</p>"
            )
        
        # è·å–æ¨¡å‹é…ç½®ä¿¡æ¯
        model_config = CTRModelConfig.get_model_config(model_type)
        model_name = model_config.get('name', model_type)
        
        # ç”Ÿæˆè®­ç»ƒç»“æœHTML
        model_status = f"""
        <div style="background-color: #d4edda; padding: 10px; border-radius: 5px; border-left: 4px solid #28a745;">
            <h4>âœ… CTRæ¨¡å‹è®­ç»ƒæˆåŠŸ</h4>
            <p><strong>æ¨¡å‹ç±»å‹:</strong> {model_name}</p>
            <p><strong>AUC:</strong> {result.get('auc', 0):.4f}</p>
            <p><strong>å‡†ç¡®ç‡:</strong> {result.get('accuracy', 0):.4f}</p>
            <p><strong>è®­ç»ƒæ ·æœ¬:</strong> {result.get('train_samples', 0)}</p>
            <p><strong>æµ‹è¯•æ ·æœ¬:</strong> {result.get('test_samples', 0)}</p>
        </div>
        """
        
        train_result = f"""
        <div style="background-color: #f8f9fa; padding: 10px; border-radius: 5px;">
            <h4>ğŸ“ˆ è®­ç»ƒç»“æœè¯¦æƒ…</h4>
            <ul>
                <li><strong>ç²¾ç¡®ç‡:</strong> {result.get('precision', 0):.4f}</li>
                <li><strong>å¬å›ç‡:</strong> {result.get('recall', 0):.4f}</li>
                <li><strong>F1åˆ†æ•°:</strong> {result.get('f1', 0):.4f}</li>
                <li><strong>è®­ç»ƒå‡†ç¡®ç‡:</strong> {result.get('train_score', 0):.4f}</li>
                <li><strong>æµ‹è¯•å‡†ç¡®ç‡:</strong> {result.get('test_score', 0):.4f}</li>
            </ul>
        </div>
        """
        
        # ç‰¹å¾æƒé‡å¯è§†åŒ–
        feature_weights = result.get('feature_weights', {})
        feature_importance = result.get('feature_importance', {})
        
        # åˆå¹¶ç‰¹å¾æƒé‡å’Œé‡è¦æ€§
        all_features = {**feature_weights, **feature_importance}
        
        if all_features:
            weights_html = "<h4>ğŸ¯ ç‰¹å¾é‡è¦æ€§åˆ†æ</h4><ul>"
            sorted_weights = sorted(all_features.items(), key=lambda x: x[1], reverse=True)
            for feature, weight in sorted_weights[:10]:  # æ˜¾ç¤ºå‰10ä¸ªç‰¹å¾
                weights_html += f"<li><strong>{feature}:</strong> {weight:.4f}</li>"
            weights_html += "</ul>"
        else:
            weights_html = "<p>æš‚æ— ç‰¹å¾æƒé‡æ•°æ®</p>"
        
        return model_status, train_result, weights_html
        
    except Exception as e:
        return (
            f"<p style='color: red;'>âŒ è®­ç»ƒè¿‡ç¨‹å‡ºé”™: {str(e)}</p>",
            "<p>è¯·æ£€æŸ¥ç³»ç»ŸçŠ¶æ€</p>",
            "<p>æš‚æ— ç‰¹å¾æƒé‡æ•°æ®</p>"
        )

def build_training_tab(model_service, data_service):
    with gr.Blocks() as training_tab:
        gr.Markdown("""### ğŸ“Š ç¬¬ä¸‰éƒ¨åˆ†ï¼šæ¨¡å‹è®­ç»ƒä¸å®éªŒ""")
        
        with gr.Tabs():
            # LLMOps é—­ç¯ç³»ç»Ÿæ ‡ç­¾é¡µ
            try:
                with gr.Tab("ğŸ”„ LLMOps é—­ç¯"):
                    from .llmops_tab import build_llmops_content
                    train_engine = build_llmops_content()
            except Exception as e:
                print(f"âŒ LLMOps æ ‡ç­¾é¡µåŠ è½½å¤±è´¥: {type(e).__name__}: {str(e)}")
                import traceback
                traceback.print_exc()
                # åˆ›å»ºä¸€ä¸ªé”™è¯¯æç¤ºæ ‡ç­¾é¡µ
                with gr.Tab("ğŸ”„ LLMOps é—­ç¯"):
                    gr.Markdown(f"""
                    ## âŒ LLMOps æ ‡ç­¾é¡µåŠ è½½å¤±è´¥
                    
                    **é”™è¯¯ç±»å‹**: {type(e).__name__}
                    
                    **é”™è¯¯ä¿¡æ¯**: {str(e)}
                    
                    è¯·æ£€æŸ¥æ—¥å¿—è·å–è¯¦ç»†ä¿¡æ¯ã€‚
                    """)
                train_engine = None
            
            # CTRæ¨¡å‹è®­ç»ƒæ ‡ç­¾é¡µ
            with gr.Tab("ğŸ¯ CTRæ¨¡å‹è®­ç»ƒ"):
                gr.Markdown("#### ç‚¹å‡»ç‡é¢„æµ‹æ¨¡å‹è®­ç»ƒ")
                
                # åœ¨çº¿å­¦ä¹ é…ç½®åŒºåŸŸ
                with gr.Accordion("ğŸ”„ åœ¨çº¿å­¦ä¹ é…ç½®", open=True):
                    gr.Markdown("""
                    **åœ¨çº¿å­¦ä¹ æ¨¡å¼**: è‡ªåŠ¨æ£€æµ‹æ–°å¢ç‚¹å‡»æ•°æ®å¹¶è§¦å‘æ¨¡å‹è®­ç»ƒï¼Œå®æ—¶ä¼˜åŒ–æ¨¡å‹æ€§èƒ½
                    - âœ… **ç¦»çº¿è®­ç»ƒ**: æ‰‹åŠ¨è§¦å‘ï¼Œå…¨é‡è®­ç»ƒï¼Œä¿å­˜åˆ° `models/offline/`
                    - ğŸ”„ **åœ¨çº¿è®­ç»ƒ**: è‡ªåŠ¨è§¦å‘ï¼Œå¢é‡è®­ç»ƒï¼Œä¿å­˜åˆ° `models/online/`ï¼ˆä¿ç•™æœ€è¿‘5ä¸ªcheckpointï¼‰
                    """)
                    with gr.Row():
                        online_learning_enabled = gr.Checkbox(
                            label="å¯ç”¨åœ¨çº¿å­¦ä¹ ",
                            value=False,
                            info="å¼€å¯åï¼Œæ¯å½“æ–°å¢ä¸€å®šæ•°é‡çš„ç‚¹å‡»æ•°æ®æ—¶è‡ªåŠ¨è§¦å‘è®­ç»ƒ"
                        )
                        online_training_threshold = gr.Slider(
                            minimum=5,
                            maximum=50,
                            value=10,
                            step=5,
                            label="è®­ç»ƒè§¦å‘é˜ˆå€¼",
                            info="æ¯æ–°å¢Næ¡ç‚¹å‡»æ•°æ®è§¦å‘ä¸€æ¬¡åœ¨çº¿è®­ç»ƒ"
                        )
                    
                    online_status_output = gr.HTML(
                        value="<p style='color: gray;'>âšª åœ¨çº¿å­¦ä¹ æœªå¯ç”¨</p>",
                        label="åœ¨çº¿å­¦ä¹ çŠ¶æ€"
                    )
                
                # æ¨¡å‹é€‰æ‹©åŒºåŸŸ
                with gr.Row():
                    with gr.Column(scale=1):
                        gr.Markdown("#### ğŸ¯ æ¨¡å‹é€‰æ‹©")
                        
                        # è·å–æ”¯æŒçš„æ¨¡å‹
                        model_choices = CTRModelConfig.get_model_names()
                        model_labels = [f"{config['name']} - {config['description']}" 
                                       for config in CTRModelConfig.get_supported_models().values()]
                        model_keys = list(CTRModelConfig.get_supported_models().keys())
                        
                        model_dropdown = gr.Dropdown(
                            choices=[(label, key) for label, key in zip(model_labels, model_keys)],
                            value="logistic_regression",
                            label="é€‰æ‹©CTRæ¨¡å‹",
                            info="é€‰æ‹©è¦è®­ç»ƒçš„CTRæ¨¡å‹ç±»å‹"
                        )
                
                with gr.Row():
                    with gr.Column(scale=2):
                        train_btn = gr.Button("ğŸš€ å¼€å§‹ç¦»çº¿è®­ç»ƒ", variant="primary")
                        clear_data_btn = gr.Button("ğŸ—‘ï¸ æ¸…ç©ºæ•°æ®", variant="secondary")
                        export_data_btn = gr.Button("ğŸ“¤ å¯¼å‡ºæ•°æ®", variant="secondary")
                        
                    with gr.Column(scale=3):
                        data_stats_output = gr.HTML(value="<p>ç‚¹å‡»æŒ‰é’®æŸ¥çœ‹æ•°æ®ç»Ÿè®¡...</p>", label="æ•°æ®ç»Ÿè®¡")
                
                # æ•°æ®ç®¡ç†æŒ‰é’®
                with gr.Row():
                    show_data_stats_btn = gr.Button("ğŸ“Š æ˜¾ç¤ºæ•°æ®ç»Ÿè®¡", variant="secondary")
                    refresh_btn = gr.Button("ğŸ”„ åˆ·æ–°æ ·æœ¬æ•°æ®", variant="secondary")
                
                training_output = gr.HTML(value="<p>ç‚¹å‡»å¼€å§‹è®­ç»ƒæŒ‰é’®è¿›è¡Œæ¨¡å‹è®­ç»ƒ...</p>", label="è®­ç»ƒç»“æœ")
                train_details = gr.HTML(value="<p>è®­ç»ƒè¯¦æƒ…å°†åœ¨è¿™é‡Œæ˜¾ç¤º...</p>", label="è®­ç»ƒè¯¦æƒ…")
                feature_weights = gr.HTML(value="<p>ç‰¹å¾é‡è¦æ€§å°†åœ¨è¿™é‡Œæ˜¾ç¤º...</p>", label="ç‰¹å¾é‡è¦æ€§")
                
                # æ¨¡å‹è¯„ä¼°ä¸åˆ†æ
                gr.Markdown("---")
                gr.Markdown("#### ğŸ“š æ¨¡å‹è¯„ä¼°ä¸åˆ†æ")
                with gr.Tabs():
                    # äº¤å‰éªŒè¯æ ‡ç­¾é¡µ
                    with gr.Tab("ğŸ“Š äº¤å‰éªŒè¯"):
                        gr.Markdown("**åŠŸèƒ½**: ä½¿ç”¨KæŠ˜äº¤å‰éªŒè¯è¯„ä¼°æ¨¡å‹åœ¨ä¸åŒæ•°æ®å­é›†ä¸Šçš„æ€§èƒ½ï¼Œäº†è§£æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›")
                        with gr.Row():
                            cv_folds = gr.Slider(3, 10, value=5, step=1, label="äº¤å‰éªŒè¯æŠ˜æ•°")
                            cv_btn = gr.Button("ğŸš€ æ‰§è¡Œäº¤å‰éªŒè¯", variant="primary")
                        cv_output = gr.HTML(value="<p>ç‚¹å‡»æŒ‰é’®æ‰§è¡Œäº¤å‰éªŒè¯...</p>", label="äº¤å‰éªŒè¯ç»“æœ")
                    
                    # å¯è§£é‡Šæ€§åˆ†ææ ‡ç­¾é¡µ
                    with gr.Tab("ğŸ” å¯è§£é‡Šæ€§åˆ†æ"):
                        gr.Markdown("**åŠŸèƒ½**: ä½¿ç”¨LIMEå’ŒSHAPåˆ†ææ¨¡å‹é¢„æµ‹çš„åŸå› å’Œç‰¹å¾é‡è¦æ€§")
                        with gr.Row():
                            with gr.Column():
                                interpret_method = gr.Radio(
                                    choices=["LIME", "SHAP", "ç‰¹å¾é‡è¦æ€§"],
                                    value="LIME",
                                    label="è§£é‡Šæ–¹æ³•"
                                )
                                num_features = gr.Slider(5, 20, value=10, step=1, label="æ˜¾ç¤ºç‰¹å¾æ•°")
                            with gr.Column():
                                interpret_btn = gr.Button("ğŸ” åˆ†ææ¨¡å‹å¯è§£é‡Šæ€§", variant="primary")
                        interpret_output = gr.HTML(value="<p>ç‚¹å‡»æŒ‰é’®è¿›è¡Œå¯è§£é‡Šæ€§åˆ†æ...</p>", label="è§£é‡Šç»“æœ")
                    
                    # å…¬å¹³æ€§åˆ†ææ ‡ç­¾é¡µ
                    with gr.Tab("âš–ï¸ å…¬å¹³æ€§åˆ†æ"):
                        gr.Markdown("**åŠŸèƒ½**: è¯„ä¼°æ¨¡å‹åœ¨ä¸åŒç¾¤ä½“ä¸Šçš„æ€§èƒ½å·®å¼‚ï¼Œåˆæ­¥äº†è§£æ¨¡å‹å…¬å¹³æ€§")
                        with gr.Row():
                            fairness_group_by = gr.Dropdown(
                                choices=["position_range", "query", "doc_id", "score_range"],
                                value="position_range",
                                label="åˆ†ç»„ä¾æ®"
                            )
                            fairness_btn = gr.Button("âš–ï¸ åˆ†ææ¨¡å‹å…¬å¹³æ€§", variant="primary")
                        fairness_output = gr.HTML(value="<p>ç‚¹å‡»æŒ‰é’®è¿›è¡Œå…¬å¹³æ€§åˆ†æ...</p>", label="å…¬å¹³æ€§åˆ†æç»“æœ")
                    
                    # AutoMLæ ‡ç­¾é¡µ
                    with gr.Tab("ğŸ¤– AutoML"):
                        gr.Markdown("**åŠŸèƒ½**: ä½¿ç”¨AutoMLå·¥å…·è¿›è¡Œæ¨¡å‹æœç´¢å’Œè¶…å‚æ•°ä¼˜åŒ–")
                        with gr.Row():
                            with gr.Column():
                                automl_method = gr.Radio(
                                    choices=["ç½‘æ ¼æœç´¢", "Optunaä¼˜åŒ–"],
                                    value="ç½‘æ ¼æœç´¢",
                                    label="ä¼˜åŒ–æ–¹æ³•"
                                )
                                automl_cv = gr.Slider(3, 10, value=3, step=1, label="äº¤å‰éªŒè¯æŠ˜æ•°")
                            with gr.Column():
                                automl_btn = gr.Button("ğŸ¤– æ‰§è¡ŒAutoMLä¼˜åŒ–", variant="primary")
                        automl_output = gr.HTML(value="<p>ç‚¹å‡»æŒ‰é’®æ‰§è¡ŒAutoMLä¼˜åŒ–...</p>", label="AutoMLç»“æœ")
                
                sample_output = gr.Dataframe(
                    headers=None,
                    label="CTRæ ·æœ¬æ•°æ®",
                    interactive=False
                )
        
            # è¯è¡¨ç¤ºï¼šWord2Vec
            with gr.Tab("ğŸ§© è¯è¡¨ç¤º Â· Word2Vec"):
                gr.Markdown("ä»é¢„ç½®æ–‡æ¡£è®­ç»ƒä¸€ä¸ª Word2Vec è¯å‘é‡æ¨¡å‹ï¼Œå¹¶æŸ¥è¯¢è¿‘ä¹‰è¯ã€‚")

                with gr.Row():
                    with gr.Column(scale=1):
                        w2v_vector_size = gr.Slider(50, 300, value=128, step=8, label="å‘é‡ç»´åº¦")
                        w2v_window = gr.Slider(2, 10, value=5, step=1, label="çª—å£å¤§å°")
                        w2v_min_count = gr.Slider(1, 5, value=2, step=1, label="æœ€å°è¯é¢‘")
                        w2v_epochs = gr.Slider(1, 10, value=3, step=1, label="è®­ç»ƒè½®æ¬¡")
                        train_w2v_btn = gr.Button("ğŸš€ è®­ç»ƒ Word2Vec", variant="primary")
                    with gr.Column(scale=1):
                        query_word = gr.Textbox(label="æŸ¥è¯¢è¯", placeholder="è¾“å…¥è¯è¯­ï¼ŒæŸ¥çœ‹è¿‘ä¹‰è¯")
                        w2v_topk = gr.Slider(3, 20, value=10, step=1, label="TopK")
                        w2v_query_btn = gr.Button("ğŸ” æŸ¥è¯¢è¿‘ä¹‰è¯")
                w2v_status = gr.HTML(value="<p>å°šæœªè®­ç»ƒ</p>")
                w2v_result = gr.Dataframe(headers=["è¯", "ç›¸ä¼¼åº¦"], interactive=False)

                # Word2Vecè‡ªç›‘ç£å­¦ä¹ æ•°æ®æ ¼å¼å¯è§†åŒ–
                gr.Markdown("#### ğŸ“Š Word2Vecè‡ªç›‘ç£å­¦ä¹ æ•°æ®æ ¼å¼")
                gr.Markdown("**CBOWä»»åŠ¡**: ä½¿ç”¨ä¸Šä¸‹æ–‡é¢„æµ‹ä¸­å¿ƒè¯ï¼ˆWord2Vecè‡ªç›‘ç£å­¦ä¹ ä¹‹ä¸€ï¼‰")
                gr.Markdown("**Skip-gramä»»åŠ¡**: ç»™å®šä¸­å¿ƒè¯ï¼Œé¢„æµ‹å‘¨å›´ä¸Šä¸‹æ–‡è¯ï¼ˆWord2Vecè‡ªç›‘ç£å­¦ä¹ ä¹‹ä¸€ï¼‰")
                with gr.Row():
                    bow_top = gr.Dataframe(headers=["è¾“å…¥", "ç›®æ ‡"], label="CBOWè‡ªç›‘ç£ä»»åŠ¡æ ·æœ¬", interactive=False)
                    skipgram_pairs = gr.Dataframe(headers=["è¾“å…¥", "ç›®æ ‡"], label="Skip-gramè‡ªç›‘ç£ä»»åŠ¡æ ·æœ¬", interactive=False)
                run_w2v_viz_btn = gr.Button("ğŸ” æŸ¥çœ‹Word2Vecè‡ªç›‘ç£æ•°æ®æ ¼å¼", variant="secondary")

            # å¥å­è¡¨ç¤ºï¼šBERT
            with gr.Tab("ğŸ§  å¥å­è¡¨ç¤º Â· BERT"):
                gr.Markdown("ä½¿ç”¨ BERT é¢„è®­ç»ƒæ¨¡å‹æŠ½å–å¥å­å‘é‡ã€‚é»˜è®¤ä½¿ç”¨ `bert-base-chinese`ï¼Œå¯è¾“å…¥ä¸¤å¥å¯¹æ¯”ä½™å¼¦ç›¸ä¼¼åº¦ã€‚")
                with gr.Row():
                    with gr.Column(scale=1):
                        bert_model_name = gr.Textbox(value="bert-base-chinese", label="æ¨¡å‹å")
                        load_bert_btn = gr.Button("ğŸ“¦ åŠ è½½æ¨¡å‹", variant="secondary")
                    with gr.Column(scale=2):
                        sent_a = gr.Textbox(label="å¥å­A", value="æˆ‘å–œæ¬¢äººå·¥æ™ºèƒ½")
                        sent_b = gr.Textbox(label="å¥å­B", value="æˆ‘çƒ­çˆ±æœºå™¨å­¦ä¹ ")
                        run_bert_btn = gr.Button("ğŸ” è®¡ç®—ç›¸ä¼¼åº¦", variant="primary")
                bert_status = gr.HTML(value="<p>æ¨¡å‹æœªåŠ è½½</p>")
                bert_similarity = gr.HTML(value="<p>ç›¸ä¼¼åº¦å°†åœ¨è¿™é‡Œæ˜¾ç¤º</p>")

            # ç”Ÿæˆæ¨¡å‹ï¼šOPTï¼ˆç”Ÿæˆ + é¢„ç½®æ–‡æ¡£ä¸Šçš„CLMå¾®è°ƒæ¼”ç¤ºï¼‰
            with gr.Tab("âœï¸ ç”Ÿæˆæ¨¡å‹ Â· OPT"):
                gr.Markdown("ä½¿ç”¨ `facebook/opt-125m` è¿›è¡Œæ–‡æœ¬ç”Ÿæˆï¼Œå¹¶åœ¨é¢„ç½®æ–‡æ¡£ä¸Šåšå°‘é‡ CLM è®­ç»ƒæ¼”ç¤ºï¼ˆä»…å±•ç¤ºæ–¹æ³•ï¼ŒCPU å°‘æ­¥æ•°ï¼‰ã€‚")
                with gr.Row():
                    with gr.Column(scale=1):
                        opt_model_name = gr.Textbox(value="facebook/opt-125m", label="æ¨¡å‹å")
                        load_opt_btn = gr.Button("ğŸ“¦ åŠ è½½æ¨¡å‹", variant="secondary")
                        # CLM è®­ç»ƒå‚æ•°
                        train_steps = gr.Slider(1, 50, value=5, step=1, label="è®­ç»ƒæ­¥æ•°")
                        lr_opt = gr.Slider(1e-6, 5e-5, value=1e-5, step=1e-6, label="å­¦ä¹ ç‡")
                        block_size = gr.Slider(64, 512, value=256, step=32, label="åºåˆ—é•¿åº¦")
                        batch_size = gr.Slider(1, 4, value=1, step=1, label="æ‰¹å¤§å°")
                        train_opt_btn = gr.Button("ğŸ“ ç”¨é¢„ç½®æ–‡æ¡£åšCLMè®­ç»ƒ(æ¼”ç¤º)", variant="primary")
                    with gr.Column(scale=2):
                        opt_prompt = gr.Textbox(label="Prompt", value="ä»Šå¤©æˆ‘å­¦ä¹ äº†ä¿¡æ¯æ£€ç´¢ï¼Œå®ƒæ˜¯â€¦â€¦", lines=4)
                        max_new_tokens = gr.Slider(16, 128, value=64, step=8, label="æœ€å¤§ç”Ÿæˆé•¿åº¦")
                        gen_btn = gr.Button("ğŸ“ ç”Ÿæˆæ–‡æœ¬", variant="secondary")
                opt_status = gr.HTML(value="<p>æ¨¡å‹æœªåŠ è½½</p>")
                opt_output = gr.HTML(value="<p>ç”Ÿæˆç»“æœå°†åœ¨è¿™é‡Œæ˜¾ç¤º</p>")

                # OPT Causal Language Modeling è‡ªç›‘ç£å­¦ä¹ æ•°æ®æ ¼å¼å¯è§†åŒ–
                gr.Markdown("#### ğŸ“Š OPTè‡ªç›‘ç£å­¦ä¹ ï¼šCausal Language Modeling (CLM)")
                gr.Markdown("**CLMä»»åŠ¡**: ç»™å®šå‰æ–‡åºåˆ—ï¼Œé¢„æµ‹ä¸‹ä¸€ä¸ªtokenï¼ˆå› æœè¯­è¨€å»ºæ¨¡ï¼Œè‡ªç›‘ç£å­¦ä¹ æ ¸å¿ƒï¼‰")
                clm_pairs_df = gr.Dataframe(headers=["è¾“å…¥åºåˆ—", "é¢„æµ‹ç›®æ ‡", "token_id", "ä½ç½®"], label="CLMè‡ªç›‘ç£ä»»åŠ¡æ ·æœ¬ (Next Token Prediction)", interactive=False)
                run_clm_viz_btn = gr.Button("ğŸ” æŸ¥çœ‹OPTè‡ªç›‘ç£æ•°æ®æ ¼å¼", variant="secondary")

            # å¤šæ¨¡æ€ï¼šCLIP å¯¹æ¯”å­¦ä¹ å¾®è°ƒï¼ˆæ¼”ç¤ºï¼‰
            with gr.Tab("ğŸ–¼ï¸ğŸ”¤ å¤šæ¨¡æ€ Â· CLIP å¾®è°ƒ"):
                gr.Markdown("#### CLIPå¤šæ¨¡æ€å¯¹æ¯”å­¦ä¹ ")
                gr.Markdown("**å¯¹æ¯”å­¦ä¹ **: åŒæ—¶è®­ç»ƒæ–‡æœ¬ç¼–ç å™¨å’Œå›¾åƒç¼–ç å™¨ï¼Œä½¿åŒ¹é…çš„æ–‡æœ¬-å›¾åƒå¯¹åœ¨åµŒå…¥ç©ºé—´ä¸­æ›´ç›¸ä¼¼ï¼ˆæ­£æ ·æœ¬ï¼‰ï¼Œä¸åŒ¹é…çš„æ›´è¿œç¦»ï¼ˆè´Ÿæ ·æœ¬ï¼‰")
                gr.Markdown("**è‡ªç›‘ç£ä»»åŠ¡**: å¤§é‡å›¾æ–‡å¯¹æ— éœ€äººå·¥æ ‡æ³¨ï¼Œé€šè¿‡å¯¹æ¯”æŸå¤±è‡ªåŠ¨å­¦ä¹ è·¨æ¨¡æ€è¡¨ç¤º")
                clip_info = gr.HTML(value="<p>åŸºäºå†…ç½®å›¾æ–‡å¯¹æ¼”ç¤ºCLIPå¯¹æ¯”å­¦ä¹ ï¼ŒCPUç¯å¢ƒè®­ç»ƒè¾ƒæ…¢ã€‚</p>")
                with gr.Row():
                    with gr.Column(scale=1):
                        clip_model_name = gr.Textbox(value="openai/clip-vit-base-patch32", label="æ¨¡å‹å")
                        load_clip_btn = gr.Button("ğŸ“¦ åŠ è½½æ¨¡å‹", variant="secondary")
                    with gr.Column(scale=2):
                        clip_train_btn = gr.Button("ğŸ“ æ¼”ç¤ºå¯¹æ¯”å­¦ä¹ å¾®è°ƒ", variant="primary")
                clip_status = gr.HTML(value="<p>æ¨¡å‹æœªåŠ è½½</p>")
                clip_log = gr.HTML(value="<p>å¯¹æ¯”å­¦ä¹ è®­ç»ƒæ—¥å¿—å°†åœ¨è¿™é‡Œæ˜¾ç¤º</p>")
                
                # CLIPå¯¹æ¯”å­¦ä¹ æ•°æ®æ ¼å¼è¯´æ˜ä¸å¯è§†åŒ–
                gr.Markdown("#### ğŸ“Š CLIPå¯¹æ¯”å­¦ä¹ æ•°æ®æ ¼å¼")
                gr.Markdown("- **æ­£æ ·æœ¬å¯¹**: (å›¾åƒ, åŒ¹é…æè¿°æ–‡æœ¬) â†’ æ‹‰è¿‘åµŒå…¥è·ç¦»")
                gr.Markdown("- **è´Ÿæ ·æœ¬å¯¹**: (å›¾åƒ, ä¸åŒ¹é…æ–‡æœ¬) â†’ æ¨è¿œåµŒå…¥è·ç¦»")
                gr.Markdown("- **æ‰¹å†…å¯¹æ¯”**: ä¸€ä¸ªbatchå†…ï¼Œæ¯ä¸ªå›¾åƒä¸æ‰€æœ‰æ–‡æœ¬è®¡ç®—ç›¸ä¼¼åº¦çŸ©é˜µï¼Œå¯¹è§’çº¿ä¸ºæ­£æ ·æœ¬")
                
                # CLIPè®­ç»ƒæ•°æ®å¯è§†åŒ–
                with gr.Row():
                    with gr.Column(scale=1):
                        clip_data_viz = gr.Dataframe(headers=["å›¾ç‰‡è·¯å¾„", "åŒ¹é…æ–‡æœ¬", "æ•°æ®ç±»å‹"], label="CLIPå›¾æ–‡å¯¹è®­ç»ƒæ•°æ®", interactive=False)
                        viz_clip_data_btn = gr.Button("ğŸ” æŸ¥çœ‹CLIPè®­ç»ƒæ•°æ®æ ¼å¼", variant="secondary")
                    with gr.Column(scale=1):
                        clip_image_gallery = gr.Gallery(label="è®­ç»ƒå›¾ç‰‡é¢„è§ˆ", show_label=True, elem_id="clip_gallery", columns=2, rows=2, object_fit="contain", height="400px")
                        clip_text_display = gr.HTML(value="<p>å›¾ç‰‡æè¿°å°†åœ¨è¿™é‡Œæ˜¾ç¤º</p>", label="å¯¹åº”æ–‡æœ¬æè¿°")

        # ç»‘å®šäº‹ä»¶ï¼ˆCTRï¼‰
        def show_data_stats():
            # ä½¿ç”¨æ–°çš„å·¥å…·å‡½æ•°è·å–ç»Ÿè®¡ä¿¡æ¯
            stats = get_data_statistics()
            
            # è·å–ç‚¹å‡»æ¨¡å¼åˆ†æ
            patterns = analyze_click_patterns()
            
            html = f"""
            <div style="background-color: #f8f9fa; padding: 15px; border-radius: 8px;">
                <h4 style="margin: 0 0 10px 0; color: #333;">ğŸ“Š CTRæ•°æ®ç»Ÿè®¡</h4>
                <ul style="margin: 0; padding-left: 20px;">
                    <li><strong>æ€»æ ·æœ¬æ•°:</strong> {stats['total_samples']}</li>
                    <li><strong>æ€»ç‚¹å‡»æ•°:</strong> {stats['total_clicks']}</li>
                    <li><strong>ç‚¹å‡»ç‡:</strong> {stats['click_rate']:.2%}</li>
                    <li><strong>å”¯ä¸€æŸ¥è¯¢æ•°:</strong> {stats['unique_queries']}</li>
                    <li><strong>å”¯ä¸€æ–‡æ¡£æ•°:</strong> {stats['unique_docs']}</li>
                    <li><strong>ç¼“å­˜çŠ¶æ€:</strong> {'å‘½ä¸­' if stats.get('cache_hit', False) else 'æœªå‘½ä¸­'}</li>
                </ul>
            </div>
            """
            
            # å¦‚æœæœ‰ç‚¹å‡»æ¨¡å¼åˆ†æç»“æœï¼Œæ·»åŠ åˆ°æ˜¾ç¤ºä¸­
            if 'error' not in patterns:
                html += f"""
                <div style="background-color: #e8f5e8; padding: 15px; border-radius: 8px; margin-top: 10px;">
                    <h4 style="margin: 0 0 10px 0; color: #333;">ğŸ” ç‚¹å‡»æ¨¡å¼åˆ†æ</h4>
                    <ul style="margin: 0; padding-left: 20px;">
                        <li><strong>æ•´ä½“CTR:</strong> {patterns['overall_ctr']:.2%}</li>
                        <li><strong>æ€»å±•ç¤ºæ•°:</strong> {patterns['total_impressions']}</li>
                        <li><strong>æ€»ç‚¹å‡»æ•°:</strong> {patterns['total_clicks']}</li>
                    </ul>
                </div>
                """
            
            return html
        
        def train_model_with_selection(selected_model):
            # ä½¿ç”¨æ–°çš„è®­ç»ƒå‡½æ•°ï¼Œæ”¯æŒæ¨¡å‹é€‰æ‹©
            try:
                ctr_model = model_service.ctr_model if hasattr(model_service, 'ctr_model') else None
                
                # data_serviceæœ¬èº«å°±æ˜¯æ•°æ®æ”¶é›†å™¨ï¼Œä¸éœ€è¦ctr_collectorå±æ€§
                if not ctr_model:
                    return (
                        "<p style='color: red;'>âŒ CTRæ¨¡å‹ä¸å¯ç”¨</p>",
                        "<p>è¯·æ£€æŸ¥ç³»ç»ŸçŠ¶æ€</p>",
                        "<p>æš‚æ— ç‰¹å¾é‡è¦æ€§æ•°æ®</p>"
                    )
                
                return train_ctr_model_direct(ctr_model, data_service, selected_model)
            except Exception as e:
                return (
                    f"<p style='color: red;'>âŒ è®­ç»ƒå‡½æ•°è°ƒç”¨å¤±è´¥: {str(e)}</p>",
                    "<p>è¯·æ£€æŸ¥ç³»ç»ŸçŠ¶æ€</p>",
                    "<p>æš‚æ— ç‰¹å¾é‡è¦æ€§æ•°æ®</p>"
                )
        
        def clear_data():
            # ä½¿ç”¨æ–°çš„å·¥å…·å‡½æ•°
            clear_all_data()
            return "<p style='color: green;'>âœ… æ•°æ®å·²æ¸…ç©º</p>"
        
        def export_data():
            import os
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            filename = f"ctr_data_export_{timestamp}.json"
            filepath = os.path.join("data", filename)
            
            os.makedirs("data", exist_ok=True)
            # ä½¿ç”¨æ–°çš„å·¥å…·å‡½æ•°
            if export_ctr_data(filepath):
                return f"<p style='color: green;'>âœ… æ•°æ®å¯¼å‡ºæˆåŠŸ: {filename}</p>"
            else:
                return "<p style='color: red;'>âŒ æ•°æ®å¯¼å‡ºå¤±è´¥</p>"
        
        # åˆ é™¤å¯¼å…¥åŠŸèƒ½ï¼šä»…ä¿ç•™å¯¼å‡º/æ¸…ç©º
        
        def refresh_samples():
            # ä½¿ç”¨æ–°çš„å·¥å…·å‡½æ•°
            return get_ctr_dataframe()
        
        def toggle_online_learning(enabled, threshold):
            """åˆ‡æ¢åœ¨çº¿å­¦ä¹ å¼€å…³"""
            try:
                # å¯ç”¨/ç¦ç”¨åœ¨çº¿å­¦ä¹ 
                model_service.enable_online_learning(enabled)
                
                # è®¾ç½®è®­ç»ƒè§¦å‘é˜ˆå€¼
                data_service.set_online_training_threshold(int(threshold))
                
                # å…³è”æ¨¡å‹æœåŠ¡åˆ°æ•°æ®æœåŠ¡ï¼ˆå¦‚æœè¿˜æ²¡æœ‰å…³è”ï¼‰
                if not data_service.model_service:
                    data_service.set_model_service(model_service)
                
                if enabled:
                    # è·å–å½“å‰åœ¨çº¿æ¨¡å‹çŠ¶æ€
                    latest_checkpoint = model_service._get_latest_online_checkpoint()
                    checkpoint_info = f"å½“å‰checkpoint: #{latest_checkpoint}" if latest_checkpoint else "å°šæ— åœ¨çº¿checkpoint"
                    
                    return f"""
                    <div style="background-color: #d4edda; padding: 10px; border-radius: 5px; border-left: 4px solid #28a745;">
                        <p style='color: #28a745; margin: 0;'><strong>ğŸŸ¢ åœ¨çº¿å­¦ä¹ å·²å¯ç”¨</strong></p>
                        <p style='margin: 5px 0 0 0;'><small>è§¦å‘é˜ˆå€¼: æ¯{int(threshold)}æ¡æ–°ç‚¹å‡»æ•°æ®</small></p>
                        <p style='margin: 5px 0 0 0;'><small>{checkpoint_info}</small></p>
                        <p style='margin: 5px 0 0 0;'><small>æ¨¡å‹ä¿å­˜: models/online/ (ä¿ç•™æœ€è¿‘5ä¸ª)</small></p>
                    </div>
                    """
                else:
                    return "<p style='color: gray;'>âšª åœ¨çº¿å­¦ä¹ æœªå¯ç”¨</p>"
            except Exception as e:
                return f"<p style='color: red;'>âŒ åˆ‡æ¢å¤±è´¥: {str(e)}</p>"
        
        # ç»‘å®šäº‹ä»¶
        # åœ¨çº¿å­¦ä¹ å¼€å…³äº‹ä»¶
        online_learning_enabled.change(
            fn=toggle_online_learning,
            inputs=[online_learning_enabled, online_training_threshold],
            outputs=[online_status_output]
        )
        online_training_threshold.change(
            fn=toggle_online_learning,
            inputs=[online_learning_enabled, online_training_threshold],
            outputs=[online_status_output]
        )
        
        train_btn.click(
            fn=train_model_with_selection, 
            inputs=[model_dropdown], 
            outputs=[training_output, train_details, feature_weights]
        )
        clear_data_btn.click(fn=clear_data, outputs=training_output)
        export_data_btn.click(fn=export_data, outputs=training_output)
        
        # å·²ç§»é™¤å¯¼å…¥æ§ä»¶ä¸äº‹ä»¶ç»‘å®š
        
        # ç»‘å®šæ•°æ®ç®¡ç†æŒ‰é’®äº‹ä»¶
        show_data_stats_btn.click(fn=show_data_stats, outputs=data_stats_output)
        refresh_btn.click(fn=refresh_samples, outputs=sample_output)
        
        # ============ æ¨¡å‹è¯„ä¼°ä¸åˆ†æ ============
        from .model_evaluation import ModelEvaluator
        from .model_interpretability import ModelInterpretability
        from .model_fairness import ModelFairnessAnalyzer
        from .model_automl import AutoMLOptimizer
        from sklearn.linear_model import LogisticRegression
        
        evaluator = ModelEvaluator()
        interpretability = ModelInterpretability()
        fairness_analyzer = ModelFairnessAnalyzer()
        automl_optimizer = AutoMLOptimizer()
        
        def run_cross_validation(folds):
            """æ‰§è¡Œäº¤å‰éªŒè¯"""
            try:
                ctr_model = model_service.ctr_model if hasattr(model_service, 'ctr_model') else None
                if not ctr_model or not ctr_model.is_trained:
                    return "<p style='color: orange;'>âš ï¸ è¯·å…ˆè®­ç»ƒæ¨¡å‹</p>"
                
                # è·å–è®­ç»ƒæ•°æ®
                records = data_service.get_all_samples()
                
                if len(records) < folds * 2:
                    return f"<p style='color: red;'>âŒ æ•°æ®é‡ä¸è¶³ï¼Œè‡³å°‘éœ€è¦{folds * 2}æ¡è®°å½•</p>"
                
                # æ‰§è¡Œäº¤å‰éªŒè¯
                result = evaluator.cross_validate_model(
                    ctr_model.model,
                    records,
                    cv_folds=int(folds)
                )
                
                if 'error' in result:
                    return f"<p style='color: red;'>âŒ {result['error']}</p>"
                
                # æ ¼å¼åŒ–ç»“æœ
                html = "<div style='background-color: #f8f9fa; padding: 15px; border-radius: 8px;'>"
                html += f"<h4>ğŸ“Š äº¤å‰éªŒè¯ç»“æœï¼ˆ{folds}æŠ˜ï¼‰</h4>"
                html += f"<p><strong>æ ·æœ¬æ•°:</strong> {result.get('n_samples', 0)}</p>"
                html += f"<p><strong>ç‰¹å¾æ•°:</strong> {result.get('n_features', 0)}</p>"
                
                if result.get('cv_mean'):
                    html += "<h5>å„æŒ‡æ ‡çš„å¹³å‡å€¼å’Œæ ‡å‡†å·®:</h5><table border='1' style='border-collapse: collapse;'>"
                    html += "<tr><th>æŒ‡æ ‡</th><th>å¹³å‡å€¼</th><th>æ ‡å‡†å·®</th></tr>"
                    for metric, mean_val in result['cv_mean'].items():
                        std_val = result['cv_std'].get(metric, 0)
                        html += f"<tr><td>{metric}</td><td>{mean_val:.4f}</td><td>{std_val:.4f}</td></tr>"
                    html += "</table>"
                
                html += "</div>"
                return html
                
            except Exception as e:
                return f"<p style='color: red;'>âŒ äº¤å‰éªŒè¯å¤±è´¥: {str(e)}</p>"
        
        def run_interpretability_analysis(method, num_feat):
            """æ‰§è¡Œå¯è§£é‡Šæ€§åˆ†æ"""
            try:
                ctr_model = model_service.ctr_model if hasattr(model_service, 'ctr_model') else None
                if not ctr_model or not ctr_model.is_trained:
                    return "<p style='color: orange;'>âš ï¸ è¯·å…ˆè®­ç»ƒæ¨¡å‹</p>"
                
                # è·å–è®­ç»ƒæ•°æ®
                records = data_service.get_all_samples()
                
                if len(records) < 10:
                    return "<p style='color: red;'>âŒ æ•°æ®é‡ä¸è¶³</p>"
                
                # æå–ç‰¹å¾
                features, labels = ctr_model.extract_features(records)
                if len(features) == 0:
                    return "<p style='color: red;'>âŒ ç‰¹å¾æå–å¤±è´¥</p>"
                
                # æ ‡å‡†åŒ–
                if ctr_model.scaler:
                    features_scaled = ctr_model.scaler.transform(features)
                else:
                    from sklearn.preprocessing import StandardScaler
                    scaler = StandardScaler()
                    features_scaled = scaler.fit_transform(features)
                
                # è·å–ç‰¹å¾åç§°
                from .ctr_config import CTRFeatureConfig
                feature_names = CTRFeatureConfig.get_feature_names()
                
                if method == "LIME":
                    # å‡†å¤‡LIMEè§£é‡Šå™¨
                    success, msg = interpretability.prepare_lime_explainer(
                        features_scaled,
                        feature_names[:len(features_scaled[0])] if len(feature_names) >= len(features_scaled[0]) else [f"ç‰¹å¾{i}" for i in range(len(features_scaled[0]))]
                    )
                    if not success:
                        return f"<p style='color: red;'>âŒ {msg}</p>"
                    
                    # è§£é‡Šä¸€ä¸ªæ ·æœ¬
                    sample_idx = 0
                    explanation = interpretability.explain_with_lime(
                        ctr_model.model,
                        features_scaled[sample_idx:sample_idx+1],
                        num_features=int(num_feat)
                    )
                    
                    if 'error' in explanation:
                        return f"<p style='color: red;'>âŒ {explanation['error']}</p>"
                    
                    html = f"<div style='background-color: #f8f9fa; padding: 15px; border-radius: 8px;'>"
                    html += f"<h4>ğŸ” LIMEè§£é‡Šç»“æœ</h4>"
                    html += f"<p><strong>é¢„æµ‹æ¦‚ç‡:</strong> {explanation.get('prediction', 0):.4f}</p>"
                    html += "<h5>ç‰¹å¾è´¡çŒ®:</h5><ul>"
                    for feat in explanation.get('features', [])[:int(num_feat)]:
                        color = "green" if feat['weight'] > 0 else "red"
                        html += f"<li><span style='color: {color};'>{feat['feature']}: {feat['weight']:.4f}</span></li>"
                    html += "</ul></div>"
                    return html
                
                elif method == "SHAP":
                    explanation = interpretability.explain_with_shap(
                        ctr_model.model,
                        features_scaled,
                        max_samples=50
                    )
                    
                    if 'error' in explanation:
                        return f"<p style='color: red;'>âŒ {explanation['error']}</p>"
                    
                    html = "<div style='background-color: #f8f9fa; padding: 15px; border-radius: 8px;'>"
                    html += "<h4>ğŸ” SHAPè§£é‡Šç»“æœ</h4>"
                    if 'feature_importance_dict' in explanation:
                        html += "<h5>ç‰¹å¾é‡è¦æ€§ï¼ˆå¹³å‡ç»å¯¹SHAPå€¼ï¼‰:</h5><ul>"
                        sorted_features = sorted(explanation['feature_importance_dict'].items(), key=lambda x: x[1], reverse=True)
                        for feat_name, importance in sorted_features[:int(num_feat)]:
                            html += f"<li><strong>{feat_name}:</strong> {importance:.4f}</li>"
                        html += "</ul>"
                    html += "</div>"
                    return html
                
                else:  # ç‰¹å¾é‡è¦æ€§
                    importance = interpretability.get_feature_importance_from_model(ctr_model.model)
                    html = "<div style='background-color: #f8f9fa; padding: 15px; border-radius: 8px;'>"
                    html += "<h4>ğŸ” æ¨¡å‹ç‰¹å¾é‡è¦æ€§</h4>"
                    if 'by_feature' in importance and 'coefficients' in importance['by_feature']:
                        html += "<h5>ç‰¹å¾ç³»æ•°ï¼ˆç»å¯¹å€¼ï¼‰:</h5><ul>"
                        sorted_features = sorted(importance['by_feature']['coefficients'].items(), key=lambda x: abs(x[1]), reverse=True)
                        for feat_name, coef in sorted_features[:int(num_feat)]:
                            html += f"<li><strong>{feat_name}:</strong> {coef:.4f}</li>"
                        html += "</ul>"
                    html += "</div>"
                    return html
                    
            except Exception as e:
                import traceback
                return f"<p style='color: red;'>âŒ å¯è§£é‡Šæ€§åˆ†æå¤±è´¥: {str(e)}</p><pre>{traceback.format_exc()[:500]}</pre>"
        
        def run_fairness_analysis(group_by):
            """æ‰§è¡Œå…¬å¹³æ€§åˆ†æ"""
            try:
                ctr_model = model_service.ctr_model if hasattr(model_service, 'ctr_model') else None
                if not ctr_model or not ctr_model.is_trained:
                    return "<p style='color: orange;'>âš ï¸ è¯·å…ˆè®­ç»ƒæ¨¡å‹</p>"
                
                # è·å–è®­ç»ƒæ•°æ®
                records = data_service.get_all_samples()
                
                if len(records) < 20:
                    return "<p style='color: red;'>âŒ æ•°æ®é‡ä¸è¶³ï¼Œè‡³å°‘éœ€è¦20æ¡è®°å½•</p>"
                
                # æ‰§è¡Œå…¬å¹³æ€§åˆ†æ
                result = fairness_analyzer.analyze_fairness(
                    ctr_model.model,
                    records,
                    group_by=group_by,
                    model_instance_extract_features=ctr_model.extract_features
                )
                
                if 'error' in result:
                    return f"<p style='color: red;'>âŒ {result['error']}</p>"
                
                # ç”ŸæˆæŠ¥å‘Š
                report = fairness_analyzer.generate_fairness_report(result)
                return f"<div style='background-color: #f8f9fa; padding: 15px; border-radius: 8px;'>{report}</div>"
                
            except Exception as e:
                import traceback
                return f"<p style='color: red;'>âŒ å…¬å¹³æ€§åˆ†æå¤±è´¥: {str(e)}</p><pre>{traceback.format_exc()[:500]}</pre>"
        
        def run_automl_optimization(method, cv_folds):
            """æ‰§è¡ŒAutoMLä¼˜åŒ–"""
            try:
                # è·å–è®­ç»ƒæ•°æ®
                records = data_service.get_all_samples()
                
                if len(records) < 30:
                    return "<p style='color: red;'>âŒ æ•°æ®é‡ä¸è¶³ï¼Œè‡³å°‘éœ€è¦30æ¡è®°å½•</p>"
                
                # æå–ç‰¹å¾
                ctr_model = model_service.ctr_model if hasattr(model_service, 'ctr_model') else None
                if not ctr_model:
                    return "<p style='color: red;'>âŒ CTRæ¨¡å‹ä¸å¯ç”¨</p>"
                
                features, labels = ctr_model.extract_features(records)
                if len(features) == 0:
                    return "<p style='color: red;'>âŒ ç‰¹å¾æå–å¤±è´¥</p>"
                
                # æ ‡å‡†åŒ–
                from sklearn.preprocessing import StandardScaler
                scaler = StandardScaler()
                X_scaled = scaler.fit_transform(features)
                
                if method == "ç½‘æ ¼æœç´¢":
                    # å®šä¹‰å‚æ•°ç½‘æ ¼
                    param_grid = {
                        'C': [0.1, 1.0, 10.0],
                        'max_iter': [500, 1000],
                        'solver': ['liblinear', 'lbfgs']
                    }
                    
                    result = automl_optimizer.simple_grid_search(
                        LogisticRegression,
                        X_scaled,
                        labels,
                        param_grid,
                        cv=int(cv_folds)
                    )
                    
                    if 'error' in result:
                        return f"<p style='color: red;'>âŒ {result['error']}</p>"
                    
                    html = "<div style='background-color: #f8f9fa; padding: 15px; border-radius: 8px;'>"
                    html += "<h4>ğŸ¤– ç½‘æ ¼æœç´¢ä¼˜åŒ–ç»“æœ</h4>"
                    html += f"<p><strong>æœ€ä½³å‚æ•°:</strong> {result.get('best_params', {})}</p>"
                    html += f"<p><strong>æœ€ä½³å¾—åˆ†:</strong> {result.get('best_score', 0):.4f}</p>"
                    html += "</div>"
                    return html
                
                else:  # Optunaä¼˜åŒ–
                    param_space = {
                        'C': {'type': 'float', 'low': 0.1, 'high': 10.0, 'log': True},
                        'max_iter': {'type': 'int', 'low': 500, 'high': 2000, 'log': False}
                    }
                    
                    result = automl_optimizer.optimize_hyperparameters_with_optuna(
                        LogisticRegression,
                        X_scaled,
                        labels,
                        param_space,
                        n_trials=10,
                        cv=int(cv_folds)
                    )
                    
                    if 'error' in result:
                        return f"<p style='color: red;'>âŒ {result['error']}</p>"
                    
                    html = "<div style='background-color: #f8f9fa; padding: 15px; border-radius: 8px;'>"
                    html += "<h4>ğŸ¤– Optunaä¼˜åŒ–ç»“æœ</h4>"
                    html += f"<p><strong>æœ€ä½³å‚æ•°:</strong> {result.get('best_params', {})}</p>"
                    html += f"<p><strong>æœ€ä½³å¾—åˆ†:</strong> {result.get('best_score', 0):.4f}</p>"
                    html += f"<p><strong>è¯•éªŒæ¬¡æ•°:</strong> {result.get('n_trials', 0)}</p>"
                    html += "</div>"
                    return html
                    
            except Exception as e:
                import traceback
                return f"<p style='color: red;'>âŒ AutoMLä¼˜åŒ–å¤±è´¥: {str(e)}</p><pre>{traceback.format_exc()[:500]}</pre>"
        
        # ç»‘å®šæ–°åŠŸèƒ½çš„äº‹ä»¶
        cv_btn.click(fn=run_cross_validation, inputs=[cv_folds], outputs=[cv_output])
        interpret_btn.click(fn=run_interpretability_analysis, inputs=[interpret_method, num_features], outputs=[interpret_output])
        fairness_btn.click(fn=run_fairness_analysis, inputs=[fairness_group_by], outputs=[fairness_output])
        automl_btn.click(fn=run_automl_optimization, inputs=[automl_method, automl_cv], outputs=[automl_output])
        
        # åˆå§‹åŒ–æ ·æœ¬æ•°æ®
        sample_output.value = get_ctr_dataframe()
        # å…¼å®¹æ€§æ–¹æ¡ˆï¼šTabæ„å»ºåè‡ªåŠ¨è§¦å‘ä¸€æ¬¡åˆ·æ–°æŒ‰é’®ï¼ˆå¦‚æœæœ‰refresh_btnï¼‰
        # æˆ–è€…åœ¨Blockså¤–éƒ¨ç”¨gradioçš„on()äº‹ä»¶ï¼ˆå¦‚æ”¯æŒï¼‰
        # è¿™é‡Œä¿ç•™åˆå§‹åŒ–èµ‹å€¼ï¼Œç”¨æˆ·åˆ‡æ¢Tabåå¦‚éœ€åˆ·æ–°å¯æ‰‹åŠ¨ç‚¹å‡»åˆ·æ–°æŒ‰é’®
        
        # ============ Word2Vec é€»è¾‘ ============
        def _load_preloaded_texts(limit: int = 5000) -> List[List[str]]:
            try:
                preloaded_path = os.path.join("data", "preloaded_documents.json")
                if not os.path.exists(preloaded_path):
                    return []
                with open(preloaded_path, "r", encoding="utf-8") as f:
                    data = json.load(f)
                docs = data["documents"] if isinstance(data, dict) and "documents" in data else data
                sentences = []
                # è½»é‡çº§ä¸­æ–‡åœç”¨è¯ä¸æ¸…æ´—
                stop = {
                    "çš„","äº†","åœ¨","æ˜¯","å’Œ","ä¸","åŠ","å¹¶","ä¹Ÿ","å¯¹","ä¸­","ä¸Š","ä¸‹","ä¸º","ä»¥",
                    "ä¸€ä¸ª","ä¸€ç§","ä¸€äº›","æˆ‘ä»¬","ä½ ä»¬","ä»–ä»¬","ä»¥åŠ","æˆ–è€…","è€Œä¸”","å¦‚æœ","å› ä¸º",
                    "å¯ä»¥","é€šè¿‡","è¿›è¡Œ","ä½¿ç”¨","æ²¡æœ‰","åŒ…æ‹¬","è¿™ç§","è¿™äº›","é‚£äº›","ç”±äº","ç”±äº",
                }
                import re
                zh_re = re.compile(r"[\u4e00-\u9fff]{2,}")
                for i, (_id, content) in enumerate(docs.items() if isinstance(docs, dict) else docs):
                    if i >= limit:
                        break
                    raw_tokens = jieba.lcut(str(content).strip())
                    tokens = []
                    for w in raw_tokens:
                        if w in stop:
                            continue
                        if not zh_re.fullmatch(w):
                            continue
                        tokens.append(w)
                    if tokens:
                        sentences.append(tokens)
                return sentences
            except Exception:
                return []

        w2v_model_holder = {"model": None}

        def train_w2v(vector_size: int, window: int, min_count: int, epochs: int):
            ok, msg = ensure_gensim(auto_install=True)
            if not ok:
                return f"<p style='color:red'>gensim ä¸å¯ç”¨ï¼š{msg}</p>", []
            corpus = _load_preloaded_texts()
            if not corpus:
                return "<p style='color:red'>æœªæ‰¾åˆ°é¢„ç½®æ–‡æ¡£æˆ–å†…å®¹ä¸ºç©º</p>", []
            model = Word2Vec(
                sentences=corpus,
                vector_size=int(vector_size),
                window=max(5, int(window)),
                min_count=max(2, int(min_count)),
                epochs=max(5, int(epochs)),
                sg=1,
                workers=1,
                seed=42,
            )
            w2v_model_holder["model"] = model
            return f"<p style='color:green'>âœ… è®­ç»ƒå®Œæˆï¼Œè¯è¡¨å¤§å°: {len(model.wv)}</p>", []

        def query_w2v(word: str, topk: int):
            model = w2v_model_holder.get("model")
            if model is None:
                return "<p style='color:red'>è¯·å…ˆè®­ç»ƒæ¨¡å‹</p>", []
            if not word:
                return "<p style='color:red'>è¯·è¾“å…¥æŸ¥è¯¢è¯</p>", []
            try:
                sims = model.wv.most_similar(word, topn=int(topk))
                rows = [[w, float(s)] for w, s in sims]
                return "<p>å¦‚ä¸‹ä¸ºè¿‘ä¹‰è¯</p>", rows
            except KeyError:
                return f"<p style='color:red'>è¯ '{word}' ä¸åœ¨è¯è¡¨ä¸­</p>", []

        train_w2v_btn.click(train_w2v, inputs=[w2v_vector_size, w2v_window, w2v_min_count, w2v_epochs], outputs=[w2v_status, w2v_result])
        w2v_query_btn.click(query_w2v, inputs=[query_word, w2v_topk], outputs=[w2v_status, w2v_result])
        
        # W2V é¢„å¤„ç†å¯è§†åŒ–ï¼šCBOWä¸Skip-gramçš„è‡ªç›‘ç£ä»»åŠ¡æ ·æœ¬
        def _bow_and_skipgram(window: int, min_count: int):
            corpus = _load_preloaded_texts(limit=2000)
            if not corpus:
                return [], []
            from collections import Counter
            token_counter = Counter()
            for sent in corpus:
                token_counter.update(sent)

            # CBOWï¼šä¸Šä¸‹æ–‡ â†’ ä¸­å¿ƒè¯
            cbow_pairs = []
            win = int(window)
            for sent in corpus[:50]:  # ä»…å–å‰è‹¥å¹²å¥åšå±•ç¤º
                for i, center in enumerate(sent):
                    # ä»…ä¿ç•™å‡ºç°æ¬¡æ•°>=min_countçš„ä¸­å¿ƒè¯ï¼Œé¿å…ç½•è§è¯
                    if token_counter[center] < int(min_count):
                        continue
                    ctx = []
                    for j in range(max(0, i - win), min(len(sent), i + win + 1)):
                        if j == i:
                            continue
                        ctx.append(sent[j])
                    if not ctx:
                        continue
                    cbow_pairs.append([f"ä¸Šä¸‹æ–‡:{' '.join(ctx)}", f"ä¸­å¿ƒè¯:{center}"])
                    if len(cbow_pairs) >= 100:
                        break
                if len(cbow_pairs) >= 100:
                    break

            # Skip-gramï¼šä¸­å¿ƒè¯ â†’ ä¸Šä¸‹æ–‡è¯
            skip_pairs = []
            for sent in corpus[:50]:
                for i, center in enumerate(sent):
                    if token_counter[center] < int(min_count):
                        continue
                    for j in range(max(0, i - win), min(len(sent), i + win + 1)):
                        if j == i:
                            continue
                        skip_pairs.append([f"ä¸­å¿ƒè¯:{center}", f"ä¸Šä¸‹æ–‡:{sent[j]}"])
                        if len(skip_pairs) >= 100:
                            break
                    if len(skip_pairs) >= 100:
                        break
                if len(skip_pairs) >= 100:
                    break

            return cbow_pairs, skip_pairs

        def run_w2v_viz():
            top, pairs = _bow_and_skipgram(window=int(w2v_window.value), min_count=int(w2v_min_count.value))
            return top, pairs

        run_w2v_viz_btn.click(run_w2v_viz, outputs=[bow_top, skipgram_pairs])

        # ============ BERT å¥å‘é‡ ============
        bert_holder = {"tok": None, "mdl": None}

        def load_bert(model_name: str):
            if AutoTokenizer is None:
                return "<p style='color:red'>transformers æœªå®‰è£…</p>"
            tok = AutoTokenizer.from_pretrained(model_name)
            mdl = AutoModel.from_pretrained(model_name)
            mdl.eval()
            bert_holder.update({"tok": tok, "mdl": mdl})
            return f"<p style='color:green'>âœ… æ¨¡å‹å·²åŠ è½½: {model_name}</p>"

        def cosine(a, b):
            import numpy as np
            na = a / (np.linalg.norm(a) + 1e-8)
            nb = b / (np.linalg.norm(b) + 1e-8)
            return float((na * nb).sum())

        def run_bert(model_name: str, a: str, b: str):
            if bert_holder["tok"] is None:
                load_bert(model_name)
            tok, mdl = bert_holder["tok"], bert_holder["mdl"]
            with torch.no_grad():
                inputs = tok([a, b], return_tensors="pt", padding=True, truncation=True, max_length=128)
                outputs = mdl(**inputs)
                # ä½¿ç”¨ [CLS] å‘é‡æˆ–å¹³å‡æ± åŒ–
                cls = outputs.last_hidden_state[:, 0, :].detach().cpu().numpy()
                sim = cosine(cls[0], cls[1])
            return gr.update(value=f"<p>ç›¸ä¼¼åº¦: {sim:.4f}</p>")

        load_bert_btn.click(load_bert, inputs=[bert_model_name], outputs=[bert_status])
        run_bert_btn.click(run_bert, inputs=[bert_model_name, sent_a, sent_b], outputs=[bert_similarity])

        # ============ OPT ç”Ÿæˆ ============
        opt_holder = {"tok": None, "mdl": None}

        def load_opt(model_name: str):
            if AutoTokenizer is None:
                return "<p style='color:red'>transformers æœªå®‰è£…</p>"
            tok = AutoTokenizer.from_pretrained(model_name)
            mdl = AutoModelForCausalLM.from_pretrained(model_name)
            opt_holder.update({"tok": tok, "mdl": mdl})
            return f"<p style='color:green'>âœ… æ¨¡å‹å·²åŠ è½½: {model_name}</p>"

        def generate_opt(model_name: str, prompt: str, max_new: int):
            if opt_holder["tok"] is None:
                load_opt(model_name)
            tok, mdl = opt_holder["tok"], opt_holder["mdl"]
            inputs = tok(prompt, return_tensors="pt")
            with torch.no_grad():
                out = mdl.generate(**inputs, max_new_tokens=int(max_new), do_sample=True, top_p=0.9)
            text = tok.decode(out[0], skip_special_tokens=True)
            return gr.update(value=f"<pre>{text}</pre>")

        def _load_preloaded_text_corpus(max_docs: int = 200) -> str:
            """å°†é¢„ç½®æ–‡æ¡£æ‹¼æ¥ä¸ºCLMè®­ç»ƒæ–‡æœ¬ï¼ˆä»…ç¤ºä¾‹ï¼‰ã€‚"""
            try:
                preloaded_path = os.path.join("data", "preloaded_documents.json")
                if not os.path.exists(preloaded_path):
                    return ""
                with open(preloaded_path, "r", encoding="utf-8") as f:
                    data = json.load(f)
                docs = data["documents"] if isinstance(data, dict) and "documents" in data else data
                texts = []
                count = 0
                if isinstance(docs, dict):
                    for _, content in docs.items():
                        texts.append(str(content).strip())
                        count += 1
                        if count >= max_docs:
                            break
                else:
                    for content in docs:
                        texts.append(str(content).strip())
                        count += 1
                        if count >= max_docs:
                            break
                return "\n\n".join(texts)
            except Exception:
                return ""

        def train_opt_on_preloaded(model_name: str, steps: int, lr: float, block: int, bsize: int):
            if opt_holder["tok"] is None:
                load_opt(model_name)
            tok, mdl = opt_holder["tok"], opt_holder["mdl"]
            corpus = _load_preloaded_text_corpus()
            if not corpus:
                return "<p style='color:red'>æœªæ‰¾åˆ°é¢„ç½®æ–‡æœ¬</p>"
            # æ„é€ ç®€æ˜“æ•°æ®å¼ é‡
            inputs = tok(corpus, return_tensors="pt", truncation=True, max_length=int(block))
            input_ids = inputs["input_ids"]
            optim = torch.optim.AdamW(mdl.parameters(), lr=float(lr))
            mdl.train()
            total_loss = 0.0
            for i in range(int(steps)):
                optim.zero_grad()
                out = mdl(input_ids=input_ids, labels=input_ids)
                loss = out.loss
                loss.backward()
                optim.step()
                total_loss += loss.item()
            mdl.eval()
            avg_loss = total_loss / max(1, int(steps))
            return f"<p style='color:green'>âœ… CLMè®­ç»ƒå®Œæˆ(æ¼”ç¤º) steps={int(steps)}, avg_loss={avg_loss:.4f}</p>"

        load_opt_btn.click(load_opt, inputs=[opt_model_name], outputs=[opt_status])
        gen_btn.click(generate_opt, inputs=[opt_model_name, opt_prompt, max_new_tokens], outputs=[opt_output])
        train_opt_btn.click(train_opt_on_preloaded, inputs=[opt_model_name, train_steps, lr_opt, block_size, batch_size], outputs=[opt_status])

        # CLM(Causal Language Modeling)è‡ªç›‘ç£å­¦ä¹ æ•°æ®æ ¼å¼å¯è§†åŒ–
        def _clm_pairs_only(model_name: str):
            text = _load_preloaded_text_corpus(max_docs=200)
            if not text:
                return []
            tok = AutoTokenizer.from_pretrained(model_name)
            ids = tok(text, return_tensors="pt", truncation=False)["input_ids"].squeeze(0).tolist()

            # CLMè‡ªç›‘ç£ä»»åŠ¡ï¼šç»™å®šå‰æ–‡token idåºåˆ—ï¼Œé¢„æµ‹ä¸‹ä¸€ä¸ªtoken id
            pairs = []
            context_len = 32  # ä»…å±•ç¤ºå°¾éƒ¨è‹¥å¹²idï¼Œé¿å…è¿‡é•¿
            for i in range(min(50, len(ids) - 1)):
                # å–åˆ°å½“å‰ä½ç½®ï¼ˆåŒ…å«å½“å‰tokenï¼‰çš„ä¸Šä¸‹æ–‡idåºåˆ—
                ctx_ids = ids[max(0, i - context_len):i + 1]
                next_id = int(ids[i + 1])
                # è§£ç ä¸Šä¸‹æ–‡ä¸ºå­—é¢æ–‡æœ¬ï¼Œä»…ç”¨äºå±•ç¤ºï¼›å¯èƒ½åŒ…å«ä¸å¯è§å­—ç¬¦ï¼Œç”¨ç®­å¤´æ›¿æ¢æ¢è¡Œ
                ctx_text = tok.decode(ctx_ids).replace("\n", "â†µ")
                input_seq = "..." + ctx_text[-64:]
                # ä»…å¯¹ä¸‹ä¸€ä¸ªtokenæ˜¾ç¤ºä¸º[id]
                pairs.append([input_seq, f"[{next_id}]", next_id, int(i + 1)])
                if len(pairs) >= 30:
                    break
            return pairs

        def run_clm_viz():
            return _clm_pairs_only(opt_model_name.value)

        run_clm_viz_btn.click(run_clm_viz, outputs=[clm_pairs_df])

        # ============ CLIP å¾®è°ƒï¼ˆæ¼”ç¤ºï¼‰ ============
        clip_holder = {"proc": None, "mdl": None}

        def load_clip(model_name: str):
            if CLIPProcessor is None:
                return "<p style='color:red'>transformers/Pillow æœªå®‰è£…</p>"
            proc = CLIPProcessor.from_pretrained(model_name)
            mdl = CLIPModel.from_pretrained(model_name)
            clip_holder.update({"proc": proc, "mdl": mdl})
            return f"<p style='color:green'>âœ… æ¨¡å‹å·²åŠ è½½: {model_name}</p>"

        def _load_builtin_pairs() -> List[Tuple[str, str]]:
            # CLIPè‡ªç›‘ç£å­¦ä¹ ï¼šæ–‡æœ¬-å›¾åƒå¯¹æ¯”å­¦ä¹ æ•°æ®æ ¼å¼
            # ä¸¥æ ¼ä½¿ç”¨çœŸå®çš„å›¾æ–‡å¯¹æ•°æ®
            candidates = []
            
            # é¦–å…ˆå°è¯•ä»æœ¬åœ°ç´¢å¼•åŠ è½½
            try:
                idx_paths = [
                    os.path.join("test_images", "image_index.json"),  # ä¼˜å…ˆä½¿ç”¨æœ‰æè¿°çš„test_images
                    os.path.join("models", "images", "image_index.json"),
                ]
                for idx in idx_paths:
                    if os.path.exists(idx):
                        with open(idx, "r", encoding="utf-8") as f:
                            data = json.load(f)
                        images = data.get("images", {})
                        for info in images.values():
                            img_path = info.get("stored_path") or info.get("path")
                            text = info.get("description") or ""
                            
                            # ä¸¥æ ¼éªŒè¯ï¼šåªä½¿ç”¨æœ‰çœŸå®æè¿°ä¸”å›¾ç‰‡å­˜åœ¨çš„æ•°æ®
                            if (img_path and os.path.exists(img_path) and 
                                text and len(text.strip()) > 0 and 
                                text != "A photo"):  # æ’é™¤é€šç”¨å ä½ç¬¦
                                candidates.append((img_path, text.strip()))
            except Exception:
                pass
            
            # å¦‚æœæ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„å›¾æ–‡å¯¹ï¼Œè¿”å›ç©ºåˆ—è¡¨
            # ç¡®ä¿æ•°æ®çš„çœŸå®æ€§ï¼Œä¸ä½¿ç”¨ä»»ä½•æ¨¡æ‹Ÿæˆ–å ä½ç¬¦æ•°æ®
            
            return candidates[:6]  # æœ€å¤šå–6å¯¹ï¼Œä¾¿äºå±•ç¤ºå¯¹æ¯”å­¦ä¹ æ¦‚å¿µ

        def finetune_clip(model_name: str):
            if clip_holder["proc"] is None:
                load_clip(model_name)
            try:
                proc, mdl = clip_holder["proc"], clip_holder["mdl"]
                pairs = _load_builtin_pairs()
                if not pairs:
                    return "<p style='color:red'>âŒ æœªæ‰¾åˆ°çœŸå®å›¾æ–‡å¯¹æ•°æ®<br/>è¯·ç¡®è®¤ models/images æˆ– test_images ç›®å½•ä¸­æœ‰å›¾ç‰‡å’Œç´¢å¼•æ–‡ä»¶<br/>CLIPæ¼”ç¤ºéœ€è¦çœŸå®çš„å›¾æ–‡å¯¹æ•°æ®æ‰èƒ½è¿›è¡Œ</p>"
                
                # éªŒè¯æ‰€æœ‰å›¾ç‰‡æ–‡ä»¶éƒ½å­˜åœ¨
                valid_pairs = [(p, t) for p, t in pairs if os.path.exists(p)]
                if not valid_pairs:
                    return "<p style='color:red'>âŒ æœªæ‰¾åˆ°æœ‰æ•ˆçš„å›¾ç‰‡æ–‡ä»¶<br/>è¯·æ£€æŸ¥å›¾ç‰‡è·¯å¾„æ˜¯å¦æ­£ç¡®</p>"
                
                # ä½¿ç”¨çœŸå®å›¾ç‰‡è¿›è¡ŒCLIPå¯¹æ¯”å­¦ä¹ æ¼”ç¤º
                mdl.train()
                optim = torch.optim.AdamW(mdl.parameters(), lr=5e-6)
                
                # å‡†å¤‡å›¾ç‰‡å’Œæ–‡æœ¬æ•°æ®
                images = [Image.open(p).convert("RGB") for p, _ in valid_pairs]
                texts = [t for _, t in valid_pairs]
                
                # CLIPé¢„å¤„ç†ï¼šå›¾ç‰‡å’Œæ–‡æœ¬ç¼–ç 
                inputs = proc(text=texts, images=images, return_tensors="pt", padding=True)
                
                # å‰å‘ä¼ æ’­
                outputs = mdl(**inputs)
                
                # CLIPå¯¹æ¯”å­¦ä¹ æ ¸å¿ƒï¼š
                # 1. è·å–æ ‡å‡†åŒ–çš„å›¾åƒå’Œæ–‡æœ¬åµŒå…¥
                image_embeds = outputs.image_embeds  # [batch_size, embed_dim]
                text_embeds = outputs.text_embeds    # [batch_size, embed_dim]
                
                # 2. è®¡ç®—ç›¸ä¼¼åº¦çŸ©é˜µ (è¿™æ˜¯CLIPçš„æ ¸å¿ƒæœºåˆ¶)
                # logits_per_image: æ¯ä¸ªå›¾åƒä¸æ‰€æœ‰æ–‡æœ¬çš„ç›¸ä¼¼åº¦ [batch_size, batch_size]
                # logits_per_text: æ¯ä¸ªæ–‡æœ¬ä¸æ‰€æœ‰å›¾åƒçš„ç›¸ä¼¼åº¦ [batch_size, batch_size]
                logits_per_image = outputs.logits_per_image
                logits_per_text = outputs.logits_per_text
                
                # 3. CLIPå¯¹æ¯”å­¦ä¹ æŸå¤±
                # å¯¹è§’çº¿å…ƒç´ æ˜¯æ­£æ ·æœ¬å¯¹(image_i, text_i)ï¼Œå…¶ä»–æ˜¯è´Ÿæ ·æœ¬
                batch_size = len(images)
                labels = torch.arange(batch_size, dtype=torch.long)
                
                # å›¾åƒåˆ°æ–‡æœ¬çš„å¯¹æ¯”æŸå¤±ï¼šæ¯ä¸ªå›¾åƒåº”è¯¥ä¸å¯¹åº”æ–‡æœ¬æœ€ç›¸ä¼¼
                loss_i2t = torch.nn.functional.cross_entropy(logits_per_image, labels)
                # æ–‡æœ¬åˆ°å›¾åƒçš„å¯¹æ¯”æŸå¤±ï¼šæ¯ä¸ªæ–‡æœ¬åº”è¯¥ä¸å¯¹åº”å›¾åƒæœ€ç›¸ä¼¼  
                loss_t2i = torch.nn.functional.cross_entropy(logits_per_text, labels)
                
                # æ€»å¯¹æ¯”æŸå¤±ï¼ˆCLIPæ ‡å‡†åšæ³•ï¼‰
                contrastive_loss = (loss_i2t + loss_t2i) / 2
                
                # åå‘ä¼ æ’­å’Œä¼˜åŒ–
                optim.zero_grad()
                contrastive_loss.backward()
                optim.step()
                mdl.eval()
                
                # è®¡ç®—è®­ç»ƒåçš„ç›¸ä¼¼åº¦ç”¨äºå±•ç¤º
                with torch.no_grad():
                    final_outputs = mdl(**inputs)
                    final_similarities = final_outputs.logits_per_image
                
                # å±•ç¤ºä½¿ç”¨çš„å›¾æ–‡å¯¹ä¿¡æ¯å’Œè®­ç»ƒç»“æœ
                data_info = "<h4>ğŸ“Š ä½¿ç”¨çš„å›¾æ–‡å¯¹æ•°æ®</h4><ul>"
                for i, (img_path, text) in enumerate(valid_pairs):
                    img_name = os.path.basename(img_path)
                    data_info += f"<li><strong>æ ·æœ¬{i+1}</strong>: {img_name} - {text}</li>"
                data_info += "</ul>"
                
                # å±•ç¤ºç›¸ä¼¼åº¦çŸ©é˜µï¼ˆå¯¹æ¯”å­¦ä¹ çš„æ ¸å¿ƒæ¦‚å¿µï¼‰
                similarity_info = "<h4>ğŸ¯ å¯¹æ¯”å­¦ä¹ ç›¸ä¼¼åº¦çŸ©é˜µ</h4>"
                similarity_info += "<p>æ¯è¡Œè¡¨ç¤ºä¸€å¼ å›¾åƒä¸æ‰€æœ‰æ–‡æœ¬çš„ç›¸ä¼¼åº¦ï¼Œå¯¹è§’çº¿åº”è¯¥æœ€é«˜ï¼ˆæ­£æ ·æœ¬å¯¹ï¼‰</p>"
                similarity_info += "<table style='border-collapse: collapse; margin: 10px 0;'>"
                similarity_info += "<tr><th style='border: 1px solid #ddd; padding: 4px;'>å›¾åƒ\\æ–‡æœ¬</th>"
                for j, (_, text) in enumerate(valid_pairs):
                    similarity_info += f"<th style='border: 1px solid #ddd; padding: 4px;'>æ–‡æœ¬{j+1}</th>"
                similarity_info += "</tr>"
                
                # æ˜¾ç¤ºç›¸ä¼¼åº¦æ•°å€¼ï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼Œä»…æ˜¾ç¤ºå‰3x3ï¼‰
                sim_matrix = final_similarities.cpu().numpy()
                display_size = min(3, batch_size)  # æœ€å¤šæ˜¾ç¤º3x3çŸ©é˜µ
                for i in range(display_size):
                    img_name = os.path.basename(valid_pairs[i][0])
                    similarity_info += f"<tr><td style='border: 1px solid #ddd; padding: 4px;'>{img_name}</td>"
                    for j in range(display_size):
                        sim_val = sim_matrix[i, j]
                        # å¯¹è§’çº¿å…ƒç´ ï¼ˆæ­£æ ·æœ¬ï¼‰ç”¨ç»¿è‰²é«˜äº®
                        color = "background-color: #d4edda;" if i == j else ""
                        similarity_info += f"<td style='border: 1px solid #ddd; padding: 4px; {color}'>{sim_val:.3f}</td>"
                    similarity_info += "</tr>"
                similarity_info += "</table>"
                
                return f"<p style='color:green'>âœ… CLIPå¯¹æ¯”å­¦ä¹ æ¼”ç¤ºå®Œæˆ</p>{data_info}<p><strong>è®­ç»ƒç»“æœ:</strong><br/>å¯¹æ¯”æŸå¤±: {contrastive_loss.item():.4f}<br/>å›¾åƒâ†’æ–‡æœ¬æŸå¤±: {loss_i2t.item():.4f} | æ–‡æœ¬â†’å›¾åƒæŸå¤±: {loss_t2i.item():.4f}<br/>è®­ç»ƒæ ·æœ¬: {batch_size}ä¸ªçœŸå®å›¾æ–‡æ­£æ ·æœ¬å¯¹</p>{similarity_info}"
                
            except Exception as e:
                return f"<p style='color:red'>CLIPå¯¹æ¯”å­¦ä¹ æ¼”ç¤ºå¤±è´¥: {str(e)}</p>"

        # CLIPè®­ç»ƒæ•°æ®å¯è§†åŒ–å‡½æ•°
        def visualize_clip_data():
            pairs = _load_builtin_pairs()
            if not pairs:
                return [["æ— æ•°æ®", "æœªæ‰¾åˆ°çœŸå®å›¾æ–‡å¯¹æ•°æ®", "é”™è¯¯"]], [], "<p style='color:red'>æœªæ‰¾åˆ°çœŸå®å›¾æ–‡å¯¹æ•°æ®</p>"
            
            # æ„å»ºCLIPå¯¹æ¯”å­¦ä¹ è®­ç»ƒæ•°æ®è¡¨æ ¼
            clip_data_rows = []
            valid_images = []
            text_descriptions = []
            
            for i, (img_path, text) in enumerate(pairs):
                if os.path.exists(img_path):
                    img_name = os.path.basename(img_path)
                    # æ­£æ ·æœ¬å¯¹ï¼šåŒ¹é…çš„å›¾æ–‡å¯¹
                    clip_data_rows.append([img_name, text, f"æ­£æ ·æœ¬{i+1}"])
                    
                    # ç¡®ä¿å›¾ç‰‡è·¯å¾„æ ¼å¼æ­£ç¡®ï¼Œç”¨äºGradio Galleryæ˜¾ç¤º
                    # è½¬æ¢ä¸ºç»å¯¹è·¯å¾„ç¡®ä¿Gradioèƒ½æ­£ç¡®åŠ è½½
                    abs_img_path = os.path.abspath(img_path)
                    valid_images.append(abs_img_path)
                    
                    text_descriptions.append(f"<strong>å›¾ç‰‡{i+1}</strong>: {img_name}<br/><strong>æè¿°</strong>: {text}")
                    
                    # è´Ÿæ ·æœ¬å¯¹ï¼šä¸å…¶ä»–æ–‡æœ¬çš„ä¸åŒ¹é…ç»„åˆï¼ˆæ¼”ç¤ºæ¦‚å¿µï¼‰
                    for j, (_, other_text) in enumerate(pairs):
                        if j != i and j < 2:  # é™åˆ¶è´Ÿæ ·æœ¬å±•ç¤ºæ•°é‡
                            clip_data_rows.append([img_name, other_text, f"è´Ÿæ ·æœ¬{i+1}-{j+1}"])
            
            # æ„å»ºå›¾æ–‡å¯¹åº”çš„HTMLæ˜¾ç¤º
            if text_descriptions:
                text_html = "<div style='max-height: 300px; overflow-y: auto;'>"
                text_html += "<h4>ğŸ–¼ï¸ å›¾æ–‡æ­£æ ·æœ¬å¯¹</h4>"
                for desc in text_descriptions:
                    text_html += f"<div style='margin: 10px 0; padding: 8px; border: 1px solid #ddd; border-radius: 4px;'>{desc}</div>"
                text_html += "</div>"
                text_html += "<p style='color: green; margin-top: 10px;'>âœ… å¯¹æ¯”å­¦ä¹ æ—¶ï¼ŒåŒ¹é…çš„å›¾æ–‡å¯¹ä½œä¸ºæ­£æ ·æœ¬ï¼Œä¸åŒ¹é…çš„ä½œä¸ºè´Ÿæ ·æœ¬</p>"
                text_html += f"<p style='color: blue;'>ğŸ“‚ å›¾ç‰‡è·¯å¾„éªŒè¯: æ‰¾åˆ° {len(valid_images)} å¼ æœ‰æ•ˆå›¾ç‰‡</p>"
            else:
                text_html = "<p style='color:red'>æœªæ‰¾åˆ°æœ‰æ•ˆçš„å›¾æ–‡å¯¹æ•°æ®</p>"
            
            # è°ƒè¯•ä¿¡æ¯
            print(f"CLIPå¯è§†åŒ–: æ‰¾åˆ° {len(valid_images)} å¼ å›¾ç‰‡")
            for img_path in valid_images:
                print(f"å›¾ç‰‡è·¯å¾„: {img_path}, å­˜åœ¨: {os.path.exists(img_path)}")
                            
            return clip_data_rows, valid_images, text_html
        
        load_clip_btn.click(load_clip, inputs=[clip_model_name], outputs=[clip_status])
        clip_train_btn.click(finetune_clip, inputs=[clip_model_name], outputs=[clip_log])
        viz_clip_data_btn.click(visualize_clip_data, outputs=[clip_data_viz, clip_image_gallery, clip_text_display])
        
        # æ·»åŠ  LLMOps Engine çš„ resume æ”¯æŒï¼ˆå‚è€ƒ LLaMA-Factory çš„è®¾è®¡ï¼‰
        # æ³¨æ„ï¼šæš‚æ—¶ç¦ç”¨ resume åŠŸèƒ½ï¼Œé¿å… Gradio ç±»å‹æ¨æ–­é”™è¯¯
        # å¦‚æœéœ€è¦æ¢å¤åŠŸèƒ½ï¼Œéœ€è¦ç¡®ä¿æ‰€æœ‰ç»„ä»¶éƒ½å·²æ­£ç¡®æ³¨å†Œä¸”ç±»å‹æ³¨è§£æ­£ç¡®
        # if train_engine is not None:
        #     try:
        #         output_elems = [elem for elem in train_engine.manager.get_elem_list() if elem is not None]
        #         if output_elems:
        #             training_tab.load(
        #                 train_engine.resume,
        #                 outputs=output_elems,
        #                 concurrency_limit=None
        #             )
        #     except Exception as e:
        #         print(f"è­¦å‘Š: LLMOps resume åŠŸèƒ½åˆå§‹åŒ–å¤±è´¥: {e}")

        return training_tab 