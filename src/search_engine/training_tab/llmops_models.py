"""
LLaMA-Factory æ”¯æŒçš„æ¨¡å‹åˆ—è¡¨é…ç½®
å‚è€ƒ: https://github.com/hiyouga/LLaMA-Factory/blob/main/src/llamafactory/data/model_cards.py
"""
from typing import Dict, List, Tuple


class LLaMAFactoryModels:
    """LLaMA-Factory æ”¯æŒçš„æ¨¡å‹é…ç½®"""
    
    # ä¸»æµå¼€æºæ¨¡å‹åˆ—è¡¨ï¼ˆæŒ‰ç³»åˆ—åˆ†ç»„ï¼‰
    SUPPORTED_MODELS = {
        # Llama ç³»åˆ—
        "llama3": [
            "meta-llama/Meta-Llama-3-8B",
            "meta-llama/Meta-Llama-3-8B-Instruct",
            "meta-llama/Meta-Llama-3-70B",
            "meta-llama/Meta-Llama-3-70B-Instruct",
            "meta-llama/Llama-3.2-1B",
            "meta-llama/Llama-3.2-3B",
            "meta-llama/Llama-3.2-1B-Instruct",
            "meta-llama/Llama-3.2-3B-Instruct",
        ],
        "llama2": [
            "meta-llama/Llama-2-7b-hf",
            "meta-llama/Llama-2-7b-chat-hf",
            "meta-llama/Llama-2-13b-hf",
            "meta-llama/Llama-2-13b-chat-hf",
            "meta-llama/Llama-2-70b-hf",
            "meta-llama/Llama-2-70b-chat-hf",
        ],
        
        # Qwen ç³»åˆ—
        "qwen2": [
            "Qwen/Qwen2-0.5B",
            "Qwen/Qwen2-1.5B",
            "Qwen/Qwen2-7B",
            "Qwen/Qwen2-7B-Instruct",
            "Qwen/Qwen2-72B",
            "Qwen/Qwen2-72B-Instruct",
            "Qwen/Qwen2.5-0.5B",
            "Qwen/Qwen2.5-1.5B",
            "Qwen/Qwen2.5-3B",
            "Qwen/Qwen2.5-7B",
            "Qwen/Qwen2.5-7B-Instruct",
            "Qwen/Qwen2.5-14B",
            "Qwen/Qwen2.5-32B",
            "Qwen/Qwen2.5-72B",
        ],
        
        # Mistral ç³»åˆ—
        "mistral": [
            "mistralai/Mistral-7B-v0.1",
            "mistralai/Mistral-7B-Instruct-v0.1",
            "mistralai/Mistral-7B-v0.3",
            "mistralai/Mistral-7B-Instruct-v0.3",
            "mistralai/Mixtral-8x7B-v0.1",
            "mistralai/Mixtral-8x7B-Instruct-v0.1",
            "mistralai/Mixtral-8x22B-v0.1",
        ],
        
        # Yi ç³»åˆ—
        "yi": [
            "01-ai/Yi-6B",
            "01-ai/Yi-6B-Chat",
            "01-ai/Yi-9B",
            "01-ai/Yi-34B",
            "01-ai/Yi-34B-Chat",
            "01-ai/Yi-1.5-6B",
            "01-ai/Yi-1.5-9B",
            "01-ai/Yi-1.5-34B",
        ],
        
        # ChatGLM ç³»åˆ—
        "chatglm": [
            "THUDM/chatglm3-6b",
            "THUDM/chatglm3-6b-base",
            "THUDM/glm-4-9b",
            "THUDM/glm-4-9b-chat",
        ],
        
        # Baichuan ç³»åˆ—
        "baichuan": [
            "baichuan-inc/Baichuan2-7B-Base",
            "baichuan-inc/Baichuan2-7B-Chat",
            "baichuan-inc/Baichuan2-13B-Base",
            "baichuan-inc/Baichuan2-13B-Chat",
        ],
        
        # DeepSeek ç³»åˆ—
        "deepseek": [
            "deepseek-ai/deepseek-llm-7b-base",
            "deepseek-ai/deepseek-llm-7b-chat",
            "deepseek-ai/deepseek-llm-67b-base",
            "deepseek-ai/deepseek-llm-67b-chat",
            "deepseek-ai/DeepSeek-V2",
            "deepseek-ai/DeepSeek-V2-Chat",
        ],
        
        # InternLM ç³»åˆ—
        "internlm": [
            "internlm/internlm2-7b",
            "internlm/internlm2-7b-chat",
            "internlm/internlm2-20b",
            "internlm/internlm2-20b-chat",
        ],
        
        # Phi ç³»åˆ—ï¼ˆå¾®è½¯ï¼‰
        "phi": [
            "microsoft/phi-2",
            "microsoft/Phi-3-mini-4k-instruct",
            "microsoft/Phi-3-mini-128k-instruct",
        ],
        
        # Gemma ç³»åˆ—ï¼ˆGoogleï¼‰
        "gemma": [
            "google/gemma-2b",
            "google/gemma-2b-it",
            "google/gemma-7b",
            "google/gemma-7b-it",
            "google/gemma-2-9b",
            "google/gemma-2-27b",
        ],
    }
    
    # å¸¸ç”¨æ¨¡å‹ï¼ˆç”¨äºå¿«é€Ÿé€‰æ‹©ï¼‰
    POPULAR_MODELS = [
        "meta-llama/Meta-Llama-3-8B",
        "Qwen/Qwen2.5-7B",
        "mistralai/Mistral-7B-v0.3",
        "01-ai/Yi-6B",
        "THUDM/chatglm3-6b",
        "deepseek-ai/deepseek-llm-7b-base",
    ]
    
    # æ¨¡å‹æ¨¡æ¿æ˜ å°„
    MODEL_TEMPLATES = {
        "llama3": "llama3",
        "llama2": "llama2",
        "qwen2": "qwen",
        "mistral": "mistral",
        "yi": "yi",
        "chatglm": "chatglm3",
        "baichuan": "baichuan2",
        "deepseek": "deepseek",
        "internlm": "intern2",
        "phi": "phi",
        "gemma": "gemma",
    }
    
    @classmethod
    def get_all_models(cls) -> List[str]:
        """è·å–æ‰€æœ‰æ”¯æŒçš„æ¨¡å‹"""
        all_models = []
        for models in cls.SUPPORTED_MODELS.values():
            all_models.extend(models)
        return sorted(all_models)
    
    @classmethod
    def get_models_by_series(cls, series: str) -> List[str]:
        """æŒ‰ç³»åˆ—è·å–æ¨¡å‹åˆ—è¡¨"""
        return cls.SUPPORTED_MODELS.get(series, [])
    
    @classmethod
    def get_popular_models(cls) -> List[str]:
        """è·å–å¸¸ç”¨æ¨¡å‹åˆ—è¡¨"""
        return cls.POPULAR_MODELS
    
    @classmethod
    def get_model_series(cls) -> List[str]:
        """è·å–æ‰€æœ‰æ¨¡å‹ç³»åˆ—"""
        return list(cls.SUPPORTED_MODELS.keys())
    
    @classmethod
    def get_grouped_choices(cls) -> List[Tuple[str, List[Tuple[str, str]]]]:
        """è·å–åˆ†ç»„çš„æ¨¡å‹é€‰æ‹©åˆ—è¡¨ï¼ˆç”¨äº Gradio Dropdownï¼‰
        
        Returns:
            List of (group_name, [(display_name, value), ...])
        """
        grouped = []
        
        # å¸¸ç”¨æ¨¡å‹ç»„
        grouped.append((
            "â­ å¸¸ç”¨æ¨¡å‹",
            [(model, model) for model in cls.POPULAR_MODELS]
        ))
        
        # æŒ‰ç³»åˆ—åˆ†ç»„
        series_display = {
            "llama3": "ğŸ¦™ Llama 3",
            "llama2": "ğŸ¦™ Llama 2",
            "qwen2": "ğŸ”· Qwen",
            "mistral": "ğŸŒ€ Mistral",
            "yi": "ğŸ¯ Yi",
            "chatglm": "ğŸ’¬ ChatGLM",
            "baichuan": "ğŸ˜ Baichuan",
            "deepseek": "ğŸ” DeepSeek",
            "internlm": "ğŸ§  InternLM",
            "phi": "Î¦ Phi",
            "gemma": "ğŸ’ Gemma",
        }
        
        for series, models in cls.SUPPORTED_MODELS.items():
            display_name = series_display.get(series, series.upper())
            grouped.append((
                display_name,
                [(model, model) for model in models]
            ))
        
        return grouped
    
    @classmethod
    def get_flat_choices(cls) -> List[str]:
        """è·å–æ‰å¹³çš„æ¨¡å‹é€‰æ‹©åˆ—è¡¨ï¼ˆç”¨äºç®€å•çš„ Dropdownï¼‰"""
        return cls.get_all_models()
    
    @classmethod
    def get_template_for_model(cls, model_path: str) -> str:
        """æ ¹æ®æ¨¡å‹è·¯å¾„æ¨æ–­å¯¹åº”çš„æ¨¡æ¿"""
        model_lower = model_path.lower()
        
        if "llama-3" in model_lower or "llama3" in model_lower:
            return "llama3"
        elif "llama-2" in model_lower or "llama2" in model_lower:
            return "llama2"
        elif "qwen" in model_lower:
            return "qwen"
        elif "mistral" in model_lower or "mixtral" in model_lower:
            return "mistral"
        elif "yi-" in model_lower or "/yi" in model_lower:
            return "yi"
        elif "chatglm" in model_lower or "glm-4" in model_lower:
            return "chatglm3"
        elif "baichuan" in model_lower:
            return "baichuan2"
        elif "deepseek" in model_lower:
            return "deepseek"
        elif "internlm" in model_lower:
            return "intern2"
        elif "phi" in model_lower:
            return "phi"
        elif "gemma" in model_lower:
            return "gemma"
        else:
            return "default"

