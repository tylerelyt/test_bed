#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
é€»è¾‘å›å½’CTRæ¨¡å‹è®­ç»ƒ
åŸºäºå€’æ’ç´¢å¼•æ£€ç´¢ç³»ç»Ÿçš„ç‚¹å‡»æ•°æ®è®­ç»ƒç‚¹å‡»ç‡é¢„æµ‹æ¨¡å‹
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report, roc_auc_score, log_loss, accuracy_score
import matplotlib.pyplot as plt
import seaborn as sns
import glob
import os

def load_ctr_data():
    """åŠ è½½æœ€æ–°çš„CTRæ•°æ®æ–‡ä»¶"""
    ctr_files = glob.glob('ctr_data_*.csv')
    
    if not ctr_files:
        print("âŒ æœªæ‰¾åˆ°CTRæ•°æ®æ–‡ä»¶")
        print("è¯·å…ˆè¿è¡Œå€’æ’ç´¢å¼•æ£€ç´¢ç³»ç»Ÿå¹¶å¯¼å‡ºCTRæ•°æ®")
        return None
    
    # ä½¿ç”¨æœ€æ–°çš„æ–‡ä»¶
    latest_file = max(ctr_files)
    print(f"ğŸ“ ä½¿ç”¨æ•°æ®æ–‡ä»¶: {latest_file}")
    
    try:
        df = pd.read_csv(latest_file)
        print(f"âœ… æˆåŠŸåŠ è½½CTRæ•°æ®: {len(df)} æ¡è®°å½•")
        return df
    except Exception as e:
        print(f"âŒ åŠ è½½æ•°æ®å¤±è´¥: {e}")
        return None

def preprocess_features(df):
    """ç‰¹å¾é¢„å¤„ç†"""
    print("ğŸ”§ ç‰¹å¾é¢„å¤„ç†...")
    
    # åŸºç¡€ç‰¹å¾
    features = df[['position', 'score', 'doc_length']].copy()
    
    # ä½ç½®ç‰¹å¾å·¥ç¨‹
    features['position_rank'] = 1.0 / features['position']  # ä½ç½®å€’æ•°
    features['position_log'] = np.log(features['position'])  # ä½ç½®å¯¹æ•°
    
    # åˆ†æ•°ç‰¹å¾å·¥ç¨‹
    features['score_squared'] = features['score'] ** 2
    features['score_log'] = np.log(features['score'] + 1e-6)
    
    # æ–‡æ¡£é•¿åº¦ç‰¹å¾å·¥ç¨‹
    features['doc_length_log'] = np.log(features['doc_length'] + 1)
    features['doc_length_ratio'] = features['doc_length'] / features['doc_length'].max()
    
    # äº¤äº’ç‰¹å¾
    features['position_score'] = features['position'] * features['score']
    features['position_length'] = features['position'] * features['doc_length_log']
    
    # æŸ¥è¯¢ç‰¹å¾ï¼ˆone-hotç¼–ç ï¼‰
    query_encoded = pd.get_dummies(df['query'], prefix='query')
    features = pd.concat([features, query_encoded], axis=1)
    
    print(f"   ç‰¹å¾æ•°é‡: {features.shape[1]}")
    print(f"   ç‰¹å¾åˆ—è¡¨: {list(features.columns)}")
    
    return features

def train_logistic_regression(X, y):
    """è®­ç»ƒé€»è¾‘å›å½’æ¨¡å‹"""
    print("ğŸ¤– è®­ç»ƒé€»è¾‘å›å½’CTRæ¨¡å‹...")
    
    # åˆ’åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›†
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42, stratify=y
    )
    
    print(f"   è®­ç»ƒé›†å¤§å°: {len(X_train)}")
    print(f"   æµ‹è¯•é›†å¤§å°: {len(X_test)}")
    print(f"   è®­ç»ƒé›†ç‚¹å‡»ç‡: {np.mean(y_train):.4f}")
    print(f"   æµ‹è¯•é›†ç‚¹å‡»ç‡: {np.mean(y_test):.4f}")
    
    # è®­ç»ƒé€»è¾‘å›å½’æ¨¡å‹
    lr_model = LogisticRegression(
        random_state=42, 
        max_iter=1000,
        solver='liblinear'  # é€‚åˆå°æ•°æ®é›†
    )
    
    lr_model.fit(X_train, y_train)
    
    # é¢„æµ‹
    y_pred = lr_model.predict(X_test)
    y_prob = lr_model.predict_proba(X_test)[:, 1]
    
    return lr_model, (X_train, X_test, y_train, y_test), (y_pred, y_prob)

def evaluate_model(y_test, y_pred, y_prob):
    """è¯„ä¼°æ¨¡å‹æ€§èƒ½"""
    print("\nğŸ“Š é€»è¾‘å›å½’æ¨¡å‹è¯„ä¼°ç»“æœ:")
    print("=" * 50)
    
    # åŸºç¡€æŒ‡æ ‡
    accuracy = accuracy_score(y_test, y_pred)
    auc = roc_auc_score(y_test, y_prob)
    loss = log_loss(y_test, y_prob)
    
    print(f"   å‡†ç¡®ç‡ (Accuracy): {accuracy:.4f}")
    print(f"   AUC: {auc:.4f}")
    print(f"   Log Loss: {loss:.4f}")
    
    # åˆ†ç±»æŠ¥å‘Š
    print(f"\n   åˆ†ç±»æŠ¥å‘Š:")
    print(classification_report(y_test, y_pred, target_names=['æœªç‚¹å‡»', 'ç‚¹å‡»']))
    
    return {
        'accuracy': accuracy,
        'auc': auc,
        'log_loss': loss
    }

def analyze_feature_importance(model, X):
    """åˆ†æç‰¹å¾é‡è¦æ€§"""
    print("\nğŸ¯ ç‰¹å¾é‡è¦æ€§åˆ†æ:")
    print("=" * 50)
    
    # è·å–ç‰¹å¾ç³»æ•°
    coefficients = model.coef_[0]
    feature_names = X.columns
    
    # åˆ›å»ºç‰¹å¾é‡è¦æ€§DataFrame
    importance_df = pd.DataFrame({
        'feature': feature_names,
        'coefficient': coefficients,
        'abs_coefficient': np.abs(coefficients)
    }).sort_values('abs_coefficient', ascending=False)
    
    print("\nğŸ“ˆ ç‰¹å¾ç³»æ•° (æŒ‰é‡è¦æ€§æ’åº):")
    print(importance_df.head(15))
    
    # åˆ†ææ­£è´Ÿå½±å“
    positive_features = importance_df[importance_df['coefficient'] > 0].head(5)
    negative_features = importance_df[importance_df['coefficient'] < 0].head(5)
    
    print(f"\nâœ… æ­£å‘å½±å“ç‰¹å¾ (æé«˜ç‚¹å‡»ç‡):")
    for _, row in positive_features.iterrows():
        print(f"   {row['feature']}: {row['coefficient']:.4f}")
    
    print(f"\nâŒ è´Ÿå‘å½±å“ç‰¹å¾ (é™ä½ç‚¹å‡»ç‡):")
    for _, row in negative_features.iterrows():
        print(f"   {row['feature']}: {row['coefficient']:.4f}")
    
    return importance_df

def visualize_results(importance_df, metrics):
    """å¯è§†åŒ–ç»“æœ"""
    print("\nğŸ“Š ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨...")
    
    # è®¾ç½®ä¸­æ–‡å­—ä½“
    plt.rcParams['font.sans-serif'] = ['SimHei', 'Arial Unicode MS']
    plt.rcParams['axes.unicode_minus'] = False
    
    fig, axes = plt.subplots(2, 2, figsize=(15, 12))
    
    # 1. ç‰¹å¾é‡è¦æ€§
    top_features = importance_df.head(10)
    axes[0, 0].barh(range(len(top_features)), top_features['coefficient'])
    axes[0, 0].set_yticks(range(len(top_features)))
    axes[0, 0].set_yticklabels(top_features['feature'])
    axes[0, 0].set_title('é€»è¾‘å›å½’ç‰¹å¾ç³»æ•° (Top 10)')
    axes[0, 0].set_xlabel('Coefficient')
    axes[0, 0].axvline(x=0, color='red', linestyle='--', alpha=0.5)
    
    # 2. æ¨¡å‹æ€§èƒ½æŒ‡æ ‡
    metric_names = list(metrics.keys())
    metric_values = list(metrics.values())
    colors = ['skyblue', 'lightcoral', 'lightgreen']
    
    bars = axes[0, 1].bar(metric_names, metric_values, color=colors)
    axes[0, 1].set_title('æ¨¡å‹æ€§èƒ½æŒ‡æ ‡')
    axes[0, 1].set_ylabel('Score')
    
    # åœ¨æŸ±çŠ¶å›¾ä¸Šæ·»åŠ æ•°å€¼æ ‡ç­¾
    for bar, value in zip(bars, metric_values):
        axes[0, 1].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,
                       f'{value:.3f}', ha='center', va='bottom')
    
    # 3. ç‰¹å¾é‡è¦æ€§åˆ†å¸ƒ
    axes[1, 0].hist(importance_df['coefficient'], bins=20, alpha=0.7, color='skyblue')
    axes[1, 0].set_title('ç‰¹å¾ç³»æ•°åˆ†å¸ƒ')
    axes[1, 0].set_xlabel('Coefficient')
    axes[1, 0].set_ylabel('Frequency')
    axes[1, 0].axvline(x=0, color='red', linestyle='--', alpha=0.5)
    
    # 4. ä½ç½®ä¸ç‚¹å‡»ç‡å…³ç³»
    # è¿™é‡Œéœ€è¦åŸå§‹æ•°æ®ï¼Œæš‚æ—¶ç”¨ç¤ºä¾‹æ•°æ®
    axes[1, 1].text(0.5, 0.5, 'ä½ç½®-ç‚¹å‡»ç‡å…³ç³»å›¾\n(éœ€è¦æ›´å¤šæ•°æ®)', 
                   ha='center', va='center', transform=axes[1, 1].transAxes,
                   fontsize=12, bbox=dict(boxstyle="round,pad=0.3", facecolor="lightgray"))
    axes[1, 1].set_title('ä½ç½®ä¸ç‚¹å‡»ç‡å…³ç³»')
    
    plt.tight_layout()
    plt.savefig('ctr_lr_results.png', dpi=300, bbox_inches='tight')
    print("   å›¾è¡¨å·²ä¿å­˜ä¸º: ctr_lr_results.png")

def generate_report(model, metrics, importance_df, X):
    """ç”ŸæˆCTRåˆ†ææŠ¥å‘Š"""
    print("\nğŸ“‹ ç”ŸæˆCTRåˆ†ææŠ¥å‘Š...")
    
    report = f"""
# é€»è¾‘å›å½’CTRæ¨¡å‹è®­ç»ƒæŠ¥å‘Š

## æ¨¡å‹æ€§èƒ½æ€»ç»“

### è¯„ä¼°æŒ‡æ ‡
- **å‡†ç¡®ç‡ (Accuracy)**: {metrics['accuracy']:.4f}
- **AUC**: {metrics['auc']:.4f}
- **Log Loss**: {metrics['log_loss']:.4f}

### æ¨¡å‹ç±»å‹
- **ç®—æ³•**: é€»è¾‘å›å½’ (Logistic Regression)
- **æ±‚è§£å™¨**: liblinear
- **æ­£åˆ™åŒ–**: L2æ­£åˆ™åŒ–

## ç‰¹å¾å·¥ç¨‹

### ç‰¹å¾æ•°é‡
æ€»ç‰¹å¾æ•°é‡: {X.shape[1]}

### ç‰¹å¾ç±»å‹
- **åŸºç¡€ç‰¹å¾**: position, score, doc_length
- **ä½ç½®ç‰¹å¾**: position_rank, position_log
- **åˆ†æ•°ç‰¹å¾**: score_squared, score_log
- **é•¿åº¦ç‰¹å¾**: doc_length_log, doc_length_ratio
- **äº¤äº’ç‰¹å¾**: position_score, position_length
- **æŸ¥è¯¢ç‰¹å¾**: æŸ¥è¯¢è¯one-hotç¼–ç 

## ç‰¹å¾é‡è¦æ€§åˆ†æ

### æ­£å‘å½±å“ç‰¹å¾ (Top 5)
"""
    
    positive_features = importance_df[importance_df['coefficient'] > 0].head(5)
    for _, row in positive_features.iterrows():
        report += f"- **{row['feature']}**: {row['coefficient']:.4f}\n"
    
    report += "\n### è´Ÿå‘å½±å“ç‰¹å¾ (Top 5)\n"
    negative_features = importance_df[importance_df['coefficient'] < 0].head(5)
    for _, row in negative_features.iterrows():
        report += f"- **{row['feature']}**: {row['coefficient']:.4f}\n"
    
    report += f"""

## æ¨¡å‹è§£é‡Š

### é€»è¾‘å›å½’ä¼˜åŠ¿
1. **å¯è§£é‡Šæ€§å¼º**: ç³»æ•°ç›´æ¥è¡¨ç¤ºç‰¹å¾å¯¹ç‚¹å‡»ç‡çš„å½±å“
2. **è®­ç»ƒé€Ÿåº¦å¿«**: é€‚åˆå®æ—¶æ›´æ–°
3. **å†…å­˜å ç”¨å°**: é€‚åˆå¤§è§„æ¨¡éƒ¨ç½²
4. **æ¦‚ç‡è¾“å‡º**: ç›´æ¥è¾“å‡ºç‚¹å‡»æ¦‚ç‡

### ç‰¹å¾å½±å“åˆ†æ
- **ä½ç½®ç‰¹å¾**: ä½ç½®è¶Šé å‰ï¼Œç‚¹å‡»ç‡è¶Šé«˜
- **åˆ†æ•°ç‰¹å¾**: ç›¸ä¼¼åº¦åˆ†æ•°è¶Šé«˜ï¼Œç‚¹å‡»ç‡è¶Šé«˜
- **é•¿åº¦ç‰¹å¾**: æ–‡æ¡£é•¿åº¦é€‚ä¸­æ—¶ç‚¹å‡»ç‡è¾ƒé«˜
- **æŸ¥è¯¢ç‰¹å¾**: ä¸åŒæŸ¥è¯¢è¯çš„ç‚¹å‡»åå¥½ä¸åŒ

## åº”ç”¨å»ºè®®

### 1. æœç´¢ç»“æœæ’åºä¼˜åŒ–
- ç»“åˆCTRé¢„æµ‹åˆ†æ•°è°ƒæ•´æ’åº
- å…¬å¼: æœ€ç»ˆåˆ†æ•° = Î± Ã— ç›¸ä¼¼åº¦åˆ†æ•° + Î² Ã— CTRé¢„æµ‹åˆ†æ•°

### 2. æ¨¡å‹æ›´æ–°ç­–ç•¥
- å®šæœŸé‡æ–°è®­ç»ƒæ¨¡å‹
- è€ƒè™‘åœ¨çº¿å­¦ä¹ æ›´æ–°
- ç›‘æ§æ¨¡å‹æ€§èƒ½å˜åŒ–

### 3. ç‰¹å¾æ‰©å±•
- æ·»åŠ ç”¨æˆ·ç‰¹å¾
- æ·»åŠ æ—¶é—´ç‰¹å¾
- æ·»åŠ ä¸Šä¸‹æ–‡ç‰¹å¾

### 4. è¯„ä¼°æŒ‡æ ‡
- ä¸»è¦å…³æ³¨AUCå’ŒLog Loss
- ä¸šåŠ¡æŒ‡æ ‡: CTRæå‡ã€ç”¨æˆ·æ»¡æ„åº¦
- A/Bæµ‹è¯•éªŒè¯æ•ˆæœ

## æŠ€æœ¯ç»†èŠ‚

### è®­ç»ƒå‚æ•°
- è®­ç»ƒé›†æ¯”ä¾‹: 80%
- æµ‹è¯•é›†æ¯”ä¾‹: 20%
- éšæœºç§å­: 42
- æœ€å¤§è¿­ä»£æ¬¡æ•°: 1000

### æ•°æ®è´¨é‡
- ç¡®ä¿æ ‡ç­¾å¹³è¡¡
- å¤„ç†ç¼ºå¤±å€¼
- ç‰¹å¾æ ‡å‡†åŒ–
"""
    
    with open('ctr_lr_analysis_report.md', 'w', encoding='utf-8') as f:
        f.write(report)
    
    print("   æŠ¥å‘Šå·²ä¿å­˜ä¸º: ctr_lr_analysis_report.md")

def save_model(model, X, importance_df):
    """ä¿å­˜æ¨¡å‹å’Œç‰¹å¾ä¿¡æ¯"""
    import pickle
    
    model_info = {
        'model': model,
        'feature_names': list(X.columns),
        'importance_df': importance_df
    }
    
    with open('ctr_lr_model.pkl', 'wb') as f:
        pickle.dump(model_info, f)
    
    print("   æ¨¡å‹å·²ä¿å­˜ä¸º: ctr_lr_model.pkl")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¯ é€»è¾‘å›å½’CTRæ¨¡å‹è®­ç»ƒ")
    print("=" * 50)
    
    # åŠ è½½æ•°æ®
    df = load_ctr_data()
    if df is None:
        return
    
    # æ•°æ®æ¦‚è§ˆ
    print(f"\nğŸ“Š æ•°æ®æ¦‚è§ˆ:")
    print(f"   æ€»è®°å½•æ•°: {len(df)}")
    print(f"   ç‚¹å‡»ç‡: {df['clicked'].mean():.4f} ({df['clicked'].mean()*100:.2f}%)")
    print(f"   å”¯ä¸€æŸ¥è¯¢æ•°: {df['query'].nunique()}")
    print(f"   å”¯ä¸€æ–‡æ¡£æ•°: {df['doc_id'].nunique()}")
    
    # æ£€æŸ¥æ•°æ®è´¨é‡
    if df['clicked'].sum() < 10:
        print("âš ï¸  è­¦å‘Š: ç‚¹å‡»æ•°æ®è¾ƒå°‘ï¼Œå¯èƒ½å½±å“æ¨¡å‹è®­ç»ƒæ•ˆæœ")
    
    # ç‰¹å¾é¢„å¤„ç†
    X = preprocess_features(df)
    y = df['clicked']
    
    # è®­ç»ƒæ¨¡å‹
    model, (X_train, X_test, y_train, y_test), (y_pred, y_prob) = train_logistic_regression(X, y)
    
    # è¯„ä¼°æ¨¡å‹
    metrics = evaluate_model(y_test, y_pred, y_prob)
    
    # ç‰¹å¾é‡è¦æ€§åˆ†æ
    importance_df = analyze_feature_importance(model, X)
    
    # å¯è§†åŒ–ç»“æœ
    visualize_results(importance_df, metrics)
    
    # ç”ŸæˆæŠ¥å‘Š
    generate_report(model, metrics, importance_df, X)
    
    # ä¿å­˜æ¨¡å‹
    save_model(model, X, importance_df)
    
    print("\nğŸ‰ é€»è¾‘å›å½’CTRæ¨¡å‹è®­ç»ƒå®Œæˆ!")
    print("ğŸ“ ç”Ÿæˆçš„æ–‡ä»¶:")
    print("   - ctr_lr_results.png: å¯è§†åŒ–å›¾è¡¨")
    print("   - ctr_lr_analysis_report.md: åˆ†ææŠ¥å‘Š")
    print("   - ctr_lr_model.pkl: è®­ç»ƒå¥½çš„æ¨¡å‹")
    
    print("\nğŸ’¡ ä½¿ç”¨å»ºè®®:")
    print("   1. æ”¶é›†æ›´å¤šç‚¹å‡»æ•°æ®ä»¥æé«˜æ¨¡å‹æ•ˆæœ")
    print("   2. å°è¯•ä¸åŒçš„ç‰¹å¾ç»„åˆ")
    print("   3. å®šæœŸé‡æ–°è®­ç»ƒæ¨¡å‹")
    print("   4. ç»“åˆä¸šåŠ¡æŒ‡æ ‡è¯„ä¼°æ¨¡å‹æ•ˆæœ")

if __name__ == "__main__":
    main() 