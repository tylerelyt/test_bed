#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
åŸºæœ¬ä½¿ç”¨ç¤ºä¾‹
æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨Intelligent Search Engineçš„æ ¸å¿ƒåŠŸèƒ½
"""

import sys
import os
sys.path.append(os.path.join(os.path.dirname(__file__), '..', 'src'))

from search_engine.service_manager import (
    get_data_service,
    get_index_service,
    get_model_service
)
from search_engine.data_utils import (
    record_search_impression,
    record_document_click,
    get_data_statistics,
    analyze_click_patterns
)


def main():
    """åŸºæœ¬ä½¿ç”¨ç¤ºä¾‹"""
    print("ğŸ” Intelligent Search Engine - åŸºæœ¬ä½¿ç”¨ç¤ºä¾‹")
    print("=" * 50)
    
    # 1. è·å–æœåŠ¡å®ä¾‹
    print("\n1. åˆå§‹åŒ–æœåŠ¡...")
    data_service = get_data_service()
    index_service = get_index_service()
    model_service = get_model_service()
    print("âœ… æœåŠ¡åˆå§‹åŒ–å®Œæˆ")
    
    # 2. æ·»åŠ ç¤ºä¾‹æ–‡æ¡£
    print("\n2. æ·»åŠ ç¤ºä¾‹æ–‡æ¡£...")
    documents = {
        "doc1": "äººå·¥æ™ºèƒ½æ˜¯è®¡ç®—æœºç§‘å­¦çš„ä¸€ä¸ªåˆ†æ”¯ï¼Œå®ƒä¼å›¾äº†è§£æ™ºèƒ½çš„å®è´¨ï¼Œå¹¶ç”Ÿäº§å‡ºä¸€ç§æ–°çš„èƒ½ä»¥äººç±»æ™ºèƒ½ç›¸ä¼¼çš„æ–¹å¼åšå‡ºååº”çš„æ™ºèƒ½æœºå™¨ã€‚",
        "doc2": "æœºå™¨å­¦ä¹ æ˜¯äººå·¥æ™ºèƒ½çš„ä¸€ä¸ªå­é¢†åŸŸï¼Œä¸“æ³¨äºç®—æ³•çš„è®¾è®¡ï¼Œè¿™äº›ç®—æ³•å¯ä»¥ä»æ•°æ®ä¸­å­¦ä¹ å¹¶åšå‡ºé¢„æµ‹æˆ–å†³ç­–ã€‚",
        "doc3": "æ·±åº¦å­¦ä¹ æ˜¯æœºå™¨å­¦ä¹ çš„ä¸€ä¸ªå­é›†ï¼Œå®ƒä½¿ç”¨å¤šå±‚ç¥ç»ç½‘ç»œæ¥æ¨¡æ‹Ÿäººè„‘çš„å­¦ä¹ è¿‡ç¨‹ã€‚",
        "doc4": "è‡ªç„¶è¯­è¨€å¤„ç†æ˜¯äººå·¥æ™ºèƒ½çš„ä¸€ä¸ªé‡è¦åˆ†æ”¯ï¼Œæ—¨åœ¨è®©è®¡ç®—æœºèƒ½å¤Ÿç†è§£ã€è§£é‡Šå’Œç”Ÿæˆäººç±»è¯­è¨€ã€‚",
        "doc5": "è®¡ç®—æœºè§†è§‰æ˜¯äººå·¥æ™ºèƒ½çš„ä¸€ä¸ªé¢†åŸŸï¼Œè‡´åŠ›äºè®©è®¡ç®—æœºèƒ½å¤Ÿè¯†åˆ«å’Œç†è§£å›¾åƒå’Œè§†é¢‘å†…å®¹ã€‚"
    }
    
    # æ‰¹é‡æ·»åŠ æ–‡æ¡£
    added_count = index_service.batch_add_documents(documents)
    print(f"âœ… æˆåŠŸæ·»åŠ  {added_count} ä¸ªæ–‡æ¡£")
    
    # 3. æ‰§è¡Œæœç´¢
    print("\n3. æ‰§è¡Œæœç´¢...")
    query = "äººå·¥æ™ºèƒ½"
    request_id = "example_request_001"
    
    # å¬å›é˜¶æ®µ
    doc_ids = index_service.retrieve(query, top_k=10)
    print(f"ğŸ“‹ å¬å›æ–‡æ¡£: {doc_ids}")
    
    # æ’åºé˜¶æ®µ
    ranked_results = index_service.rank(query, doc_ids, top_k=5)
    print(f"ğŸ“Š æ’åºç»“æœ: {len(ranked_results)} ä¸ªæ–‡æ¡£")
    
    # 4. è®°å½•ç”¨æˆ·è¡Œä¸º
    print("\n4. è®°å½•ç”¨æˆ·è¡Œä¸º...")
    
    # è®°å½•å±•ç¤ºäº‹ä»¶
    for position, result in enumerate(ranked_results, 1):
        doc_id, score, summary = result[:3]  # è§£æç»“æœ
        
        # ä½¿ç”¨å·¥å…·å‡½æ•°è®°å½•å±•ç¤º
        record_search_impression(
            query=query,
            doc_id=doc_id,
            position=position,
            score=score,
            summary=summary,
            request_id=request_id
        )
        
        print(f"  ğŸ“„ ä½ç½®{position}: {doc_id} (åˆ†æ•°: {score:.3f})")
    
    # æ¨¡æ‹Ÿç”¨æˆ·ç‚¹å‡»ç¬¬ä¸€ä¸ªç»“æœ
    clicked_doc_id = ranked_results[0][0]
    success = record_document_click(clicked_doc_id, request_id)
    print(f"ğŸ‘† ç”¨æˆ·ç‚¹å‡»æ–‡æ¡£: {clicked_doc_id} {'âœ…' if success else 'âŒ'}")
    
    # 5. æŸ¥çœ‹æ•°æ®ç»Ÿè®¡
    print("\n5. æ•°æ®ç»Ÿè®¡...")
    stats = get_data_statistics()
    print(f"ğŸ“Š æ€»æ ·æœ¬æ•°: {stats['total_samples']}")
    print(f"ğŸ“Š æ€»ç‚¹å‡»æ•°: {stats['total_clicks']}")
    print(f"ğŸ“Š ç‚¹å‡»ç‡: {stats['click_rate']:.2%}")
    print(f"ğŸ“Š å”¯ä¸€æŸ¥è¯¢æ•°: {stats['unique_queries']}")
    print(f"ğŸ“Š å”¯ä¸€æ–‡æ¡£æ•°: {stats['unique_docs']}")
    
    # 6. ç‚¹å‡»æ¨¡å¼åˆ†æ
    print("\n6. ç‚¹å‡»æ¨¡å¼åˆ†æ...")
    patterns = analyze_click_patterns()
    if 'error' not in patterns:
        print(f"ğŸ” æ•´ä½“CTR: {patterns['overall_ctr']:.2%}")
        print(f"ğŸ” æ€»å±•ç¤ºæ•°: {patterns['total_impressions']}")
        print(f"ğŸ” æ€»ç‚¹å‡»æ•°: {patterns['total_clicks']}")
        
        # ä½ç½®åˆ†æ
        if patterns.get('position_analysis'):
            print("ğŸ“ˆ ä½ç½®CTRåˆ†æ:")
            for pos, stats in patterns['position_analysis'].items():
                if isinstance(stats, dict) and 'mean' in stats:
                    print(f"  ä½ç½®{pos}: CTR={stats['mean']:.2%}")
    
    # 7. æ¨¡å‹è®­ç»ƒ
    print("\n7. æ¨¡å‹è®­ç»ƒ...")
    
    # éªŒè¯è®­ç»ƒæ•°æ®
    validation = model_service.validate_training_data(data_service)
    if validation['valid']:
        print("âœ… è®­ç»ƒæ•°æ®éªŒè¯é€šè¿‡")
        
        # è®­ç»ƒæ¨¡å‹
        result = model_service.train_model(data_service)
        if result['success']:
            print("âœ… æ¨¡å‹è®­ç»ƒæˆåŠŸ")
            
            # è·å–æ¨¡å‹ä¿¡æ¯
            model_info = model_service.get_model_info()
            print(f"ğŸ¤– æ¨¡å‹çŠ¶æ€: {'å·²è®­ç»ƒ' if model_info['is_trained'] else 'æœªè®­ç»ƒ'}")
            print(f"ğŸ¤– è®­ç»ƒæ—¶é—´: {model_info.get('training_time', 'N/A')}")
        else:
            print(f"âŒ æ¨¡å‹è®­ç»ƒå¤±è´¥: {result.get('error', 'æœªçŸ¥é”™è¯¯')}")
    else:
        print("âŒ è®­ç»ƒæ•°æ®éªŒè¯å¤±è´¥:")
        for issue in validation['issues']:
            print(f"  - {issue}")
        print("ğŸ’¡ å»ºè®®:")
        for rec in validation['recommendations']:
            print(f"  - {rec}")
    
    # 8. è·å–ç´¢å¼•ç»Ÿè®¡
    print("\n8. ç´¢å¼•ç»Ÿè®¡...")
    index_stats = index_service.get_stats()
    print(f"ğŸ“š æ€»æ–‡æ¡£æ•°: {index_stats.get('total_documents', 0)}")
    print(f"ğŸ“š æ€»è¯æ±‡æ•°: {index_stats.get('total_terms', 0)}")
    print(f"ğŸ“š å¹³å‡æ–‡æ¡£é•¿åº¦: {index_stats.get('avg_doc_length', 0):.1f}")
    
    print("\nğŸ‰ ç¤ºä¾‹æ‰§è¡Œå®Œæˆï¼")
    print("ğŸ’¡ æç¤º: è¿è¡Œ 'python start_system.py' å¯åŠ¨Webç•Œé¢")


if __name__ == "__main__":
    main() 