#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ‰¹é‡æ“ä½œç¤ºä¾‹
æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨æ‰¹é‡æ“ä½œæé«˜æ•°æ®å¤„ç†æ•ˆç‡
"""

import sys
import os
sys.path.append(os.path.join(os.path.dirname(__file__), '..', 'src'))

from search_engine.service_manager import get_data_service
from search_engine.data_utils import get_data_statistics
import uuid
from datetime import datetime


def generate_sample_data(num_queries=5, num_docs_per_query=10):
    """ç”Ÿæˆç¤ºä¾‹æ•°æ®"""
    queries = [
        "äººå·¥æ™ºèƒ½",
        "æœºå™¨å­¦ä¹ ", 
        "æ·±åº¦å­¦ä¹ ",
        "è‡ªç„¶è¯­è¨€å¤„ç†",
        "è®¡ç®—æœºè§†è§‰"
    ]
    
    impressions = []
    clicks = []
    
    for i, query in enumerate(queries[:num_queries]):
        request_id = f"batch_req_{i}_{uuid.uuid4().hex[:8]}"
        
        # ä¸ºæ¯ä¸ªæŸ¥è¯¢ç”Ÿæˆå¤šä¸ªæ–‡æ¡£å±•ç¤º
        for j in range(num_docs_per_query):
            doc_id = f"doc_{i}_{j}"
            position = j + 1
            score = 1.0 - (j * 0.1)  # åˆ†æ•°é€’å‡
            summary = f"å…³äº{query}çš„æ–‡æ¡£{j+1}çš„æ‘˜è¦å†…å®¹"
            
            impressions.append({
                "query": query,
                "doc_id": doc_id,
                "position": position,
                "score": score,
                "summary": summary,
                "request_id": request_id
            })
            
            # æ¨¡æ‹Ÿç‚¹å‡»ï¼ˆå‰å‡ ä¸ªä½ç½®æœ‰æ›´é«˜çš„ç‚¹å‡»æ¦‚ç‡ï¼‰
            if j < 3 and (j + i) % 2 == 0:  # ç®€å•çš„ç‚¹å‡»æ¨¡æ‹Ÿ
                clicks.append({
                    "doc_id": doc_id,
                    "request_id": request_id
                })
    
    return impressions, clicks


def main():
    """æ‰¹é‡æ“ä½œç¤ºä¾‹"""
    print("ğŸ” Intelligent Search Engine - æ‰¹é‡æ“ä½œç¤ºä¾‹")
    print("=" * 50)
    
    # 1. è·å–æ•°æ®æœåŠ¡
    print("\n1. åˆå§‹åŒ–æ•°æ®æœåŠ¡...")
    data_service = get_data_service()
    print("âœ… æ•°æ®æœåŠ¡åˆå§‹åŒ–å®Œæˆ")
    
    # 2. ç”Ÿæˆç¤ºä¾‹æ•°æ®
    print("\n2. ç”Ÿæˆç¤ºä¾‹æ•°æ®...")
    impressions, clicks = generate_sample_data(num_queries=3, num_docs_per_query=8)
    print(f"ğŸ“Š ç”Ÿæˆ {len(impressions)} ä¸ªå±•ç¤ºäº‹ä»¶")
    print(f"ğŸ‘† ç”Ÿæˆ {len(clicks)} ä¸ªç‚¹å‡»äº‹ä»¶")
    
    # 3. æ‰¹é‡è®°å½•å±•ç¤ºäº‹ä»¶
    print("\n3. æ‰¹é‡è®°å½•å±•ç¤ºäº‹ä»¶...")
    start_time = datetime.now()
    
    result = data_service.batch_record_impressions(impressions)
    
    end_time = datetime.now()
    duration = (end_time - start_time).total_seconds()
    
    print(f"â±ï¸  æ‰¹é‡å±•ç¤ºè€—æ—¶: {duration:.3f}ç§’")
    print(f"âœ… æˆåŠŸè®°å½•: {result['success_count']} ä¸ªå±•ç¤º")
    print(f"âŒ å¤±è´¥è®°å½•: {result['error_count']} ä¸ªå±•ç¤º")
    
    if result['errors']:
        print("é”™è¯¯è¯¦æƒ…:")
        for error in result['errors'][:5]:  # åªæ˜¾ç¤ºå‰5ä¸ªé”™è¯¯
            print(f"  - {error}")
    
    # 4. æ‰¹é‡è®°å½•ç‚¹å‡»äº‹ä»¶
    print("\n4. æ‰¹é‡è®°å½•ç‚¹å‡»äº‹ä»¶...")
    start_time = datetime.now()
    
    result = data_service.batch_record_clicks(clicks)
    
    end_time = datetime.now()
    duration = (end_time - start_time).total_seconds()
    
    print(f"â±ï¸  æ‰¹é‡ç‚¹å‡»è€—æ—¶: {duration:.3f}ç§’")
    print(f"âœ… æˆåŠŸè®°å½•: {result['success_count']} ä¸ªç‚¹å‡»")
    print(f"âŒ å¤±è´¥è®°å½•: {result['error_count']} ä¸ªç‚¹å‡»")
    
    if result['errors']:
        print("é”™è¯¯è¯¦æƒ…:")
        for error in result['errors'][:5]:
            print(f"  - {error}")
    
    # 5. æŸ¥çœ‹æ•°æ®ç»Ÿè®¡
    print("\n5. æ•°æ®ç»Ÿè®¡...")
    stats = get_data_statistics()
    print(f"ğŸ“Š æ€»æ ·æœ¬æ•°: {stats['total_samples']}")
    print(f"ğŸ“Š æ€»ç‚¹å‡»æ•°: {stats['total_clicks']}")
    print(f"ğŸ“Š ç‚¹å‡»ç‡: {stats['click_rate']:.2%}")
    print(f"ğŸ“Š å”¯ä¸€æŸ¥è¯¢æ•°: {stats['unique_queries']}")
    print(f"ğŸ“Š å”¯ä¸€æ–‡æ¡£æ•°: {stats['unique_docs']}")
    
    # 6. æ€§èƒ½å¯¹æ¯”ç¤ºä¾‹
    print("\n6. æ€§èƒ½å¯¹æ¯”...")
    
    # ç”Ÿæˆå°æ‰¹é‡æ•°æ®ç”¨äºå¯¹æ¯”
    small_impressions, _ = generate_sample_data(num_queries=1, num_docs_per_query=10)
    
    # æ–¹å¼1: æ‰¹é‡æ“ä½œ
    print("æ–¹å¼1: æ‰¹é‡æ“ä½œ")
    start_time = datetime.now()
    data_service.batch_record_impressions(small_impressions)
    batch_duration = (datetime.now() - start_time).total_seconds()
    print(f"  æ‰¹é‡æ“ä½œè€—æ—¶: {batch_duration:.3f}ç§’")
    
    # æ–¹å¼2: é€ä¸ªæ“ä½œï¼ˆä»…ç”¨äºæ¼”ç¤ºï¼Œå®é™…ä¸æ¨èï¼‰
    print("æ–¹å¼2: é€ä¸ªæ“ä½œï¼ˆæ¼”ç¤ºç”¨ï¼‰")
    start_time = datetime.now()
    for impression in small_impressions[:5]:  # åªæµ‹è¯•å‰5ä¸ª
        try:
            data_service.record_impression(
                impression['query'],
                impression['doc_id'] + "_single",  # é¿å…é‡å¤
                impression['position'],
                impression['score'],
                impression['summary'],
                impression['request_id'] + "_single"
            )
        except Exception as e:
            print(f"    é”™è¯¯: {e}")
    single_duration = (datetime.now() - start_time).total_seconds()
    print(f"  é€ä¸ªæ“ä½œè€—æ—¶: {single_duration:.3f}ç§’")
    
    if batch_duration > 0:
        speedup = single_duration / batch_duration * 2  # ä¹˜ä»¥2å› ä¸ºåªæµ‹è¯•äº†ä¸€åŠ
        print(f"  æ€§èƒ½æå‡: {speedup:.1f}å€")
    
    # 7. æ•°æ®å¥åº·æ£€æŸ¥
    print("\n7. æ•°æ®å¥åº·æ£€æŸ¥...")
    health = data_service.get_data_health_check()
    print(f"ğŸ“Š æ€»æ ·æœ¬æ•°: {health['total_samples']}")
    print(f"ğŸ“Š å¾…ä¿å­˜å˜æ›´: {health['pending_changes']}")
    print(f"ğŸ“Š ç¼“å­˜çŠ¶æ€: {health['cache_status']}")
    
    if health['data_issues']:
        print("âš ï¸  æ•°æ®é—®é¢˜:")
        for issue in health['data_issues']:
            print(f"  - {issue}")
    
    if health['recommendations']:
        print("ğŸ’¡ å»ºè®®:")
        for rec in health['recommendations']:
            print(f"  - {rec}")
    
    # 8. å¼ºåˆ¶ä¿å­˜æ•°æ®
    print("\n8. å¼ºåˆ¶ä¿å­˜æ•°æ®...")
    data_service.force_save()
    print("âœ… æ•°æ®å·²å¼ºåˆ¶ä¿å­˜åˆ°ç£ç›˜")
    
    print("\nğŸ‰ æ‰¹é‡æ“ä½œç¤ºä¾‹å®Œæˆï¼")
    print("ğŸ’¡ æç¤º: æ‰¹é‡æ“ä½œæ¯”é€ä¸ªæ“ä½œæ•ˆç‡æ›´é«˜ï¼Œå»ºè®®åœ¨å¤„ç†å¤§é‡æ•°æ®æ—¶ä½¿ç”¨")


if __name__ == "__main__":
    main() 